=== Step4. Script Execution Started at Fri Jul 25 11:41:42 PM UTC 2025 ===
Base directory: vrchat-worlds
Data prefix: meta
Output directory: output/vrchat-worlds/train
[INFO] ip_len → norm: token, model: bigru
[INFO] tcp_window → norm: token, model: bigru
Running CUDA_VISIBLE_DEVICES=1 python vrscanner.py --train --debug_path output/vrchat-worlds/train/train_meta_1753486902.debug --leaderboard_path output/vrchat-worlds/train/train_meta_1753486902.csv --kfold 5 --pktcount 1000 --input_dim 512 --hidden_size 256 --num_layers 3 --dropout 0.3 --fusion_dim 256 --fc_hidden_size 128 --epoch 50 --lr 0.001 --path vrchat-worlds/meta-ip_len/meta-ip_len.csv vrchat-worlds/meta-tcp_window/meta-tcp_window.csv --norm token token --model bigru bigru
[2025-07-25 23:41:44,772] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv', 'vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=1000, importance=False, kfold=5, model=['bigru', 'bigru'], norm=['token', 'token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/vrchat-worlds/train/train_meta_1753486902.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753486902.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'))
[2025-07-25 23:42:25,961] [INFO] Processed data from vrchat-worlds/meta-ip_len/meta-ip_len.csv:
[2025-07-25 23:42:25,961] [INFO] (15228, 1000)
[2025-07-25 23:42:25,961] [INFO] [['244' '141' '52' ... '52' '52' '100']
 ['60' '60' '52' ... '52' '52' '1432']
 ['1432' '1432' '1432' ... '52' '930' '76']
 ...
 ['52' '1432' '1432' ... '1432' '1432' '1432']
 ['1432' '340' '52' ... '1432' '1432' '1432']
 ['52' '52' '1432' ... '52' '254' '235']]
[2025-07-25 23:43:10,403] [INFO] Processed data from vrchat-worlds/meta-tcp_window/meta-tcp_window.csv:
[2025-07-25 23:43:10,404] [INFO] (15228, 1000)
[2025-07-25 23:43:10,404] [INFO] [['1281' '1281' '580' ... '291' '291' '291']
 ['65535' '65535' '256' ... '291' '291' '1540']
 ['2038' '2038' '2038' ... '534' '534' '310']
 ...
 ['265' '774' '774' ... '300' '300' '300']
 ['265' '265' '332' ... '289' '289' '289']
 ['343' '761' '300' ... '774' '5404' '5404']]
[2025-07-25 23:43:10,459] [INFO] Training Fold 1/5
[2025-07-25 23:43:25,605] [INFO] Feature 0 normalized using token
[2025-07-25 23:43:25,606] [INFO] Train shape: (10659, 1000), Val shape: (1523, 1000), Test shape: (3046, 1000)
[2025-07-25 23:43:42,855] [INFO] Feature 1 normalized using token
[2025-07-25 23:43:42,855] [INFO] Train shape: (10659, 1000), Val shape: (1523, 1000), Test shape: (3046, 1000)
[2025-07-25 23:43:42,955] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
    (1): Embedding(5120, 512)
  )
  (rnn_layers): ModuleList(
    (0-1): 2 x GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0-1): 2 x Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-25 23:43:42,955] [INFO] Training...
[2025-07-25 23:44:25,464] [INFO] Epoch 1/50, ValAcc: 49.97%, TrainLoss: 2.8802, ValLoss: 1.7656, LR: 0.001
[2025-07-25 23:45:07,454] [INFO] Epoch 2/50, ValAcc: 68.88%, TrainLoss: 1.4496, ValLoss: 1.0959, LR: 0.001
[2025-07-25 23:45:48,454] [INFO] Epoch 3/50, ValAcc: 75.84%, TrainLoss: 0.8835, ValLoss: 0.8844, LR: 0.001
[2025-07-25 23:46:29,491] [INFO] Epoch 4/50, ValAcc: 80.24%, TrainLoss: 0.6074, ValLoss: 0.7446, LR: 0.001
[2025-07-25 23:47:10,523] [INFO] Epoch 5/50, ValAcc: 81.48%, TrainLoss: 0.4707, ValLoss: 0.7361, LR: 0.001
[2025-07-25 23:47:51,510] [INFO] Epoch 6/50, ValAcc: 82.86%, TrainLoss: 0.3589, ValLoss: 0.7673, LR: 0.001
[2025-07-25 23:48:32,607] [INFO] Epoch 7/50, ValAcc: 82.14%, TrainLoss: 0.3069, ValLoss: 0.8411, LR: 0.001
[2025-07-25 23:49:13,813] [INFO] Epoch 8/50, ValAcc: 82.80%, TrainLoss: 0.2753, ValLoss: 0.7760, LR: 0.001
[2025-07-25 23:49:55,193] [INFO] Epoch 9/50, ValAcc: 86.54%, TrainLoss: 0.1410, ValLoss: 0.7109, LR: 0.0005
[2025-07-25 23:50:36,478] [INFO] Epoch 10/50, ValAcc: 85.69%, TrainLoss: 0.0897, ValLoss: 0.7860, LR: 0.0005
[2025-07-25 23:51:17,794] [INFO] Epoch 11/50, ValAcc: 85.75%, TrainLoss: 0.0709, ValLoss: 0.8150, LR: 0.0005
[2025-07-25 23:51:58,885] [INFO] Epoch 12/50, ValAcc: 86.15%, TrainLoss: 0.0589, ValLoss: 0.8796, LR: 0.0005
[2025-07-25 23:52:39,950] [INFO] Epoch 13/50, ValAcc: 86.61%, TrainLoss: 0.0379, ValLoss: 0.8889, LR: 0.00025
[2025-07-25 23:53:21,059] [INFO] Epoch 14/50, ValAcc: 86.80%, TrainLoss: 0.0317, ValLoss: 0.9152, LR: 0.00025
[2025-07-25 23:54:02,318] [INFO] Epoch 15/50, ValAcc: 86.74%, TrainLoss: 0.0298, ValLoss: 0.9262, LR: 0.00025
[2025-07-25 23:54:43,353] [INFO] Epoch 16/50, ValAcc: 86.54%, TrainLoss: 0.0255, ValLoss: 0.9183, LR: 0.000125
[2025-07-25 23:55:24,488] [INFO] Epoch 17/50, ValAcc: 86.93%, TrainLoss: 0.0225, ValLoss: 0.9336, LR: 0.000125
[2025-07-25 23:56:05,750] [INFO] Epoch 18/50, ValAcc: 86.61%, TrainLoss: 0.0215, ValLoss: 0.9556, LR: 0.000125
[2025-07-25 23:56:47,098] [INFO] Epoch 19/50, ValAcc: 86.93%, TrainLoss: 0.0183, ValLoss: 0.9551, LR: 6.25e-05
[2025-07-25 23:56:47,098] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-25 23:56:51,183] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv', 'vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=1000, importance=False, kfold=5, model=['bigru', 'bigru'], norm=['token', 'token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/vrchat-worlds/train/train_meta_1753486902.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753486902.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen-tcpwindow_token-token_bigru-bigru_1000_64_50_0.001_512_256_3_0.3_256_128'),0.8664,0.8637,0.8657,0.8641
[2025-07-25 23:56:51,184] [INFO] Training Fold 2/5
[2025-07-25 23:57:07,248] [INFO] Feature 0 normalized using token
[2025-07-25 23:57:07,248] [INFO] Train shape: (10659, 1000), Val shape: (1523, 1000), Test shape: (3046, 1000)
[2025-07-25 23:57:23,327] [INFO] Feature 1 normalized using token
[2025-07-25 23:57:23,327] [INFO] Train shape: (10659, 1000), Val shape: (1523, 1000), Test shape: (3046, 1000)
[2025-07-25 23:57:23,414] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
    (1): Embedding(5091, 512)
  )
  (rnn_layers): ModuleList(
    (0-1): 2 x GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0-1): 2 x Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-25 23:57:23,414] [INFO] Training...
[2025-07-25 23:58:04,785] [INFO] Epoch 1/50, ValAcc: 55.75%, TrainLoss: 2.8320, ValLoss: 1.6789, LR: 0.001
[2025-07-25 23:58:46,000] [INFO] Epoch 2/50, ValAcc: 69.40%, TrainLoss: 1.3593, ValLoss: 1.1263, LR: 0.001
[2025-07-25 23:59:27,124] [INFO] Epoch 3/50, ValAcc: 75.64%, TrainLoss: 0.8594, ValLoss: 0.8666, LR: 0.001
[2025-07-26 00:00:08,126] [INFO] Epoch 4/50, ValAcc: 78.59%, TrainLoss: 0.5838, ValLoss: 0.8540, LR: 0.001
[2025-07-26 00:00:49,129] [INFO] Epoch 5/50, ValAcc: 79.32%, TrainLoss: 0.4427, ValLoss: 0.8422, LR: 0.001
[2025-07-26 00:01:30,144] [INFO] Epoch 6/50, ValAcc: 81.29%, TrainLoss: 0.3422, ValLoss: 0.8015, LR: 0.001
[2025-07-26 00:02:11,176] [INFO] Epoch 7/50, ValAcc: 82.34%, TrainLoss: 0.2917, ValLoss: 0.7908, LR: 0.001
[2025-07-26 00:02:52,180] [INFO] Epoch 8/50, ValAcc: 82.53%, TrainLoss: 0.2345, ValLoss: 0.8559, LR: 0.001
[2025-07-26 00:03:33,193] [INFO] Epoch 9/50, ValAcc: 83.32%, TrainLoss: 0.1860, ValLoss: 0.9302, LR: 0.001
[2025-07-26 00:04:14,162] [INFO] Epoch 10/50, ValAcc: 82.21%, TrainLoss: 0.1621, ValLoss: 1.0364, LR: 0.001
[2025-07-26 00:04:55,114] [INFO] Epoch 11/50, ValAcc: 85.23%, TrainLoss: 0.0934, ValLoss: 0.9446, LR: 0.0005
[2025-07-26 00:05:36,119] [INFO] Epoch 12/50, ValAcc: 86.01%, TrainLoss: 0.0519, ValLoss: 1.0143, LR: 0.0005
[2025-07-26 00:06:17,272] [INFO] Epoch 13/50, ValAcc: 86.21%, TrainLoss: 0.0451, ValLoss: 1.0432, LR: 0.0005
[2025-07-26 00:06:58,522] [INFO] Epoch 14/50, ValAcc: 86.15%, TrainLoss: 0.0313, ValLoss: 1.0518, LR: 0.00025
[2025-07-26 00:07:39,861] [INFO] Epoch 15/50, ValAcc: 86.01%, TrainLoss: 0.0235, ValLoss: 1.0762, LR: 0.00025
[2025-07-26 00:08:21,133] [INFO] Epoch 16/50, ValAcc: 86.34%, TrainLoss: 0.0228, ValLoss: 1.1252, LR: 0.00025
[2025-07-26 00:09:02,402] [INFO] Epoch 17/50, ValAcc: 86.41%, TrainLoss: 0.0199, ValLoss: 1.1260, LR: 0.000125
[2025-07-26 00:09:43,608] [INFO] Epoch 18/50, ValAcc: 86.08%, TrainLoss: 0.0184, ValLoss: 1.1310, LR: 0.000125
[2025-07-26 00:10:24,548] [INFO] Epoch 19/50, ValAcc: 86.15%, TrainLoss: 0.0168, ValLoss: 1.1438, LR: 0.000125
[2025-07-26 00:11:05,582] [INFO] Epoch 20/50, ValAcc: 86.34%, TrainLoss: 0.0147, ValLoss: 1.1530, LR: 6.25e-05
[2025-07-26 00:11:05,582] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-26 00:11:09,586] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv', 'vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=1000, importance=False, kfold=5, model=['bigru', 'bigru'], norm=['token', 'token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/vrchat-worlds/train/train_meta_1753486902.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753486902.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen-tcpwindow_token-token_bigru-bigru_1000_64_50_0.001_512_256_3_0.3_256_128'),0.8529,0.8562,0.8578,0.8585
[2025-07-26 00:11:09,586] [INFO] Training Fold 3/5
[2025-07-26 00:11:25,177] [INFO] Feature 0 normalized using token
[2025-07-26 00:11:25,177] [INFO] Train shape: (10659, 1000), Val shape: (1523, 1000), Test shape: (3046, 1000)
[2025-07-26 00:11:40,939] [INFO] Feature 1 normalized using token
[2025-07-26 00:11:40,939] [INFO] Train shape: (10659, 1000), Val shape: (1523, 1000), Test shape: (3046, 1000)
[2025-07-26 00:11:41,041] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
    (1): Embedding(5118, 512)
  )
  (rnn_layers): ModuleList(
    (0-1): 2 x GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0-1): 2 x Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-26 00:11:41,042] [INFO] Training...
[2025-07-26 00:12:22,308] [INFO] Epoch 1/50, ValAcc: 51.61%, TrainLoss: 2.8277, ValLoss: 1.7189, LR: 0.001
[2025-07-26 00:13:03,348] [INFO] Epoch 2/50, ValAcc: 69.86%, TrainLoss: 1.3900, ValLoss: 1.0621, LR: 0.001
[2025-07-26 00:13:44,499] [INFO] Epoch 3/50, ValAcc: 76.36%, TrainLoss: 0.8375, ValLoss: 0.8880, LR: 0.001
[2025-07-26 00:14:25,538] [INFO] Epoch 4/50, ValAcc: 79.45%, TrainLoss: 0.5850, ValLoss: 0.7872, LR: 0.001
[2025-07-26 00:15:06,721] [INFO] Epoch 5/50, ValAcc: 81.48%, TrainLoss: 0.4246, ValLoss: 0.7930, LR: 0.001
[2025-07-26 00:15:48,110] [INFO] Epoch 6/50, ValAcc: 82.07%, TrainLoss: 0.3275, ValLoss: 0.7446, LR: 0.001
[2025-07-26 00:16:29,600] [INFO] Epoch 7/50, ValAcc: 84.04%, TrainLoss: 0.2570, ValLoss: 0.7417, LR: 0.001
[2025-07-26 00:17:11,074] [INFO] Epoch 8/50, ValAcc: 83.52%, TrainLoss: 0.2063, ValLoss: 0.8410, LR: 0.001
[2025-07-26 00:17:52,553] [INFO] Epoch 9/50, ValAcc: 83.78%, TrainLoss: 0.1800, ValLoss: 0.8856, LR: 0.001
[2025-07-26 00:18:33,908] [INFO] Epoch 10/50, ValAcc: 84.90%, TrainLoss: 0.1395, ValLoss: 0.9759, LR: 0.001
[2025-07-26 00:19:15,039] [INFO] Epoch 11/50, ValAcc: 86.15%, TrainLoss: 0.0797, ValLoss: 0.8974, LR: 0.0005
[2025-07-26 00:19:56,183] [INFO] Epoch 12/50, ValAcc: 86.34%, TrainLoss: 0.0490, ValLoss: 0.9218, LR: 0.0005
[2025-07-26 00:20:37,211] [INFO] Epoch 13/50, ValAcc: 86.61%, TrainLoss: 0.0413, ValLoss: 0.9803, LR: 0.0005
[2025-07-26 00:21:18,515] [INFO] Epoch 14/50, ValAcc: 86.41%, TrainLoss: 0.0295, ValLoss: 0.9904, LR: 0.00025
[2025-07-26 00:21:59,778] [INFO] Epoch 15/50, ValAcc: 86.15%, TrainLoss: 0.0255, ValLoss: 1.0243, LR: 0.00025
[2025-07-26 00:22:40,927] [INFO] Epoch 16/50, ValAcc: 86.34%, TrainLoss: 0.0259, ValLoss: 1.0268, LR: 0.00025
[2025-07-26 00:23:22,016] [INFO] Epoch 17/50, ValAcc: 86.41%, TrainLoss: 0.0222, ValLoss: 1.0408, LR: 0.000125
[2025-07-26 00:24:04,076] [INFO] Epoch 18/50, ValAcc: 86.47%, TrainLoss: 0.0209, ValLoss: 1.0700, LR: 0.000125
[2025-07-26 00:24:45,116] [INFO] Epoch 19/50, ValAcc: 86.74%, TrainLoss: 0.0201, ValLoss: 1.0731, LR: 0.000125
[2025-07-26 00:25:26,223] [INFO] Epoch 20/50, ValAcc: 86.74%, TrainLoss: 0.0196, ValLoss: 1.0712, LR: 6.25e-05
[2025-07-26 00:25:26,223] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-26 00:25:30,222] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv', 'vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=1000, importance=False, kfold=5, model=['bigru', 'bigru'], norm=['token', 'token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/vrchat-worlds/train/train_meta_1753486902.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753486902.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen-tcpwindow_token-token_bigru-bigru_1000_64_50_0.001_512_256_3_0.3_256_128'),0.8605,0.8616,0.8650,0.8620
[2025-07-26 00:25:30,222] [INFO] Training Fold 4/5
[2025-07-26 00:25:46,069] [INFO] Feature 0 normalized using token
[2025-07-26 00:25:46,069] [INFO] Train shape: (10660, 1000), Val shape: (1523, 1000), Test shape: (3045, 1000)
[2025-07-26 00:26:02,638] [INFO] Feature 1 normalized using token
[2025-07-26 00:26:02,639] [INFO] Train shape: (10660, 1000), Val shape: (1523, 1000), Test shape: (3045, 1000)
[2025-07-26 00:26:02,722] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
    (1): Embedding(5144, 512)
  )
  (rnn_layers): ModuleList(
    (0-1): 2 x GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0-1): 2 x Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-26 00:26:02,722] [INFO] Training...
[2025-07-26 00:26:43,893] [INFO] Epoch 1/50, ValAcc: 46.09%, TrainLoss: 2.9592, ValLoss: 1.9623, LR: 0.001
[2025-07-26 00:27:25,087] [INFO] Epoch 2/50, ValAcc: 70.85%, TrainLoss: 1.5158, ValLoss: 1.1031, LR: 0.001
[2025-07-26 00:28:06,328] [INFO] Epoch 3/50, ValAcc: 77.28%, TrainLoss: 0.8849, ValLoss: 0.8497, LR: 0.001
[2025-07-26 00:28:47,445] [INFO] Epoch 4/50, ValAcc: 79.32%, TrainLoss: 0.5857, ValLoss: 0.8334, LR: 0.001
[2025-07-26 00:29:28,546] [INFO] Epoch 5/50, ValAcc: 81.81%, TrainLoss: 0.4315, ValLoss: 0.7880, LR: 0.001
[2025-07-26 00:30:09,596] [INFO] Epoch 6/50, ValAcc: 82.01%, TrainLoss: 0.3455, ValLoss: 0.8723, LR: 0.001
[2025-07-26 00:30:50,635] [INFO] Epoch 7/50, ValAcc: 81.94%, TrainLoss: 0.2621, ValLoss: 0.8832, LR: 0.001
[2025-07-26 00:31:31,686] [INFO] Epoch 8/50, ValAcc: 83.19%, TrainLoss: 0.2130, ValLoss: 0.9173, LR: 0.001
[2025-07-26 00:32:12,822] [INFO] Epoch 9/50, ValAcc: 85.49%, TrainLoss: 0.1213, ValLoss: 0.8880, LR: 0.0005
[2025-07-26 00:32:53,935] [INFO] Epoch 10/50, ValAcc: 86.21%, TrainLoss: 0.0717, ValLoss: 0.9225, LR: 0.0005
[2025-07-26 00:33:35,007] [INFO] Epoch 11/50, ValAcc: 85.82%, TrainLoss: 0.0567, ValLoss: 1.0146, LR: 0.0005
[2025-07-26 00:34:16,124] [INFO] Epoch 12/50, ValAcc: 86.41%, TrainLoss: 0.0357, ValLoss: 1.0277, LR: 0.00025
[2025-07-26 00:34:57,185] [INFO] Epoch 13/50, ValAcc: 86.61%, TrainLoss: 0.0312, ValLoss: 1.0671, LR: 0.00025
[2025-07-26 00:35:38,243] [INFO] Epoch 14/50, ValAcc: 86.93%, TrainLoss: 0.0289, ValLoss: 1.0853, LR: 0.00025
[2025-07-26 00:36:19,480] [INFO] Epoch 15/50, ValAcc: 86.74%, TrainLoss: 0.0230, ValLoss: 1.0930, LR: 0.000125
[2025-07-26 00:37:00,516] [INFO] Epoch 16/50, ValAcc: 86.47%, TrainLoss: 0.0221, ValLoss: 1.1138, LR: 0.000125
[2025-07-26 00:37:41,709] [INFO] Epoch 17/50, ValAcc: 86.67%, TrainLoss: 0.0200, ValLoss: 1.1280, LR: 0.000125
[2025-07-26 00:38:23,119] [INFO] Epoch 18/50, ValAcc: 87.07%, TrainLoss: 0.0191, ValLoss: 1.1304, LR: 6.25e-05
[2025-07-26 00:38:23,119] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-26 00:38:27,165] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv', 'vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=1000, importance=False, kfold=5, model=['bigru', 'bigru'], norm=['token', 'token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/vrchat-worlds/train/train_meta_1753486902.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753486902.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen-tcpwindow_token-token_bigru-bigru_1000_64_50_0.001_512_256_3_0.3_256_128'),0.8667,0.8640,0.8658,0.8652
[2025-07-26 00:38:27,165] [INFO] Training Fold 5/5
[2025-07-26 00:38:42,693] [INFO] Feature 0 normalized using token
[2025-07-26 00:38:42,693] [INFO] Train shape: (10660, 1000), Val shape: (1523, 1000), Test shape: (3045, 1000)
[2025-07-26 00:38:58,982] [INFO] Feature 1 normalized using token
[2025-07-26 00:38:58,982] [INFO] Train shape: (10660, 1000), Val shape: (1523, 1000), Test shape: (3045, 1000)
[2025-07-26 00:38:59,062] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
    (1): Embedding(5138, 512)
  )
  (rnn_layers): ModuleList(
    (0-1): 2 x GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0-1): 2 x Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-26 00:38:59,062] [INFO] Training...
[2025-07-26 00:39:40,574] [INFO] Epoch 1/50, ValAcc: 51.48%, TrainLoss: 2.9020, ValLoss: 1.8281, LR: 0.001
[2025-07-26 00:40:22,103] [INFO] Epoch 2/50, ValAcc: 67.96%, TrainLoss: 1.5255, ValLoss: 1.1103, LR: 0.001
[2025-07-26 00:41:03,616] [INFO] Epoch 3/50, ValAcc: 76.82%, TrainLoss: 0.9129, ValLoss: 0.8373, LR: 0.001
[2025-07-26 00:41:44,858] [INFO] Epoch 4/50, ValAcc: 80.43%, TrainLoss: 0.6267, ValLoss: 0.7501, LR: 0.001
[2025-07-26 00:42:26,071] [INFO] Epoch 5/50, ValAcc: 81.68%, TrainLoss: 0.4552, ValLoss: 0.7437, LR: 0.001
[2025-07-26 00:43:07,246] [INFO] Epoch 6/50, ValAcc: 83.19%, TrainLoss: 0.3418, ValLoss: 0.7140, LR: 0.001
[2025-07-26 00:43:48,372] [INFO] Epoch 7/50, ValAcc: 84.04%, TrainLoss: 0.2642, ValLoss: 0.7665, LR: 0.001
[2025-07-26 00:44:29,540] [INFO] Epoch 8/50, ValAcc: 84.37%, TrainLoss: 0.2213, ValLoss: 0.8020, LR: 0.001
[2025-07-26 00:45:10,666] [INFO] Epoch 9/50, ValAcc: 84.18%, TrainLoss: 0.1990, ValLoss: 0.8778, LR: 0.001
[2025-07-26 00:45:51,930] [INFO] Epoch 10/50, ValAcc: 85.55%, TrainLoss: 0.1093, ValLoss: 0.7875, LR: 0.0005
[2025-07-26 00:46:33,129] [INFO] Epoch 11/50, ValAcc: 85.69%, TrainLoss: 0.0702, ValLoss: 0.8371, LR: 0.0005
[2025-07-26 00:47:14,353] [INFO] Epoch 12/50, ValAcc: 85.62%, TrainLoss: 0.0516, ValLoss: 0.9182, LR: 0.0005
[2025-07-26 00:47:55,575] [INFO] Epoch 13/50, ValAcc: 86.21%, TrainLoss: 0.0369, ValLoss: 0.9197, LR: 0.00025
[2025-07-26 00:48:36,831] [INFO] Epoch 14/50, ValAcc: 85.88%, TrainLoss: 0.0309, ValLoss: 0.9395, LR: 0.00025
[2025-07-26 00:49:17,917] [INFO] Epoch 15/50, ValAcc: 85.49%, TrainLoss: 0.0263, ValLoss: 0.9546, LR: 0.00025
[2025-07-26 00:49:59,037] [INFO] Epoch 16/50, ValAcc: 85.75%, TrainLoss: 0.0236, ValLoss: 0.9712, LR: 0.000125
[2025-07-26 00:50:40,267] [INFO] Epoch 17/50, ValAcc: 85.75%, TrainLoss: 0.0224, ValLoss: 0.9953, LR: 0.000125
[2025-07-26 00:51:21,568] [INFO] Epoch 18/50, ValAcc: 85.88%, TrainLoss: 0.0206, ValLoss: 1.0066, LR: 0.000125
[2025-07-26 00:52:02,974] [INFO] Epoch 19/50, ValAcc: 86.21%, TrainLoss: 0.0190, ValLoss: 1.0072, LR: 6.25e-05
[2025-07-26 00:52:02,974] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-26 00:52:07,030] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv', 'vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=1000, importance=False, kfold=5, model=['bigru', 'bigru'], norm=['token', 'token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/vrchat-worlds/train/train_meta_1753486902.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753486902.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen-tcpwindow_token-token_bigru-bigru_1000_64_50_0.001_512_256_3_0.3_256_128'),0.8650,0.8637,0.8673,0.8637
[2025-07-26 00:52:07,460] [INFO] [(0.8663821405121471, 0.8637179359021896, 0.8657213511849062, 0.864124118154382), (0.8529218647406435, 0.8562144685538499, 0.8578067374818892, 0.8585218560869857), (0.860472751149048, 0.8615841033748045, 0.8650020460588133, 0.8619754515927979), (0.8666666666666667, 0.8640407363606286, 0.8658430101155649, 0.8652445451373458), (0.865024630541872, 0.8636835334234968, 0.8673126986605872, 0.8637154755298976)]
Running CUDA_VISIBLE_DEVICES=1 python vrscanner.py --train --debug_path output/vrchat-worlds/train/train_meta_1753491128.debug --leaderboard_path output/vrchat-worlds/train/train_meta_1753491128.csv --kfold 5 --pktcount 2000 --input_dim 512 --hidden_size 256 --num_layers 3 --dropout 0.3 --fusion_dim 256 --fc_hidden_size 128 --epoch 50 --lr 0.001 --path vrchat-worlds/meta-ip_len/meta-ip_len.csv vrchat-worlds/meta-tcp_window/meta-tcp_window.csv --norm token token --model bigru bigru
[2025-07-26 00:52:10,463] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv', 'vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=2000, importance=False, kfold=5, model=['bigru', 'bigru'], norm=['token', 'token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/vrchat-worlds/train/train_meta_1753491128.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753491128.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'))
[2025-07-26 00:52:52,214] [INFO] Processed data from vrchat-worlds/meta-ip_len/meta-ip_len.csv:
[2025-07-26 00:52:52,214] [INFO] (15228, 2000)
[2025-07-26 00:52:52,214] [INFO] [['244' '141' '52' ... '1432' '1432' '1432']
 ['60' '60' '52' ... '52' '242' '143']
 ['1432' '1432' '1432' ... '1432' '1432' '1432']
 ...
 ['52' '1432' '1432' ... '76' '52' '52']
 ['1432' '340' '52' ... '76' '52' '52']
 ['52' '52' '1432' ... '52' '60' '60']]
[2025-07-26 00:53:37,102] [INFO] Processed data from vrchat-worlds/meta-tcp_window/meta-tcp_window.csv:
[2025-07-26 00:53:37,102] [INFO] (15228, 2000)
[2025-07-26 00:53:37,102] [INFO] [['1281' '1281' '580' ... '300' '300' '300']
 ['65535' '65535' '256' ... '774' '2566' '2566']
 ['2038' '2038' '2038' ... '289' '289' '300']
 ...
 ['265' '774' '774' ... '268' '268' '310']
 ['265' '265' '332' ... '282' '282' '310']
 ['343' '761' '300' ... '774' '65535' '65535']]
[2025-07-26 00:53:37,213] [INFO] Training Fold 1/5
[2025-07-26 00:54:12,455] [INFO] Feature 0 normalized using token
[2025-07-26 00:54:12,455] [INFO] Train shape: (10659, 2000), Val shape: (1523, 2000), Test shape: (3046, 2000)
[2025-07-26 00:54:47,696] [INFO] Feature 1 normalized using token
[2025-07-26 00:54:47,696] [INFO] Train shape: (10659, 2000), Val shape: (1523, 2000), Test shape: (3046, 2000)
[2025-07-26 00:54:47,809] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
    (1): Embedding(5717, 512)
  )
  (rnn_layers): ModuleList(
    (0-1): 2 x GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0-1): 2 x Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-26 00:54:47,809] [INFO] Training...
[2025-07-26 00:56:12,769] [INFO] Epoch 1/50, ValAcc: 49.70%, TrainLoss: 2.9420, ValLoss: 1.8607, LR: 0.001
[2025-07-26 00:57:36,670] [INFO] Epoch 2/50, ValAcc: 69.34%, TrainLoss: 1.4792, ValLoss: 1.0593, LR: 0.001
[2025-07-26 00:59:00,815] [INFO] Epoch 3/50, ValAcc: 80.24%, TrainLoss: 0.8706, ValLoss: 0.7216, LR: 0.001
[2025-07-26 01:00:24,838] [INFO] Epoch 4/50, ValAcc: 83.52%, TrainLoss: 0.5808, ValLoss: 0.5886, LR: 0.001
[2025-07-26 01:01:49,025] [INFO] Epoch 5/50, ValAcc: 84.04%, TrainLoss: 0.4143, ValLoss: 0.6170, LR: 0.001
[2025-07-26 01:03:13,296] [INFO] Epoch 6/50, ValAcc: 86.54%, TrainLoss: 0.3139, ValLoss: 0.5754, LR: 0.001
[2025-07-26 01:04:37,363] [INFO] Epoch 7/50, ValAcc: 86.41%, TrainLoss: 0.2550, ValLoss: 0.6436, LR: 0.001
[2025-07-26 01:06:01,133] [INFO] Epoch 8/50, ValAcc: 84.90%, TrainLoss: 0.2255, ValLoss: 0.7074, LR: 0.001
[2025-07-26 01:07:24,944] [INFO] Epoch 9/50, ValAcc: 87.72%, TrainLoss: 0.1771, ValLoss: 0.6155, LR: 0.001
[2025-07-26 01:08:48,756] [INFO] Epoch 10/50, ValAcc: 89.63%, TrainLoss: 0.0815, ValLoss: 0.6036, LR: 0.0005
[2025-07-26 01:10:12,817] [INFO] Epoch 11/50, ValAcc: 89.76%, TrainLoss: 0.0565, ValLoss: 0.6439, LR: 0.0005
[2025-07-26 01:11:36,844] [INFO] Epoch 12/50, ValAcc: 89.95%, TrainLoss: 0.0474, ValLoss: 0.6469, LR: 0.0005
[2025-07-26 01:13:00,848] [INFO] Epoch 13/50, ValAcc: 90.35%, TrainLoss: 0.0316, ValLoss: 0.6566, LR: 0.00025
[2025-07-26 01:14:24,829] [INFO] Epoch 14/50, ValAcc: 90.09%, TrainLoss: 0.0244, ValLoss: 0.7020, LR: 0.00025
[2025-07-26 01:15:48,645] [INFO] Epoch 15/50, ValAcc: 90.28%, TrainLoss: 0.0245, ValLoss: 0.7176, LR: 0.00025
[2025-07-26 01:17:12,437] [INFO] Epoch 16/50, ValAcc: 90.35%, TrainLoss: 0.0216, ValLoss: 0.7166, LR: 0.000125
[2025-07-26 01:18:36,352] [INFO] Epoch 17/50, ValAcc: 90.28%, TrainLoss: 0.0202, ValLoss: 0.7265, LR: 0.000125
[2025-07-26 01:20:00,198] [INFO] Epoch 18/50, ValAcc: 90.28%, TrainLoss: 0.0169, ValLoss: 0.7283, LR: 0.000125
[2025-07-26 01:21:24,012] [INFO] Epoch 19/50, ValAcc: 90.35%, TrainLoss: 0.0154, ValLoss: 0.7364, LR: 6.25e-05
[2025-07-26 01:21:24,012] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-26 01:21:31,972] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv', 'vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=2000, importance=False, kfold=5, model=['bigru', 'bigru'], norm=['token', 'token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/vrchat-worlds/train/train_meta_1753491128.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753491128.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen-tcpwindow_token-token_bigru-bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.9012,0.8990,0.8997,0.9000
[2025-07-26 01:21:31,973] [INFO] Training Fold 2/5
[2025-07-26 01:22:07,142] [INFO] Feature 0 normalized using token
[2025-07-26 01:22:07,143] [INFO] Train shape: (10659, 2000), Val shape: (1523, 2000), Test shape: (3046, 2000)
[2025-07-26 01:22:42,094] [INFO] Feature 1 normalized using token
[2025-07-26 01:22:42,094] [INFO] Train shape: (10659, 2000), Val shape: (1523, 2000), Test shape: (3046, 2000)
[2025-07-26 01:22:42,201] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
    (1): Embedding(5660, 512)
  )
  (rnn_layers): ModuleList(
    (0-1): 2 x GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0-1): 2 x Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-26 01:22:42,201] [INFO] Training...
[2025-07-26 01:24:05,857] [INFO] Epoch 1/50, ValAcc: 53.45%, TrainLoss: 2.8129, ValLoss: 1.6767, LR: 0.001
[2025-07-26 01:25:29,458] [INFO] Epoch 2/50, ValAcc: 73.74%, TrainLoss: 1.2796, ValLoss: 0.9831, LR: 0.001
[2025-07-26 01:26:53,141] [INFO] Epoch 3/50, ValAcc: 78.86%, TrainLoss: 0.7581, ValLoss: 0.7379, LR: 0.001
[2025-07-26 01:28:16,829] [INFO] Epoch 4/50, ValAcc: 82.73%, TrainLoss: 0.5059, ValLoss: 0.6418, LR: 0.001
[2025-07-26 01:29:40,657] [INFO] Epoch 5/50, ValAcc: 82.60%, TrainLoss: 0.3648, ValLoss: 0.7082, LR: 0.001
[2025-07-26 01:31:04,507] [INFO] Epoch 6/50, ValAcc: 84.90%, TrainLoss: 0.2840, ValLoss: 0.6555, LR: 0.001
[2025-07-26 01:32:28,403] [INFO] Epoch 7/50, ValAcc: 85.23%, TrainLoss: 0.2188, ValLoss: 0.6798, LR: 0.001
[2025-07-26 01:33:52,335] [INFO] Epoch 8/50, ValAcc: 87.07%, TrainLoss: 0.1369, ValLoss: 0.5924, LR: 0.0005
[2025-07-26 01:35:16,256] [INFO] Epoch 9/50, ValAcc: 87.00%, TrainLoss: 0.0767, ValLoss: 0.6352, LR: 0.0005
[2025-07-26 01:36:40,191] [INFO] Epoch 10/50, ValAcc: 87.79%, TrainLoss: 0.0574, ValLoss: 0.6581, LR: 0.0005
[2025-07-26 01:38:04,125] [INFO] Epoch 11/50, ValAcc: 87.20%, TrainLoss: 0.0494, ValLoss: 0.7279, LR: 0.0005
[2025-07-26 01:39:27,976] [INFO] Epoch 12/50, ValAcc: 87.39%, TrainLoss: 0.0372, ValLoss: 0.6918, LR: 0.00025
[2025-07-26 01:40:51,918] [INFO] Epoch 13/50, ValAcc: 87.92%, TrainLoss: 0.0291, ValLoss: 0.7143, LR: 0.00025
[2025-07-26 01:42:15,851] [INFO] Epoch 14/50, ValAcc: 87.79%, TrainLoss: 0.0234, ValLoss: 0.7258, LR: 0.00025
[2025-07-26 01:43:39,779] [INFO] Epoch 15/50, ValAcc: 87.66%, TrainLoss: 0.0214, ValLoss: 0.7326, LR: 0.000125
[2025-07-26 01:45:03,763] [INFO] Epoch 16/50, ValAcc: 87.46%, TrainLoss: 0.0192, ValLoss: 0.7522, LR: 0.000125
[2025-07-26 01:46:27,727] [INFO] Epoch 17/50, ValAcc: 87.33%, TrainLoss: 0.0166, ValLoss: 0.7800, LR: 0.000125
[2025-07-26 01:47:51,665] [INFO] Epoch 18/50, ValAcc: 87.46%, TrainLoss: 0.0159, ValLoss: 0.7739, LR: 6.25e-05
[2025-07-26 01:47:51,666] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-26 01:47:59,672] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv', 'vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=2000, importance=False, kfold=5, model=['bigru', 'bigru'], norm=['token', 'token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/vrchat-worlds/train/train_meta_1753491128.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753491128.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen-tcpwindow_token-token_bigru-bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.8743,0.8767,0.8769,0.8791
[2025-07-26 01:47:59,673] [INFO] Training Fold 3/5
[2025-07-26 01:48:34,193] [INFO] Feature 0 normalized using token
[2025-07-26 01:48:34,193] [INFO] Train shape: (10659, 2000), Val shape: (1523, 2000), Test shape: (3046, 2000)
[2025-07-26 01:49:08,557] [INFO] Feature 1 normalized using token
[2025-07-26 01:49:08,557] [INFO] Train shape: (10659, 2000), Val shape: (1523, 2000), Test shape: (3046, 2000)
[2025-07-26 01:49:08,664] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
    (1): Embedding(5654, 512)
  )
  (rnn_layers): ModuleList(
    (0-1): 2 x GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0-1): 2 x Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-26 01:49:08,665] [INFO] Training...
[2025-07-26 01:50:32,576] [INFO] Epoch 1/50, ValAcc: 57.85%, TrainLoss: 2.8345, ValLoss: 1.6347, LR: 0.001
[2025-07-26 01:51:56,452] [INFO] Epoch 2/50, ValAcc: 74.98%, TrainLoss: 1.2889, ValLoss: 0.8824, LR: 0.001
[2025-07-26 01:53:20,327] [INFO] Epoch 3/50, ValAcc: 80.70%, TrainLoss: 0.7137, ValLoss: 0.6795, LR: 0.001
[2025-07-26 01:54:44,120] [INFO] Epoch 4/50, ValAcc: 83.39%, TrainLoss: 0.5078, ValLoss: 0.6178, LR: 0.001
[2025-07-26 01:56:08,053] [INFO] Epoch 5/50, ValAcc: 85.29%, TrainLoss: 0.3734, ValLoss: 0.6322, LR: 0.001
[2025-07-26 01:57:31,985] [INFO] Epoch 6/50, ValAcc: 86.08%, TrainLoss: 0.2900, ValLoss: 0.5821, LR: 0.001
[2025-07-26 01:58:55,862] [INFO] Epoch 7/50, ValAcc: 86.34%, TrainLoss: 0.2304, ValLoss: 0.6343, LR: 0.001
[2025-07-26 02:00:19,709] [INFO] Epoch 8/50, ValAcc: 86.08%, TrainLoss: 0.1847, ValLoss: 0.6887, LR: 0.001
[2025-07-26 02:01:43,539] [INFO] Epoch 9/50, ValAcc: 86.67%, TrainLoss: 0.1601, ValLoss: 0.6487, LR: 0.001
[2025-07-26 02:03:07,389] [INFO] Epoch 10/50, ValAcc: 88.51%, TrainLoss: 0.0821, ValLoss: 0.5843, LR: 0.0005
[2025-07-26 02:04:31,293] [INFO] Epoch 11/50, ValAcc: 89.10%, TrainLoss: 0.0530, ValLoss: 0.6180, LR: 0.0005
[2025-07-26 02:05:55,135] [INFO] Epoch 12/50, ValAcc: 89.30%, TrainLoss: 0.0418, ValLoss: 0.6023, LR: 0.0005
[2025-07-26 02:07:19,007] [INFO] Epoch 13/50, ValAcc: 88.90%, TrainLoss: 0.0313, ValLoss: 0.6424, LR: 0.00025
[2025-07-26 02:08:42,849] [INFO] Epoch 14/50, ValAcc: 89.69%, TrainLoss: 0.0256, ValLoss: 0.6545, LR: 0.00025
[2025-07-26 02:10:06,694] [INFO] Epoch 15/50, ValAcc: 89.17%, TrainLoss: 0.0242, ValLoss: 0.6655, LR: 0.00025
[2025-07-26 02:11:30,548] [INFO] Epoch 16/50, ValAcc: 89.30%, TrainLoss: 0.0215, ValLoss: 0.6697, LR: 0.000125
[2025-07-26 02:12:54,419] [INFO] Epoch 17/50, ValAcc: 89.69%, TrainLoss: 0.0200, ValLoss: 0.6811, LR: 0.000125
[2025-07-26 02:14:18,291] [INFO] Epoch 18/50, ValAcc: 89.43%, TrainLoss: 0.0188, ValLoss: 0.6887, LR: 0.000125
[2025-07-26 02:15:42,094] [INFO] Epoch 19/50, ValAcc: 89.17%, TrainLoss: 0.0181, ValLoss: 0.6972, LR: 6.25e-05
[2025-07-26 02:15:42,095] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-26 02:15:50,083] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv', 'vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=2000, importance=False, kfold=5, model=['bigru', 'bigru'], norm=['token', 'token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/vrchat-worlds/train/train_meta_1753491128.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753491128.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen-tcpwindow_token-token_bigru-bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.9018,0.9023,0.9049,0.9023
[2025-07-26 02:15:50,084] [INFO] Training Fold 4/5
[2025-07-26 02:16:24,754] [INFO] Feature 0 normalized using token
[2025-07-26 02:16:24,754] [INFO] Train shape: (10660, 2000), Val shape: (1523, 2000), Test shape: (3045, 2000)
[2025-07-26 02:16:59,228] [INFO] Feature 1 normalized using token
[2025-07-26 02:16:59,229] [INFO] Train shape: (10660, 2000), Val shape: (1523, 2000), Test shape: (3045, 2000)
[2025-07-26 02:16:59,337] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
    (1): Embedding(5720, 512)
  )
  (rnn_layers): ModuleList(
    (0-1): 2 x GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0-1): 2 x Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-26 02:16:59,337] [INFO] Training...
[2025-07-26 02:18:23,003] [INFO] Epoch 1/50, ValAcc: 57.39%, TrainLoss: 2.8367, ValLoss: 1.6396, LR: 0.001
[2025-07-26 02:19:46,842] [INFO] Epoch 2/50, ValAcc: 73.67%, TrainLoss: 1.3471, ValLoss: 0.9435, LR: 0.001
[2025-07-26 02:21:10,587] [INFO] Epoch 3/50, ValAcc: 79.91%, TrainLoss: 0.7743, ValLoss: 0.7020, LR: 0.001
[2025-07-26 02:22:34,350] [INFO] Epoch 4/50, ValAcc: 81.94%, TrainLoss: 0.5203, ValLoss: 0.6526, LR: 0.001
[2025-07-26 02:23:58,244] [INFO] Epoch 5/50, ValAcc: 83.39%, TrainLoss: 0.3739, ValLoss: 0.7154, LR: 0.001
[2025-07-26 02:25:21,960] [INFO] Epoch 6/50, ValAcc: 85.55%, TrainLoss: 0.3019, ValLoss: 0.6878, LR: 0.001
[2025-07-26 02:26:45,818] [INFO] Epoch 7/50, ValAcc: 85.69%, TrainLoss: 0.2378, ValLoss: 0.6918, LR: 0.001
[2025-07-26 02:28:09,726] [INFO] Epoch 8/50, ValAcc: 88.12%, TrainLoss: 0.1206, ValLoss: 0.6263, LR: 0.0005
[2025-07-26 02:29:33,671] [INFO] Epoch 9/50, ValAcc: 88.90%, TrainLoss: 0.0798, ValLoss: 0.6589, LR: 0.0005
[2025-07-26 02:30:57,608] [INFO] Epoch 10/50, ValAcc: 88.31%, TrainLoss: 0.0608, ValLoss: 0.7115, LR: 0.0005
[2025-07-26 02:32:21,387] [INFO] Epoch 11/50, ValAcc: 89.17%, TrainLoss: 0.0548, ValLoss: 0.6974, LR: 0.0005
[2025-07-26 02:33:45,107] [INFO] Epoch 12/50, ValAcc: 89.76%, TrainLoss: 0.0405, ValLoss: 0.7021, LR: 0.00025
[2025-07-26 02:35:08,794] [INFO] Epoch 13/50, ValAcc: 89.69%, TrainLoss: 0.0339, ValLoss: 0.7425, LR: 0.00025
[2025-07-26 02:36:32,485] [INFO] Epoch 14/50, ValAcc: 89.36%, TrainLoss: 0.0294, ValLoss: 0.7583, LR: 0.00025
[2025-07-26 02:37:56,180] [INFO] Epoch 15/50, ValAcc: 89.49%, TrainLoss: 0.0255, ValLoss: 0.7727, LR: 0.000125
[2025-07-26 02:39:19,894] [INFO] Epoch 16/50, ValAcc: 89.23%, TrainLoss: 0.0251, ValLoss: 0.7689, LR: 0.000125
[2025-07-26 02:40:43,580] [INFO] Epoch 17/50, ValAcc: 89.17%, TrainLoss: 0.0245, ValLoss: 0.7795, LR: 0.000125
[2025-07-26 02:42:07,333] [INFO] Epoch 18/50, ValAcc: 89.10%, TrainLoss: 0.0220, ValLoss: 0.7830, LR: 6.25e-05
[2025-07-26 02:42:07,334] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-26 02:42:15,330] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv', 'vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=2000, importance=False, kfold=5, model=['bigru', 'bigru'], norm=['token', 'token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/vrchat-worlds/train/train_meta_1753491128.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753491128.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen-tcpwindow_token-token_bigru-bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.9064,0.9046,0.9053,0.9061
[2025-07-26 02:42:15,331] [INFO] Training Fold 5/5
[2025-07-26 02:42:49,843] [INFO] Feature 0 normalized using token
[2025-07-26 02:42:49,843] [INFO] Train shape: (10660, 2000), Val shape: (1523, 2000), Test shape: (3045, 2000)
[2025-07-26 02:43:24,402] [INFO] Feature 1 normalized using token
[2025-07-26 02:43:24,402] [INFO] Train shape: (10660, 2000), Val shape: (1523, 2000), Test shape: (3045, 2000)
[2025-07-26 02:43:24,509] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
    (1): Embedding(5707, 512)
  )
  (rnn_layers): ModuleList(
    (0-1): 2 x GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0-1): 2 x Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-26 02:43:24,509] [INFO] Training...
[2025-07-26 02:44:48,509] [INFO] Epoch 1/50, ValAcc: 57.45%, TrainLoss: 2.7940, ValLoss: 1.6371, LR: 0.001
[2025-07-26 02:46:12,362] [INFO] Epoch 2/50, ValAcc: 73.08%, TrainLoss: 1.3115, ValLoss: 0.9457, LR: 0.001
[2025-07-26 02:47:36,252] [INFO] Epoch 3/50, ValAcc: 77.81%, TrainLoss: 0.7839, ValLoss: 0.7746, LR: 0.001
[2025-07-26 02:49:00,133] [INFO] Epoch 4/50, ValAcc: 82.07%, TrainLoss: 0.5336, ValLoss: 0.6655, LR: 0.001
[2025-07-26 02:50:24,006] [INFO] Epoch 5/50, ValAcc: 83.65%, TrainLoss: 0.3839, ValLoss: 0.6104, LR: 0.001
[2025-07-26 02:51:47,848] [INFO] Epoch 6/50, ValAcc: 84.83%, TrainLoss: 0.3180, ValLoss: 0.6575, LR: 0.001
[2025-07-26 02:53:11,752] [INFO] Epoch 7/50, ValAcc: 85.03%, TrainLoss: 0.2323, ValLoss: 0.6356, LR: 0.001
[2025-07-26 02:54:35,570] [INFO] Epoch 8/50, ValAcc: 84.70%, TrainLoss: 0.1767, ValLoss: 0.7125, LR: 0.001
[2025-07-26 02:55:59,412] [INFO] Epoch 9/50, ValAcc: 86.93%, TrainLoss: 0.0979, ValLoss: 0.6666, LR: 0.0005
[2025-07-26 02:57:23,259] [INFO] Epoch 10/50, ValAcc: 87.85%, TrainLoss: 0.0662, ValLoss: 0.6866, LR: 0.0005
[2025-07-26 02:58:47,083] [INFO] Epoch 11/50, ValAcc: 88.31%, TrainLoss: 0.0504, ValLoss: 0.7206, LR: 0.0005
[2025-07-26 03:00:10,911] [INFO] Epoch 12/50, ValAcc: 88.05%, TrainLoss: 0.0393, ValLoss: 0.7205, LR: 0.00025
[2025-07-26 03:01:34,701] [INFO] Epoch 13/50, ValAcc: 87.92%, TrainLoss: 0.0308, ValLoss: 0.7311, LR: 0.00025
[2025-07-26 03:02:58,564] [INFO] Epoch 14/50, ValAcc: 88.44%, TrainLoss: 0.0282, ValLoss: 0.7485, LR: 0.00025
[2025-07-26 03:04:22,351] [INFO] Epoch 15/50, ValAcc: 88.84%, TrainLoss: 0.0258, ValLoss: 0.7587, LR: 0.000125
[2025-07-26 03:05:46,258] [INFO] Epoch 16/50, ValAcc: 88.38%, TrainLoss: 0.0242, ValLoss: 0.7762, LR: 0.000125
[2025-07-26 03:07:10,029] [INFO] Epoch 17/50, ValAcc: 88.44%, TrainLoss: 0.0226, ValLoss: 0.7980, LR: 0.000125
[2025-07-26 03:08:33,851] [INFO] Epoch 18/50, ValAcc: 88.58%, TrainLoss: 0.0202, ValLoss: 0.7940, LR: 6.25e-05
[2025-07-26 03:08:33,851] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-26 03:08:41,860] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv', 'vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=2000, importance=False, kfold=5, model=['bigru', 'bigru'], norm=['token', 'token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/vrchat-worlds/train/train_meta_1753491128.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753491128.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen-tcpwindow_token-token_bigru-bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.8966,0.8956,0.8983,0.8955
[2025-07-26 03:08:42,930] [INFO] [(0.9011818778726198, 0.8990187179434621, 0.8996623461182521, 0.8999561365546579), (0.8742613263296126, 0.8766932443873405, 0.8769311381186526, 0.8791192778156618), (0.9018384766907419, 0.9023048450432323, 0.9048865552200712, 0.9022527266585014), (0.9064039408866995, 0.9045710831727058, 0.9052884542075637, 0.9060629046967867), (0.896551724137931, 0.8956303496128879, 0.8982876362704962, 0.8955471928340647)]
=== Step4. Script Execution Finished at Sat Jul 26 03:08:44 AM UTC 2025 ===
