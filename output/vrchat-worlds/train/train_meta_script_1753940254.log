=== Step4. Script Execution Started at Thu Jul 31 05:37:34 AM UTC 2025 ===
Base directory: vrchat-worlds
Data prefix: meta
Output directory: output/vrchat-worlds/train
[INFO] ip_len â†’ norm: token, model: bigru
Running python vrscanner.py --train --debug_path output/vrchat-worlds/train/train_meta_1753940254.debug --leaderboard_path output/vrchat-worlds/train/train_meta_1753940254.csv --kfold 5 --pktcount 1000 --input_dim 512 --hidden_size 256 --num_layers 3 --dropout 0.3 --fusion_dim 256 --fc_hidden_size 128 --epoch 50 --lr 0.001 --strict --path vrchat-worlds/meta-ip_len/meta-ip_len.csv --norm token --model bigru
[2025-07-31 05:37:36,144] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv'], pktcount=1000, kfold=5, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753940254.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753940254.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'))
[2025-07-31 05:38:06,731] [INFO] Processed data from vrchat-worlds/meta-ip_len/meta-ip_len.csv:
[2025-07-31 05:38:06,731] [INFO] (15228, 1000)
[2025-07-31 05:38:06,731] [INFO] [['244' '141' '52' ... '52' '52' '100']
 ['60' '60' '52' ... '52' '52' '1432']
 ['1432' '1432' '1432' ... '52' '930' '76']
 ...
 ['52' '1432' '1432' ... '1432' '1432' '1432']
 ['1432' '340' '52' ... '1432' '1432' '1432']
 ['52' '52' '1432' ... '52' '254' '235']]
[2025-07-31 05:38:06,780] [INFO] Training Fold 1/5
[2025-07-31 05:38:18,453] [INFO] Feature 0 normalized using token
[2025-07-31 05:38:18,453] [INFO] Train shape: (10659, 1000), Val shape: (1523, 1000), Test shape: (3046, 1000)
[2025-07-31 05:38:18,507] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-31 05:38:18,507] [INFO] Training...
[2025-07-31 05:38:38,170] [INFO] Epoch 1/50, ValAcc: 20.42%, TrainLoss: 3.5269, ValLoss: 2.8748, LR: 0.001
[2025-07-31 05:38:56,647] [INFO] Epoch 2/50, ValAcc: 44.78%, TrainLoss: 2.4741, ValLoss: 1.7725, LR: 0.001
[2025-07-31 05:39:15,127] [INFO] Epoch 3/50, ValAcc: 65.92%, TrainLoss: 1.5542, ValLoss: 1.1199, LR: 0.001
[2025-07-31 05:39:33,600] [INFO] Epoch 4/50, ValAcc: 71.70%, TrainLoss: 0.9951, ValLoss: 0.8415, LR: 0.001
[2025-07-31 05:39:52,078] [INFO] Epoch 5/50, ValAcc: 75.25%, TrainLoss: 0.7285, ValLoss: 0.7325, LR: 0.001
[2025-07-31 05:40:10,556] [INFO] Epoch 6/50, ValAcc: 78.53%, TrainLoss: 0.5754, ValLoss: 0.6768, LR: 0.001
[2025-07-31 05:40:29,030] [INFO] Epoch 7/50, ValAcc: 78.27%, TrainLoss: 0.4558, ValLoss: 0.6868, LR: 0.001
[2025-07-31 05:40:47,497] [INFO] Epoch 8/50, ValAcc: 79.45%, TrainLoss: 0.3993, ValLoss: 0.7814, LR: 0.001
[2025-07-31 05:41:05,968] [INFO] Epoch 9/50, ValAcc: 79.71%, TrainLoss: 0.3493, ValLoss: 0.6990, LR: 0.001
[2025-07-31 05:41:24,450] [INFO] Epoch 10/50, ValAcc: 82.21%, TrainLoss: 0.2062, ValLoss: 0.6757, LR: 0.0005
[2025-07-31 05:41:42,910] [INFO] Epoch 11/50, ValAcc: 82.21%, TrainLoss: 0.1446, ValLoss: 0.7517, LR: 0.0005
[2025-07-31 05:42:01,384] [INFO] Epoch 12/50, ValAcc: 82.01%, TrainLoss: 0.1193, ValLoss: 0.7723, LR: 0.0005
[2025-07-31 05:42:19,859] [INFO] Epoch 13/50, ValAcc: 82.40%, TrainLoss: 0.1059, ValLoss: 0.8214, LR: 0.0005
[2025-07-31 05:42:38,307] [INFO] Epoch 14/50, ValAcc: 82.53%, TrainLoss: 0.0783, ValLoss: 0.8400, LR: 0.00025
[2025-07-31 05:42:56,767] [INFO] Epoch 15/50, ValAcc: 82.67%, TrainLoss: 0.0652, ValLoss: 0.8575, LR: 0.00025
[2025-07-31 05:43:15,213] [INFO] Epoch 16/50, ValAcc: 82.07%, TrainLoss: 0.0585, ValLoss: 0.9184, LR: 0.00025
[2025-07-31 05:43:33,657] [INFO] Epoch 17/50, ValAcc: 82.80%, TrainLoss: 0.0537, ValLoss: 0.8894, LR: 0.000125
[2025-07-31 05:43:52,102] [INFO] Epoch 18/50, ValAcc: 82.40%, TrainLoss: 0.0502, ValLoss: 0.9181, LR: 0.000125
[2025-07-31 05:44:10,549] [INFO] Epoch 19/50, ValAcc: 82.99%, TrainLoss: 0.0453, ValLoss: 0.9341, LR: 0.000125
[2025-07-31 05:44:28,986] [INFO] Epoch 20/50, ValAcc: 82.93%, TrainLoss: 0.0445, ValLoss: 0.9392, LR: 6.25e-05
[2025-07-31 05:44:28,987] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-31 05:44:31,825] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv'], pktcount=1000, kfold=5, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753940254.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753940254.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_1000_64_50_0.001_512_256_3_0.3_256_128'),0.8355,0.8318,0.8348,0.8336
[2025-07-31 05:44:31,826] [INFO] Training Fold 2/5
[2025-07-31 05:44:43,506] [INFO] Feature 0 normalized using token
[2025-07-31 05:44:43,506] [INFO] Train shape: (10659, 1000), Val shape: (1523, 1000), Test shape: (3046, 1000)
[2025-07-31 05:44:43,535] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-31 05:44:43,535] [INFO] Training...
[2025-07-31 05:45:02,005] [INFO] Epoch 1/50, ValAcc: 17.01%, TrainLoss: 3.5684, ValLoss: 2.9467, LR: 0.001
[2025-07-31 05:45:20,472] [INFO] Epoch 2/50, ValAcc: 49.90%, TrainLoss: 2.4206, ValLoss: 1.6801, LR: 0.001
[2025-07-31 05:45:38,941] [INFO] Epoch 3/50, ValAcc: 65.20%, TrainLoss: 1.4409, ValLoss: 1.0650, LR: 0.001
[2025-07-31 05:45:57,408] [INFO] Epoch 4/50, ValAcc: 74.33%, TrainLoss: 0.9421, ValLoss: 0.8283, LR: 0.001
[2025-07-31 05:46:15,869] [INFO] Epoch 5/50, ValAcc: 76.43%, TrainLoss: 0.6941, ValLoss: 0.7560, LR: 0.001
[2025-07-31 05:46:34,333] [INFO] Epoch 6/50, ValAcc: 78.14%, TrainLoss: 0.5709, ValLoss: 0.7268, LR: 0.001
[2025-07-31 05:46:52,795] [INFO] Epoch 7/50, ValAcc: 78.59%, TrainLoss: 0.4567, ValLoss: 0.6723, LR: 0.001
[2025-07-31 05:47:11,152] [INFO] Epoch 8/50, ValAcc: 79.84%, TrainLoss: 0.3926, ValLoss: 0.7029, LR: 0.001
[2025-07-31 05:47:29,457] [INFO] Epoch 9/50, ValAcc: 81.16%, TrainLoss: 0.3292, ValLoss: 0.6873, LR: 0.001
[2025-07-31 05:47:47,747] [INFO] Epoch 10/50, ValAcc: 79.19%, TrainLoss: 0.2705, ValLoss: 0.8314, LR: 0.001
[2025-07-31 05:48:06,044] [INFO] Epoch 11/50, ValAcc: 81.75%, TrainLoss: 0.1690, ValLoss: 0.7548, LR: 0.0005
[2025-07-31 05:48:24,357] [INFO] Epoch 12/50, ValAcc: 80.56%, TrainLoss: 0.1095, ValLoss: 0.8374, LR: 0.0005
[2025-07-31 05:48:42,681] [INFO] Epoch 13/50, ValAcc: 81.62%, TrainLoss: 0.0981, ValLoss: 0.8860, LR: 0.0005
[2025-07-31 05:49:00,992] [INFO] Epoch 14/50, ValAcc: 81.02%, TrainLoss: 0.0702, ValLoss: 0.8997, LR: 0.00025
[2025-07-31 05:49:19,306] [INFO] Epoch 15/50, ValAcc: 81.94%, TrainLoss: 0.0552, ValLoss: 0.9366, LR: 0.00025
[2025-07-31 05:49:37,623] [INFO] Epoch 16/50, ValAcc: 81.55%, TrainLoss: 0.0477, ValLoss: 0.9639, LR: 0.00025
[2025-07-31 05:49:55,951] [INFO] Epoch 17/50, ValAcc: 81.81%, TrainLoss: 0.0426, ValLoss: 0.9829, LR: 0.000125
[2025-07-31 05:50:14,274] [INFO] Epoch 18/50, ValAcc: 81.16%, TrainLoss: 0.0383, ValLoss: 1.0152, LR: 0.000125
[2025-07-31 05:50:32,576] [INFO] Epoch 19/50, ValAcc: 81.16%, TrainLoss: 0.0361, ValLoss: 1.0361, LR: 0.000125
[2025-07-31 05:50:50,889] [INFO] Epoch 20/50, ValAcc: 81.35%, TrainLoss: 0.0336, ValLoss: 1.0326, LR: 6.25e-05
[2025-07-31 05:50:50,889] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-31 05:50:53,665] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv'], pktcount=1000, kfold=5, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753940254.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753940254.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_1000_64_50_0.001_512_256_3_0.3_256_128'),0.8191,0.8201,0.8217,0.8226
[2025-07-31 05:50:53,665] [INFO] Training Fold 3/5
[2025-07-31 05:51:05,059] [INFO] Feature 0 normalized using token
[2025-07-31 05:51:05,059] [INFO] Train shape: (10659, 1000), Val shape: (1523, 1000), Test shape: (3046, 1000)
[2025-07-31 05:51:05,085] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-31 05:51:05,085] [INFO] Training...
[2025-07-31 05:51:23,416] [INFO] Epoch 1/50, ValAcc: 18.58%, TrainLoss: 3.5426, ValLoss: 2.8875, LR: 0.001
[2025-07-31 05:51:41,734] [INFO] Epoch 2/50, ValAcc: 49.51%, TrainLoss: 2.3566, ValLoss: 1.6568, LR: 0.001
[2025-07-31 05:52:00,042] [INFO] Epoch 3/50, ValAcc: 65.00%, TrainLoss: 1.3892, ValLoss: 1.0773, LR: 0.001
[2025-07-31 05:52:18,343] [INFO] Epoch 4/50, ValAcc: 70.78%, TrainLoss: 0.9369, ValLoss: 0.9023, LR: 0.001
[2025-07-31 05:52:36,665] [INFO] Epoch 5/50, ValAcc: 73.93%, TrainLoss: 0.7182, ValLoss: 0.7877, LR: 0.001
[2025-07-31 05:52:54,982] [INFO] Epoch 6/50, ValAcc: 76.89%, TrainLoss: 0.5877, ValLoss: 0.7168, LR: 0.001
[2025-07-31 05:53:13,305] [INFO] Epoch 7/50, ValAcc: 78.00%, TrainLoss: 0.4689, ValLoss: 0.6992, LR: 0.001
[2025-07-31 05:53:31,624] [INFO] Epoch 8/50, ValAcc: 78.92%, TrainLoss: 0.3895, ValLoss: 0.6626, LR: 0.001
[2025-07-31 05:53:49,945] [INFO] Epoch 9/50, ValAcc: 77.94%, TrainLoss: 0.3592, ValLoss: 0.7525, LR: 0.001
[2025-07-31 05:54:08,258] [INFO] Epoch 10/50, ValAcc: 78.00%, TrainLoss: 0.3009, ValLoss: 0.8090, LR: 0.001
[2025-07-31 05:54:26,570] [INFO] Epoch 11/50, ValAcc: 79.58%, TrainLoss: 0.2707, ValLoss: 0.7347, LR: 0.001
[2025-07-31 05:54:44,878] [INFO] Epoch 12/50, ValAcc: 81.62%, TrainLoss: 0.1650, ValLoss: 0.6920, LR: 0.0005
[2025-07-31 05:55:03,202] [INFO] Epoch 13/50, ValAcc: 82.99%, TrainLoss: 0.0995, ValLoss: 0.7984, LR: 0.0005
[2025-07-31 05:55:21,526] [INFO] Epoch 14/50, ValAcc: 82.99%, TrainLoss: 0.0859, ValLoss: 0.8357, LR: 0.0005
[2025-07-31 05:55:39,848] [INFO] Epoch 15/50, ValAcc: 83.19%, TrainLoss: 0.0661, ValLoss: 0.8178, LR: 0.00025
[2025-07-31 05:55:58,164] [INFO] Epoch 16/50, ValAcc: 83.45%, TrainLoss: 0.0531, ValLoss: 0.8265, LR: 0.00025
[2025-07-31 05:56:16,487] [INFO] Epoch 17/50, ValAcc: 83.26%, TrainLoss: 0.0492, ValLoss: 0.8430, LR: 0.00025
[2025-07-31 05:56:34,808] [INFO] Epoch 18/50, ValAcc: 83.45%, TrainLoss: 0.0430, ValLoss: 0.8719, LR: 0.000125
[2025-07-31 05:56:53,123] [INFO] Epoch 19/50, ValAcc: 83.72%, TrainLoss: 0.0403, ValLoss: 0.9020, LR: 0.000125
[2025-07-31 05:57:11,444] [INFO] Epoch 20/50, ValAcc: 83.45%, TrainLoss: 0.0384, ValLoss: 0.8825, LR: 0.000125
[2025-07-31 05:57:29,763] [INFO] Epoch 21/50, ValAcc: 83.72%, TrainLoss: 0.0377, ValLoss: 0.8946, LR: 6.25e-05
[2025-07-31 05:57:29,763] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-31 05:57:32,539] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv'], pktcount=1000, kfold=5, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753940254.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753940254.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_1000_64_50_0.001_512_256_3_0.3_256_128'),0.8175,0.8192,0.8243,0.8223
[2025-07-31 05:57:32,539] [INFO] Training Fold 4/5
[2025-07-31 05:57:43,548] [INFO] Feature 0 normalized using token
[2025-07-31 05:57:43,549] [INFO] Train shape: (10660, 1000), Val shape: (1523, 1000), Test shape: (3045, 1000)
[2025-07-31 05:57:43,573] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-31 05:57:43,574] [INFO] Training...
[2025-07-31 05:58:01,906] [INFO] Epoch 1/50, ValAcc: 19.04%, TrainLoss: 3.5929, ValLoss: 2.9540, LR: 0.001
[2025-07-31 05:58:20,230] [INFO] Epoch 2/50, ValAcc: 48.92%, TrainLoss: 2.4330, ValLoss: 1.7145, LR: 0.001
[2025-07-31 05:58:38,553] [INFO] Epoch 3/50, ValAcc: 66.19%, TrainLoss: 1.4239, ValLoss: 1.0468, LR: 0.001
[2025-07-31 05:58:56,873] [INFO] Epoch 4/50, ValAcc: 73.34%, TrainLoss: 0.9391, ValLoss: 0.8084, LR: 0.001
[2025-07-31 05:59:15,213] [INFO] Epoch 5/50, ValAcc: 74.66%, TrainLoss: 0.7112, ValLoss: 0.7256, LR: 0.001
[2025-07-31 05:59:33,547] [INFO] Epoch 6/50, ValAcc: 74.66%, TrainLoss: 0.5635, ValLoss: 0.7346, LR: 0.001
[2025-07-31 05:59:51,868] [INFO] Epoch 7/50, ValAcc: 76.69%, TrainLoss: 0.4801, ValLoss: 0.7378, LR: 0.001
[2025-07-31 06:00:10,187] [INFO] Epoch 8/50, ValAcc: 76.03%, TrainLoss: 0.3917, ValLoss: 0.8282, LR: 0.001
[2025-07-31 06:00:28,500] [INFO] Epoch 9/50, ValAcc: 78.99%, TrainLoss: 0.2419, ValLoss: 0.7118, LR: 0.0005
[2025-07-31 06:00:46,803] [INFO] Epoch 10/50, ValAcc: 78.20%, TrainLoss: 0.1796, ValLoss: 0.7745, LR: 0.0005
[2025-07-31 06:01:05,137] [INFO] Epoch 11/50, ValAcc: 78.27%, TrainLoss: 0.1458, ValLoss: 0.9091, LR: 0.0005
[2025-07-31 06:01:23,455] [INFO] Epoch 12/50, ValAcc: 78.59%, TrainLoss: 0.1264, ValLoss: 0.8769, LR: 0.0005
[2025-07-31 06:01:41,781] [INFO] Epoch 13/50, ValAcc: 79.84%, TrainLoss: 0.0940, ValLoss: 0.9076, LR: 0.00025
[2025-07-31 06:02:00,110] [INFO] Epoch 14/50, ValAcc: 80.04%, TrainLoss: 0.0757, ValLoss: 0.9150, LR: 0.00025
[2025-07-31 06:02:18,429] [INFO] Epoch 15/50, ValAcc: 80.37%, TrainLoss: 0.0657, ValLoss: 0.9490, LR: 0.00025
[2025-07-31 06:02:36,747] [INFO] Epoch 16/50, ValAcc: 80.24%, TrainLoss: 0.0567, ValLoss: 0.9586, LR: 0.000125
[2025-07-31 06:02:55,052] [INFO] Epoch 17/50, ValAcc: 79.51%, TrainLoss: 0.0530, ValLoss: 1.0001, LR: 0.000125
[2025-07-31 06:03:13,376] [INFO] Epoch 18/50, ValAcc: 80.63%, TrainLoss: 0.0502, ValLoss: 0.9890, LR: 0.000125
[2025-07-31 06:03:31,702] [INFO] Epoch 19/50, ValAcc: 80.30%, TrainLoss: 0.0451, ValLoss: 1.0133, LR: 6.25e-05
[2025-07-31 06:03:31,702] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-31 06:03:34,504] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv'], pktcount=1000, kfold=5, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753940254.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753940254.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_1000_64_50_0.001_512_256_3_0.3_256_128'),0.8240,0.8216,0.8233,0.8235
[2025-07-31 06:03:34,504] [INFO] Training Fold 5/5
[2025-07-31 06:03:45,701] [INFO] Feature 0 normalized using token
[2025-07-31 06:03:45,701] [INFO] Train shape: (10660, 1000), Val shape: (1523, 1000), Test shape: (3045, 1000)
[2025-07-31 06:03:45,730] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-31 06:03:45,730] [INFO] Training...
[2025-07-31 06:04:04,067] [INFO] Epoch 1/50, ValAcc: 20.81%, TrainLoss: 3.5766, ValLoss: 2.7956, LR: 0.001
[2025-07-31 06:04:22,488] [INFO] Epoch 2/50, ValAcc: 49.18%, TrainLoss: 2.3805, ValLoss: 1.7082, LR: 0.001
[2025-07-31 06:04:40,926] [INFO] Epoch 3/50, ValAcc: 68.02%, TrainLoss: 1.4691, ValLoss: 0.9926, LR: 0.001
[2025-07-31 06:04:59,366] [INFO] Epoch 4/50, ValAcc: 75.11%, TrainLoss: 0.9505, ValLoss: 0.7771, LR: 0.001
[2025-07-31 06:05:17,802] [INFO] Epoch 5/50, ValAcc: 77.94%, TrainLoss: 0.7010, ValLoss: 0.6604, LR: 0.001
[2025-07-31 06:05:36,230] [INFO] Epoch 6/50, ValAcc: 78.53%, TrainLoss: 0.5468, ValLoss: 0.6452, LR: 0.001
[2025-07-31 06:05:54,670] [INFO] Epoch 7/50, ValAcc: 76.76%, TrainLoss: 0.4558, ValLoss: 0.7201, LR: 0.001
[2025-07-31 06:06:13,113] [INFO] Epoch 8/50, ValAcc: 79.12%, TrainLoss: 0.3844, ValLoss: 0.6758, LR: 0.001
[2025-07-31 06:06:31,555] [INFO] Epoch 9/50, ValAcc: 80.11%, TrainLoss: 0.3444, ValLoss: 0.7049, LR: 0.001
[2025-07-31 06:06:49,993] [INFO] Epoch 10/50, ValAcc: 82.14%, TrainLoss: 0.2108, ValLoss: 0.6170, LR: 0.0005
[2025-07-31 06:07:08,430] [INFO] Epoch 11/50, ValAcc: 81.88%, TrainLoss: 0.1483, ValLoss: 0.6721, LR: 0.0005
[2025-07-31 06:07:26,874] [INFO] Epoch 12/50, ValAcc: 82.27%, TrainLoss: 0.1263, ValLoss: 0.7435, LR: 0.0005
[2025-07-31 06:07:45,322] [INFO] Epoch 13/50, ValAcc: 80.43%, TrainLoss: 0.1127, ValLoss: 0.7971, LR: 0.0005
[2025-07-31 06:08:03,751] [INFO] Epoch 14/50, ValAcc: 82.34%, TrainLoss: 0.0829, ValLoss: 0.7830, LR: 0.00025
[2025-07-31 06:08:22,167] [INFO] Epoch 15/50, ValAcc: 82.21%, TrainLoss: 0.0680, ValLoss: 0.7849, LR: 0.00025
[2025-07-31 06:08:40,589] [INFO] Epoch 16/50, ValAcc: 82.86%, TrainLoss: 0.0595, ValLoss: 0.8526, LR: 0.00025
[2025-07-31 06:08:59,016] [INFO] Epoch 17/50, ValAcc: 82.60%, TrainLoss: 0.0512, ValLoss: 0.8678, LR: 0.000125
[2025-07-31 06:09:17,431] [INFO] Epoch 18/50, ValAcc: 81.88%, TrainLoss: 0.0455, ValLoss: 0.8765, LR: 0.000125
[2025-07-31 06:09:35,854] [INFO] Epoch 19/50, ValAcc: 82.07%, TrainLoss: 0.0447, ValLoss: 0.8653, LR: 0.000125
[2025-07-31 06:09:54,288] [INFO] Epoch 20/50, ValAcc: 82.40%, TrainLoss: 0.0426, ValLoss: 0.8572, LR: 6.25e-05
[2025-07-31 06:09:54,288] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-31 06:09:57,106] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv'], pktcount=1000, kfold=5, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753940254.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753940254.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_1000_64_50_0.001_512_256_3_0.3_256_128'),0.8361,0.8350,0.8380,0.8346
[2025-07-31 06:09:57,256] [INFO] [(0.8355219960604071, 0.8318268223604541, 0.8347525337597979, 0.8335567283725541), (0.8191070256073539, 0.8201110650112973, 0.8217239585350626, 0.8226457760794825), (0.8174655285620486, 0.8191787887273211, 0.8242508247494321, 0.8223420613549629), (0.8239737274220033, 0.8216102058953222, 0.8233231029781396, 0.823525355863043), (0.8361247947454844, 0.8349602797549067, 0.8379667786140662, 0.8345616024095517)]
Running python vrscanner.py --train --debug_path output/vrchat-worlds/train/train_meta_1753942197.debug --leaderboard_path output/vrchat-worlds/train/train_meta_1753942197.csv --kfold 5 --pktcount 2000 --input_dim 512 --hidden_size 256 --num_layers 3 --dropout 0.3 --fusion_dim 256 --fc_hidden_size 128 --epoch 50 --lr 0.001 --strict --path vrchat-worlds/meta-ip_len/meta-ip_len.csv --norm token --model bigru
[2025-07-31 06:09:59,596] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv'], pktcount=2000, kfold=5, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753942197.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753942197.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'))
[2025-07-31 06:10:30,903] [INFO] Processed data from vrchat-worlds/meta-ip_len/meta-ip_len.csv:
[2025-07-31 06:10:30,903] [INFO] (15228, 2000)
[2025-07-31 06:10:30,903] [INFO] [['244' '141' '52' ... '1432' '1432' '1432']
 ['60' '60' '52' ... '52' '242' '143']
 ['1432' '1432' '1432' ... '1432' '1432' '1432']
 ...
 ['52' '1432' '1432' ... '76' '52' '52']
 ['1432' '340' '52' ... '76' '52' '52']
 ['52' '52' '1432' ... '52' '60' '60']]
[2025-07-31 06:10:31,015] [INFO] Training Fold 1/5
[2025-07-31 06:10:59,976] [INFO] Feature 0 normalized using token
[2025-07-31 06:10:59,977] [INFO] Train shape: (10659, 2000), Val shape: (1523, 2000), Test shape: (3046, 2000)
[2025-07-31 06:11:00,040] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-31 06:11:00,040] [INFO] Training...
[2025-07-31 06:11:37,131] [INFO] Epoch 1/50, ValAcc: 23.31%, TrainLoss: 3.5390, ValLoss: 2.8082, LR: 0.001
[2025-07-31 06:12:12,943] [INFO] Epoch 2/50, ValAcc: 43.01%, TrainLoss: 2.4695, ValLoss: 1.8124, LR: 0.001
[2025-07-31 06:12:48,748] [INFO] Epoch 3/50, ValAcc: 65.27%, TrainLoss: 1.5446, ValLoss: 1.0818, LR: 0.001
[2025-07-31 06:13:24,540] [INFO] Epoch 4/50, ValAcc: 71.70%, TrainLoss: 0.9979, ValLoss: 0.8379, LR: 0.001
[2025-07-31 06:14:00,323] [INFO] Epoch 5/50, ValAcc: 75.25%, TrainLoss: 0.7407, ValLoss: 0.7502, LR: 0.001
[2025-07-31 06:14:36,063] [INFO] Epoch 6/50, ValAcc: 77.15%, TrainLoss: 0.6052, ValLoss: 0.6871, LR: 0.001
[2025-07-31 06:15:11,786] [INFO] Epoch 7/50, ValAcc: 78.73%, TrainLoss: 0.4861, ValLoss: 0.6363, LR: 0.001
[2025-07-31 06:15:47,515] [INFO] Epoch 8/50, ValAcc: 79.05%, TrainLoss: 0.4117, ValLoss: 0.6839, LR: 0.001
[2025-07-31 06:16:23,257] [INFO] Epoch 9/50, ValAcc: 80.96%, TrainLoss: 0.3685, ValLoss: 0.6685, LR: 0.001
[2025-07-31 06:16:59,021] [INFO] Epoch 10/50, ValAcc: 80.76%, TrainLoss: 0.3446, ValLoss: 0.6346, LR: 0.001
[2025-07-31 06:17:34,802] [INFO] Epoch 11/50, ValAcc: 80.50%, TrainLoss: 0.2940, ValLoss: 0.7150, LR: 0.001
[2025-07-31 06:18:10,545] [INFO] Epoch 12/50, ValAcc: 80.04%, TrainLoss: 0.2636, ValLoss: 0.7128, LR: 0.001
[2025-07-31 06:18:46,283] [INFO] Epoch 13/50, ValAcc: 81.48%, TrainLoss: 0.2081, ValLoss: 0.7433, LR: 0.001
[2025-07-31 06:19:22,037] [INFO] Epoch 14/50, ValAcc: 83.52%, TrainLoss: 0.1257, ValLoss: 0.6846, LR: 0.0005
[2025-07-31 06:19:57,781] [INFO] Epoch 15/50, ValAcc: 84.18%, TrainLoss: 0.0858, ValLoss: 0.7278, LR: 0.0005
[2025-07-31 06:20:33,551] [INFO] Epoch 16/50, ValAcc: 83.98%, TrainLoss: 0.0718, ValLoss: 0.7722, LR: 0.0005
[2025-07-31 06:21:09,293] [INFO] Epoch 17/50, ValAcc: 84.57%, TrainLoss: 0.0555, ValLoss: 0.7421, LR: 0.00025
[2025-07-31 06:21:45,038] [INFO] Epoch 18/50, ValAcc: 84.24%, TrainLoss: 0.0458, ValLoss: 0.7610, LR: 0.00025
[2025-07-31 06:22:20,778] [INFO] Epoch 19/50, ValAcc: 85.49%, TrainLoss: 0.0399, ValLoss: 0.7860, LR: 0.00025
[2025-07-31 06:22:56,525] [INFO] Epoch 20/50, ValAcc: 85.42%, TrainLoss: 0.0343, ValLoss: 0.7733, LR: 0.000125
[2025-07-31 06:23:32,389] [INFO] Epoch 21/50, ValAcc: 85.55%, TrainLoss: 0.0305, ValLoss: 0.7771, LR: 0.000125
[2025-07-31 06:24:08,152] [INFO] Epoch 22/50, ValAcc: 84.83%, TrainLoss: 0.0289, ValLoss: 0.8040, LR: 0.000125
[2025-07-31 06:24:43,963] [INFO] Epoch 23/50, ValAcc: 85.10%, TrainLoss: 0.0265, ValLoss: 0.7981, LR: 6.25e-05
[2025-07-31 06:24:43,964] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-31 06:24:49,429] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv'], pktcount=2000, kfold=5, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753942197.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753942197.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.8539,0.8520,0.8562,0.8531
[2025-07-31 06:24:49,430] [INFO] Training Fold 2/5
[2025-07-31 06:25:18,683] [INFO] Feature 0 normalized using token
[2025-07-31 06:25:18,683] [INFO] Train shape: (10659, 2000), Val shape: (1523, 2000), Test shape: (3046, 2000)
[2025-07-31 06:25:18,721] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-31 06:25:18,721] [INFO] Training...
[2025-07-31 06:25:54,185] [INFO] Epoch 1/50, ValAcc: 17.73%, TrainLoss: 3.5833, ValLoss: 2.9605, LR: 0.001
[2025-07-31 06:26:29,942] [INFO] Epoch 2/50, ValAcc: 39.33%, TrainLoss: 2.5639, ValLoss: 1.9488, LR: 0.001
[2025-07-31 06:27:05,696] [INFO] Epoch 3/50, ValAcc: 64.02%, TrainLoss: 1.6417, ValLoss: 1.1386, LR: 0.001
[2025-07-31 06:27:41,429] [INFO] Epoch 4/50, ValAcc: 71.04%, TrainLoss: 1.0480, ValLoss: 0.8562, LR: 0.001
[2025-07-31 06:28:17,164] [INFO] Epoch 5/50, ValAcc: 76.03%, TrainLoss: 0.7565, ValLoss: 0.7065, LR: 0.001
[2025-07-31 06:28:52,892] [INFO] Epoch 6/50, ValAcc: 75.84%, TrainLoss: 0.6072, ValLoss: 0.7463, LR: 0.001
[2025-07-31 06:29:28,618] [INFO] Epoch 7/50, ValAcc: 79.71%, TrainLoss: 0.4849, ValLoss: 0.6430, LR: 0.001
[2025-07-31 06:30:04,341] [INFO] Epoch 8/50, ValAcc: 80.56%, TrainLoss: 0.4145, ValLoss: 0.6624, LR: 0.001
[2025-07-31 06:30:40,060] [INFO] Epoch 9/50, ValAcc: 80.56%, TrainLoss: 0.3483, ValLoss: 0.6888, LR: 0.001
[2025-07-31 06:31:15,776] [INFO] Epoch 10/50, ValAcc: 78.92%, TrainLoss: 0.3234, ValLoss: 0.7750, LR: 0.001
[2025-07-31 06:31:51,483] [INFO] Epoch 11/50, ValAcc: 82.86%, TrainLoss: 0.1958, ValLoss: 0.6319, LR: 0.0005
[2025-07-31 06:32:27,191] [INFO] Epoch 12/50, ValAcc: 83.72%, TrainLoss: 0.1296, ValLoss: 0.6576, LR: 0.0005
[2025-07-31 06:33:02,891] [INFO] Epoch 13/50, ValAcc: 83.59%, TrainLoss: 0.1023, ValLoss: 0.7232, LR: 0.0005
[2025-07-31 06:33:38,611] [INFO] Epoch 14/50, ValAcc: 83.26%, TrainLoss: 0.0847, ValLoss: 0.7541, LR: 0.0005
[2025-07-31 06:34:14,316] [INFO] Epoch 15/50, ValAcc: 83.98%, TrainLoss: 0.0652, ValLoss: 0.7512, LR: 0.00025
[2025-07-31 06:34:50,012] [INFO] Epoch 16/50, ValAcc: 83.19%, TrainLoss: 0.0517, ValLoss: 0.8149, LR: 0.00025
[2025-07-31 06:35:25,723] [INFO] Epoch 17/50, ValAcc: 84.24%, TrainLoss: 0.0448, ValLoss: 0.8379, LR: 0.00025
[2025-07-31 06:36:01,391] [INFO] Epoch 18/50, ValAcc: 84.44%, TrainLoss: 0.0350, ValLoss: 0.8404, LR: 0.000125
[2025-07-31 06:36:37,094] [INFO] Epoch 19/50, ValAcc: 84.31%, TrainLoss: 0.0359, ValLoss: 0.8469, LR: 0.000125
[2025-07-31 06:37:12,790] [INFO] Epoch 20/50, ValAcc: 84.70%, TrainLoss: 0.0297, ValLoss: 0.8546, LR: 0.000125
[2025-07-31 06:37:48,454] [INFO] Epoch 21/50, ValAcc: 84.64%, TrainLoss: 0.0270, ValLoss: 0.8510, LR: 6.25e-05
[2025-07-31 06:37:48,454] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-31 06:37:53,942] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv'], pktcount=2000, kfold=5, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753942197.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753942197.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.8260,0.8284,0.8309,0.8322
[2025-07-31 06:37:53,942] [INFO] Training Fold 3/5
[2025-07-31 06:38:20,899] [INFO] Feature 0 normalized using token
[2025-07-31 06:38:20,899] [INFO] Train shape: (10659, 2000), Val shape: (1523, 2000), Test shape: (3046, 2000)
[2025-07-31 06:38:20,940] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-31 06:38:20,940] [INFO] Training...
[2025-07-31 06:38:56,623] [INFO] Epoch 1/50, ValAcc: 20.81%, TrainLoss: 3.4785, ValLoss: 2.7762, LR: 0.001
[2025-07-31 06:39:32,288] [INFO] Epoch 2/50, ValAcc: 51.74%, TrainLoss: 2.2466, ValLoss: 1.5450, LR: 0.001
[2025-07-31 06:40:07,956] [INFO] Epoch 3/50, ValAcc: 67.10%, TrainLoss: 1.3429, ValLoss: 0.9907, LR: 0.001
[2025-07-31 06:40:43,629] [INFO] Epoch 4/50, ValAcc: 71.44%, TrainLoss: 0.9209, ValLoss: 0.8296, LR: 0.001
[2025-07-31 06:41:19,326] [INFO] Epoch 5/50, ValAcc: 75.57%, TrainLoss: 0.6881, ValLoss: 0.7136, LR: 0.001
[2025-07-31 06:41:55,035] [INFO] Epoch 6/50, ValAcc: 76.82%, TrainLoss: 0.5422, ValLoss: 0.7087, LR: 0.001
[2025-07-31 06:42:30,716] [INFO] Epoch 7/50, ValAcc: 76.56%, TrainLoss: 0.4618, ValLoss: 0.7041, LR: 0.001
[2025-07-31 06:43:06,409] [INFO] Epoch 8/50, ValAcc: 78.20%, TrainLoss: 0.3950, ValLoss: 0.6545, LR: 0.001
[2025-07-31 06:43:42,117] [INFO] Epoch 9/50, ValAcc: 80.83%, TrainLoss: 0.3405, ValLoss: 0.6817, LR: 0.001
[2025-07-31 06:44:17,803] [INFO] Epoch 10/50, ValAcc: 80.89%, TrainLoss: 0.2870, ValLoss: 0.6775, LR: 0.001
[2025-07-31 06:44:53,488] [INFO] Epoch 11/50, ValAcc: 80.96%, TrainLoss: 0.2661, ValLoss: 0.7400, LR: 0.001
[2025-07-31 06:45:29,162] [INFO] Epoch 12/50, ValAcc: 81.16%, TrainLoss: 0.1485, ValLoss: 0.7404, LR: 0.0005
[2025-07-31 06:46:04,841] [INFO] Epoch 13/50, ValAcc: 82.07%, TrainLoss: 0.1109, ValLoss: 0.7559, LR: 0.0005
[2025-07-31 06:46:40,529] [INFO] Epoch 14/50, ValAcc: 83.06%, TrainLoss: 0.0855, ValLoss: 0.7629, LR: 0.0005
[2025-07-31 06:47:16,213] [INFO] Epoch 15/50, ValAcc: 82.21%, TrainLoss: 0.0636, ValLoss: 0.7904, LR: 0.00025
[2025-07-31 06:47:51,908] [INFO] Epoch 16/50, ValAcc: 82.53%, TrainLoss: 0.0571, ValLoss: 0.7924, LR: 0.00025
[2025-07-31 06:48:27,586] [INFO] Epoch 17/50, ValAcc: 82.60%, TrainLoss: 0.0505, ValLoss: 0.8290, LR: 0.00025
[2025-07-31 06:49:03,262] [INFO] Epoch 18/50, ValAcc: 82.40%, TrainLoss: 0.0423, ValLoss: 0.8478, LR: 0.000125
[2025-07-31 06:49:38,946] [INFO] Epoch 19/50, ValAcc: 82.86%, TrainLoss: 0.0386, ValLoss: 0.8655, LR: 0.000125
[2025-07-31 06:50:14,641] [INFO] Epoch 20/50, ValAcc: 82.34%, TrainLoss: 0.0365, ValLoss: 0.8774, LR: 0.000125
[2025-07-31 06:50:50,340] [INFO] Epoch 21/50, ValAcc: 82.47%, TrainLoss: 0.0343, ValLoss: 0.8638, LR: 6.25e-05
[2025-07-31 06:50:50,340] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-31 06:50:55,796] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv'], pktcount=2000, kfold=5, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753942197.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753942197.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.8411,0.8428,0.8450,0.8449
[2025-07-31 06:50:55,796] [INFO] Training Fold 4/5
[2025-07-31 06:51:22,369] [INFO] Feature 0 normalized using token
[2025-07-31 06:51:22,369] [INFO] Train shape: (10660, 2000), Val shape: (1523, 2000), Test shape: (3045, 2000)
[2025-07-31 06:51:22,406] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-31 06:51:22,407] [INFO] Training...
[2025-07-31 06:51:57,837] [INFO] Epoch 1/50, ValAcc: 23.57%, TrainLoss: 3.4736, ValLoss: 2.8216, LR: 0.001
[2025-07-31 06:52:33,524] [INFO] Epoch 2/50, ValAcc: 45.31%, TrainLoss: 2.3983, ValLoss: 1.7850, LR: 0.001
[2025-07-31 06:53:09,200] [INFO] Epoch 3/50, ValAcc: 62.18%, TrainLoss: 1.4849, ValLoss: 1.1158, LR: 0.001
[2025-07-31 06:53:44,912] [INFO] Epoch 4/50, ValAcc: 70.39%, TrainLoss: 0.9686, ValLoss: 0.8754, LR: 0.001
[2025-07-31 06:54:20,618] [INFO] Epoch 5/50, ValAcc: 74.92%, TrainLoss: 0.7314, ValLoss: 0.7169, LR: 0.001
[2025-07-31 06:54:56,294] [INFO] Epoch 6/50, ValAcc: 78.00%, TrainLoss: 0.5847, ValLoss: 0.6697, LR: 0.001
[2025-07-31 06:55:31,969] [INFO] Epoch 7/50, ValAcc: 76.76%, TrainLoss: 0.4913, ValLoss: 0.7069, LR: 0.001
[2025-07-31 06:56:07,651] [INFO] Epoch 8/50, ValAcc: 80.11%, TrainLoss: 0.4242, ValLoss: 0.6707, LR: 0.001
[2025-07-31 06:56:43,361] [INFO] Epoch 9/50, ValAcc: 81.09%, TrainLoss: 0.3728, ValLoss: 0.6184, LR: 0.001
[2025-07-31 06:57:19,057] [INFO] Epoch 10/50, ValAcc: 80.17%, TrainLoss: 0.3332, ValLoss: 0.6824, LR: 0.001
[2025-07-31 06:57:54,753] [INFO] Epoch 11/50, ValAcc: 79.51%, TrainLoss: 0.2958, ValLoss: 0.7058, LR: 0.001
[2025-07-31 06:58:30,455] [INFO] Epoch 12/50, ValAcc: 80.11%, TrainLoss: 0.2548, ValLoss: 0.7149, LR: 0.001
[2025-07-31 06:59:06,153] [INFO] Epoch 13/50, ValAcc: 82.40%, TrainLoss: 0.1415, ValLoss: 0.7201, LR: 0.0005
[2025-07-31 06:59:41,845] [INFO] Epoch 14/50, ValAcc: 81.94%, TrainLoss: 0.0977, ValLoss: 0.7397, LR: 0.0005
[2025-07-31 07:00:17,553] [INFO] Epoch 15/50, ValAcc: 81.88%, TrainLoss: 0.0871, ValLoss: 0.8050, LR: 0.0005
[2025-07-31 07:00:53,246] [INFO] Epoch 16/50, ValAcc: 83.32%, TrainLoss: 0.0637, ValLoss: 0.7934, LR: 0.00025
[2025-07-31 07:01:28,939] [INFO] Epoch 17/50, ValAcc: 82.93%, TrainLoss: 0.0510, ValLoss: 0.8261, LR: 0.00025
[2025-07-31 07:02:04,627] [INFO] Epoch 18/50, ValAcc: 82.21%, TrainLoss: 0.0468, ValLoss: 0.8644, LR: 0.00025
[2025-07-31 07:02:40,304] [INFO] Epoch 19/50, ValAcc: 82.99%, TrainLoss: 0.0356, ValLoss: 0.8733, LR: 0.000125
[2025-07-31 07:03:15,999] [INFO] Epoch 20/50, ValAcc: 83.13%, TrainLoss: 0.0342, ValLoss: 0.8709, LR: 0.000125
[2025-07-31 07:03:51,685] [INFO] Epoch 21/50, ValAcc: 82.47%, TrainLoss: 0.0306, ValLoss: 0.8902, LR: 0.000125
[2025-07-31 07:04:27,376] [INFO] Epoch 22/50, ValAcc: 82.40%, TrainLoss: 0.0284, ValLoss: 0.8918, LR: 6.25e-05
[2025-07-31 07:04:27,376] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-31 07:04:32,837] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv'], pktcount=2000, kfold=5, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753942197.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753942197.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.8506,0.8480,0.8515,0.8491
[2025-07-31 07:04:32,838] [INFO] Training Fold 5/5
[2025-07-31 07:04:59,767] [INFO] Feature 0 normalized using token
[2025-07-31 07:04:59,767] [INFO] Train shape: (10660, 2000), Val shape: (1523, 2000), Test shape: (3045, 2000)
[2025-07-31 07:04:59,807] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-31 07:04:59,807] [INFO] Training...
[2025-07-31 07:05:35,519] [INFO] Epoch 1/50, ValAcc: 15.36%, TrainLoss: 3.6482, ValLoss: 3.1299, LR: 0.001
[2025-07-31 07:06:11,225] [INFO] Epoch 2/50, ValAcc: 38.08%, TrainLoss: 2.7027, ValLoss: 2.0389, LR: 0.001
[2025-07-31 07:06:46,924] [INFO] Epoch 3/50, ValAcc: 60.74%, TrainLoss: 1.7268, ValLoss: 1.1957, LR: 0.001
[2025-07-31 07:07:22,657] [INFO] Epoch 4/50, ValAcc: 71.77%, TrainLoss: 1.1058, ValLoss: 0.8073, LR: 0.001
[2025-07-31 07:07:58,370] [INFO] Epoch 5/50, ValAcc: 75.44%, TrainLoss: 0.8197, ValLoss: 0.7017, LR: 0.001
[2025-07-31 07:08:34,074] [INFO] Epoch 6/50, ValAcc: 77.35%, TrainLoss: 0.6482, ValLoss: 0.6576, LR: 0.001
[2025-07-31 07:09:09,746] [INFO] Epoch 7/50, ValAcc: 79.38%, TrainLoss: 0.5450, ValLoss: 0.5984, LR: 0.001
[2025-07-31 07:09:45,442] [INFO] Epoch 8/50, ValAcc: 79.38%, TrainLoss: 0.4538, ValLoss: 0.6251, LR: 0.001
[2025-07-31 07:10:21,136] [INFO] Epoch 9/50, ValAcc: 80.43%, TrainLoss: 0.3780, ValLoss: 0.5811, LR: 0.001
[2025-07-31 07:10:56,805] [INFO] Epoch 10/50, ValAcc: 80.83%, TrainLoss: 0.3245, ValLoss: 0.6254, LR: 0.001
[2025-07-31 07:11:32,523] [INFO] Epoch 11/50, ValAcc: 81.42%, TrainLoss: 0.3114, ValLoss: 0.6210, LR: 0.001
[2025-07-31 07:12:08,207] [INFO] Epoch 12/50, ValAcc: 80.30%, TrainLoss: 0.2751, ValLoss: 0.7197, LR: 0.001
[2025-07-31 07:12:43,884] [INFO] Epoch 13/50, ValAcc: 83.39%, TrainLoss: 0.1611, ValLoss: 0.5902, LR: 0.0005
[2025-07-31 07:13:19,556] [INFO] Epoch 14/50, ValAcc: 82.99%, TrainLoss: 0.1148, ValLoss: 0.6347, LR: 0.0005
[2025-07-31 07:13:55,246] [INFO] Epoch 15/50, ValAcc: 84.37%, TrainLoss: 0.0932, ValLoss: 0.6222, LR: 0.0005
[2025-07-31 07:14:30,956] [INFO] Epoch 16/50, ValAcc: 83.91%, TrainLoss: 0.0611, ValLoss: 0.6637, LR: 0.00025
[2025-07-31 07:15:06,649] [INFO] Epoch 17/50, ValAcc: 84.64%, TrainLoss: 0.0515, ValLoss: 0.6939, LR: 0.00025
[2025-07-31 07:15:42,351] [INFO] Epoch 18/50, ValAcc: 84.57%, TrainLoss: 0.0465, ValLoss: 0.7456, LR: 0.00025
[2025-07-31 07:16:18,050] [INFO] Epoch 19/50, ValAcc: 84.50%, TrainLoss: 0.0394, ValLoss: 0.7196, LR: 0.000125
[2025-07-31 07:16:53,738] [INFO] Epoch 20/50, ValAcc: 84.50%, TrainLoss: 0.0349, ValLoss: 0.7342, LR: 0.000125
[2025-07-31 07:17:29,446] [INFO] Epoch 21/50, ValAcc: 84.90%, TrainLoss: 0.0316, ValLoss: 0.7452, LR: 0.000125
[2025-07-31 07:18:05,118] [INFO] Epoch 22/50, ValAcc: 84.64%, TrainLoss: 0.0280, ValLoss: 0.7475, LR: 6.25e-05
[2025-07-31 07:18:05,118] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-31 07:18:10,588] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv'], pktcount=2000, kfold=5, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753942197.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753942197.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.8483,0.8458,0.8492,0.8455
[2025-07-31 07:18:10,901] [INFO] [(0.8539067629678266, 0.8519897919839391, 0.8561935616109883, 0.8530754008215469), (0.8260013131976363, 0.8283820113672961, 0.8308580320452228, 0.8321924703877136), (0.8411030860144452, 0.8428202984924166, 0.8450034247034942, 0.8449489385294661), (0.8505747126436781, 0.8480410590438219, 0.8514656914828784, 0.849065348731802), (0.8482758620689655, 0.8458217961157898, 0.849162378908258, 0.8455293165127634)]
=== Step4. Script Execution Finished at Thu Jul 31 07:18:11 AM UTC 2025 ===
