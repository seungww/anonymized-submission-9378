[2025-07-31 06:09:59,596] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv'], pktcount=2000, kfold=5, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753942197.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753942197.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'))
[2025-07-31 06:10:30,903] [INFO] Processed data from vrchat-worlds/meta-ip_len/meta-ip_len.csv:
[2025-07-31 06:10:30,903] [INFO] (15228, 2000)
[2025-07-31 06:10:30,903] [INFO] [['244' '141' '52' ... '1432' '1432' '1432']
 ['60' '60' '52' ... '52' '242' '143']
 ['1432' '1432' '1432' ... '1432' '1432' '1432']
 ...
 ['52' '1432' '1432' ... '76' '52' '52']
 ['1432' '340' '52' ... '76' '52' '52']
 ['52' '52' '1432' ... '52' '60' '60']]
[2025-07-31 06:10:31,015] [INFO] Training Fold 1/5
[2025-07-31 06:10:59,976] [INFO] Feature 0 normalized using token
[2025-07-31 06:10:59,977] [INFO] Train shape: (10659, 2000), Val shape: (1523, 2000), Test shape: (3046, 2000)
[2025-07-31 06:11:00,040] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-31 06:11:00,040] [INFO] Training...
[2025-07-31 06:11:37,131] [INFO] Epoch 1/50, ValAcc: 23.31%, TrainLoss: 3.5390, ValLoss: 2.8082, LR: 0.001
[2025-07-31 06:12:12,943] [INFO] Epoch 2/50, ValAcc: 43.01%, TrainLoss: 2.4695, ValLoss: 1.8124, LR: 0.001
[2025-07-31 06:12:48,748] [INFO] Epoch 3/50, ValAcc: 65.27%, TrainLoss: 1.5446, ValLoss: 1.0818, LR: 0.001
[2025-07-31 06:13:24,540] [INFO] Epoch 4/50, ValAcc: 71.70%, TrainLoss: 0.9979, ValLoss: 0.8379, LR: 0.001
[2025-07-31 06:14:00,323] [INFO] Epoch 5/50, ValAcc: 75.25%, TrainLoss: 0.7407, ValLoss: 0.7502, LR: 0.001
[2025-07-31 06:14:36,063] [INFO] Epoch 6/50, ValAcc: 77.15%, TrainLoss: 0.6052, ValLoss: 0.6871, LR: 0.001
[2025-07-31 06:15:11,786] [INFO] Epoch 7/50, ValAcc: 78.73%, TrainLoss: 0.4861, ValLoss: 0.6363, LR: 0.001
[2025-07-31 06:15:47,515] [INFO] Epoch 8/50, ValAcc: 79.05%, TrainLoss: 0.4117, ValLoss: 0.6839, LR: 0.001
[2025-07-31 06:16:23,257] [INFO] Epoch 9/50, ValAcc: 80.96%, TrainLoss: 0.3685, ValLoss: 0.6685, LR: 0.001
[2025-07-31 06:16:59,021] [INFO] Epoch 10/50, ValAcc: 80.76%, TrainLoss: 0.3446, ValLoss: 0.6346, LR: 0.001
[2025-07-31 06:17:34,802] [INFO] Epoch 11/50, ValAcc: 80.50%, TrainLoss: 0.2940, ValLoss: 0.7150, LR: 0.001
[2025-07-31 06:18:10,545] [INFO] Epoch 12/50, ValAcc: 80.04%, TrainLoss: 0.2636, ValLoss: 0.7128, LR: 0.001
[2025-07-31 06:18:46,283] [INFO] Epoch 13/50, ValAcc: 81.48%, TrainLoss: 0.2081, ValLoss: 0.7433, LR: 0.001
[2025-07-31 06:19:22,037] [INFO] Epoch 14/50, ValAcc: 83.52%, TrainLoss: 0.1257, ValLoss: 0.6846, LR: 0.0005
[2025-07-31 06:19:57,781] [INFO] Epoch 15/50, ValAcc: 84.18%, TrainLoss: 0.0858, ValLoss: 0.7278, LR: 0.0005
[2025-07-31 06:20:33,551] [INFO] Epoch 16/50, ValAcc: 83.98%, TrainLoss: 0.0718, ValLoss: 0.7722, LR: 0.0005
[2025-07-31 06:21:09,293] [INFO] Epoch 17/50, ValAcc: 84.57%, TrainLoss: 0.0555, ValLoss: 0.7421, LR: 0.00025
[2025-07-31 06:21:45,038] [INFO] Epoch 18/50, ValAcc: 84.24%, TrainLoss: 0.0458, ValLoss: 0.7610, LR: 0.00025
[2025-07-31 06:22:20,778] [INFO] Epoch 19/50, ValAcc: 85.49%, TrainLoss: 0.0399, ValLoss: 0.7860, LR: 0.00025
[2025-07-31 06:22:56,525] [INFO] Epoch 20/50, ValAcc: 85.42%, TrainLoss: 0.0343, ValLoss: 0.7733, LR: 0.000125
[2025-07-31 06:23:32,389] [INFO] Epoch 21/50, ValAcc: 85.55%, TrainLoss: 0.0305, ValLoss: 0.7771, LR: 0.000125
[2025-07-31 06:24:08,152] [INFO] Epoch 22/50, ValAcc: 84.83%, TrainLoss: 0.0289, ValLoss: 0.8040, LR: 0.000125
[2025-07-31 06:24:43,963] [INFO] Epoch 23/50, ValAcc: 85.10%, TrainLoss: 0.0265, ValLoss: 0.7981, LR: 6.25e-05
[2025-07-31 06:24:43,964] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-31 06:24:49,429] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv'], pktcount=2000, kfold=5, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753942197.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753942197.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.8539,0.8520,0.8562,0.8531
[2025-07-31 06:24:49,430] [INFO] Training Fold 2/5
[2025-07-31 06:25:18,683] [INFO] Feature 0 normalized using token
[2025-07-31 06:25:18,683] [INFO] Train shape: (10659, 2000), Val shape: (1523, 2000), Test shape: (3046, 2000)
[2025-07-31 06:25:18,721] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-31 06:25:18,721] [INFO] Training...
[2025-07-31 06:25:54,185] [INFO] Epoch 1/50, ValAcc: 17.73%, TrainLoss: 3.5833, ValLoss: 2.9605, LR: 0.001
[2025-07-31 06:26:29,942] [INFO] Epoch 2/50, ValAcc: 39.33%, TrainLoss: 2.5639, ValLoss: 1.9488, LR: 0.001
[2025-07-31 06:27:05,696] [INFO] Epoch 3/50, ValAcc: 64.02%, TrainLoss: 1.6417, ValLoss: 1.1386, LR: 0.001
[2025-07-31 06:27:41,429] [INFO] Epoch 4/50, ValAcc: 71.04%, TrainLoss: 1.0480, ValLoss: 0.8562, LR: 0.001
[2025-07-31 06:28:17,164] [INFO] Epoch 5/50, ValAcc: 76.03%, TrainLoss: 0.7565, ValLoss: 0.7065, LR: 0.001
[2025-07-31 06:28:52,892] [INFO] Epoch 6/50, ValAcc: 75.84%, TrainLoss: 0.6072, ValLoss: 0.7463, LR: 0.001
[2025-07-31 06:29:28,618] [INFO] Epoch 7/50, ValAcc: 79.71%, TrainLoss: 0.4849, ValLoss: 0.6430, LR: 0.001
[2025-07-31 06:30:04,341] [INFO] Epoch 8/50, ValAcc: 80.56%, TrainLoss: 0.4145, ValLoss: 0.6624, LR: 0.001
[2025-07-31 06:30:40,060] [INFO] Epoch 9/50, ValAcc: 80.56%, TrainLoss: 0.3483, ValLoss: 0.6888, LR: 0.001
[2025-07-31 06:31:15,776] [INFO] Epoch 10/50, ValAcc: 78.92%, TrainLoss: 0.3234, ValLoss: 0.7750, LR: 0.001
[2025-07-31 06:31:51,483] [INFO] Epoch 11/50, ValAcc: 82.86%, TrainLoss: 0.1958, ValLoss: 0.6319, LR: 0.0005
[2025-07-31 06:32:27,191] [INFO] Epoch 12/50, ValAcc: 83.72%, TrainLoss: 0.1296, ValLoss: 0.6576, LR: 0.0005
[2025-07-31 06:33:02,891] [INFO] Epoch 13/50, ValAcc: 83.59%, TrainLoss: 0.1023, ValLoss: 0.7232, LR: 0.0005
[2025-07-31 06:33:38,611] [INFO] Epoch 14/50, ValAcc: 83.26%, TrainLoss: 0.0847, ValLoss: 0.7541, LR: 0.0005
[2025-07-31 06:34:14,316] [INFO] Epoch 15/50, ValAcc: 83.98%, TrainLoss: 0.0652, ValLoss: 0.7512, LR: 0.00025
[2025-07-31 06:34:50,012] [INFO] Epoch 16/50, ValAcc: 83.19%, TrainLoss: 0.0517, ValLoss: 0.8149, LR: 0.00025
[2025-07-31 06:35:25,723] [INFO] Epoch 17/50, ValAcc: 84.24%, TrainLoss: 0.0448, ValLoss: 0.8379, LR: 0.00025
[2025-07-31 06:36:01,391] [INFO] Epoch 18/50, ValAcc: 84.44%, TrainLoss: 0.0350, ValLoss: 0.8404, LR: 0.000125
[2025-07-31 06:36:37,094] [INFO] Epoch 19/50, ValAcc: 84.31%, TrainLoss: 0.0359, ValLoss: 0.8469, LR: 0.000125
[2025-07-31 06:37:12,790] [INFO] Epoch 20/50, ValAcc: 84.70%, TrainLoss: 0.0297, ValLoss: 0.8546, LR: 0.000125
[2025-07-31 06:37:48,454] [INFO] Epoch 21/50, ValAcc: 84.64%, TrainLoss: 0.0270, ValLoss: 0.8510, LR: 6.25e-05
[2025-07-31 06:37:48,454] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-31 06:37:53,942] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv'], pktcount=2000, kfold=5, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753942197.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753942197.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.8260,0.8284,0.8309,0.8322
[2025-07-31 06:37:53,942] [INFO] Training Fold 3/5
[2025-07-31 06:38:20,899] [INFO] Feature 0 normalized using token
[2025-07-31 06:38:20,899] [INFO] Train shape: (10659, 2000), Val shape: (1523, 2000), Test shape: (3046, 2000)
[2025-07-31 06:38:20,940] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-31 06:38:20,940] [INFO] Training...
[2025-07-31 06:38:56,623] [INFO] Epoch 1/50, ValAcc: 20.81%, TrainLoss: 3.4785, ValLoss: 2.7762, LR: 0.001
[2025-07-31 06:39:32,288] [INFO] Epoch 2/50, ValAcc: 51.74%, TrainLoss: 2.2466, ValLoss: 1.5450, LR: 0.001
[2025-07-31 06:40:07,956] [INFO] Epoch 3/50, ValAcc: 67.10%, TrainLoss: 1.3429, ValLoss: 0.9907, LR: 0.001
[2025-07-31 06:40:43,629] [INFO] Epoch 4/50, ValAcc: 71.44%, TrainLoss: 0.9209, ValLoss: 0.8296, LR: 0.001
[2025-07-31 06:41:19,326] [INFO] Epoch 5/50, ValAcc: 75.57%, TrainLoss: 0.6881, ValLoss: 0.7136, LR: 0.001
[2025-07-31 06:41:55,035] [INFO] Epoch 6/50, ValAcc: 76.82%, TrainLoss: 0.5422, ValLoss: 0.7087, LR: 0.001
[2025-07-31 06:42:30,716] [INFO] Epoch 7/50, ValAcc: 76.56%, TrainLoss: 0.4618, ValLoss: 0.7041, LR: 0.001
[2025-07-31 06:43:06,409] [INFO] Epoch 8/50, ValAcc: 78.20%, TrainLoss: 0.3950, ValLoss: 0.6545, LR: 0.001
[2025-07-31 06:43:42,117] [INFO] Epoch 9/50, ValAcc: 80.83%, TrainLoss: 0.3405, ValLoss: 0.6817, LR: 0.001
[2025-07-31 06:44:17,803] [INFO] Epoch 10/50, ValAcc: 80.89%, TrainLoss: 0.2870, ValLoss: 0.6775, LR: 0.001
[2025-07-31 06:44:53,488] [INFO] Epoch 11/50, ValAcc: 80.96%, TrainLoss: 0.2661, ValLoss: 0.7400, LR: 0.001
[2025-07-31 06:45:29,162] [INFO] Epoch 12/50, ValAcc: 81.16%, TrainLoss: 0.1485, ValLoss: 0.7404, LR: 0.0005
[2025-07-31 06:46:04,841] [INFO] Epoch 13/50, ValAcc: 82.07%, TrainLoss: 0.1109, ValLoss: 0.7559, LR: 0.0005
[2025-07-31 06:46:40,529] [INFO] Epoch 14/50, ValAcc: 83.06%, TrainLoss: 0.0855, ValLoss: 0.7629, LR: 0.0005
[2025-07-31 06:47:16,213] [INFO] Epoch 15/50, ValAcc: 82.21%, TrainLoss: 0.0636, ValLoss: 0.7904, LR: 0.00025
[2025-07-31 06:47:51,908] [INFO] Epoch 16/50, ValAcc: 82.53%, TrainLoss: 0.0571, ValLoss: 0.7924, LR: 0.00025
[2025-07-31 06:48:27,586] [INFO] Epoch 17/50, ValAcc: 82.60%, TrainLoss: 0.0505, ValLoss: 0.8290, LR: 0.00025
[2025-07-31 06:49:03,262] [INFO] Epoch 18/50, ValAcc: 82.40%, TrainLoss: 0.0423, ValLoss: 0.8478, LR: 0.000125
[2025-07-31 06:49:38,946] [INFO] Epoch 19/50, ValAcc: 82.86%, TrainLoss: 0.0386, ValLoss: 0.8655, LR: 0.000125
[2025-07-31 06:50:14,641] [INFO] Epoch 20/50, ValAcc: 82.34%, TrainLoss: 0.0365, ValLoss: 0.8774, LR: 0.000125
[2025-07-31 06:50:50,340] [INFO] Epoch 21/50, ValAcc: 82.47%, TrainLoss: 0.0343, ValLoss: 0.8638, LR: 6.25e-05
[2025-07-31 06:50:50,340] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-31 06:50:55,796] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv'], pktcount=2000, kfold=5, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753942197.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753942197.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.8411,0.8428,0.8450,0.8449
[2025-07-31 06:50:55,796] [INFO] Training Fold 4/5
[2025-07-31 06:51:22,369] [INFO] Feature 0 normalized using token
[2025-07-31 06:51:22,369] [INFO] Train shape: (10660, 2000), Val shape: (1523, 2000), Test shape: (3045, 2000)
[2025-07-31 06:51:22,406] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-31 06:51:22,407] [INFO] Training...
[2025-07-31 06:51:57,837] [INFO] Epoch 1/50, ValAcc: 23.57%, TrainLoss: 3.4736, ValLoss: 2.8216, LR: 0.001
[2025-07-31 06:52:33,524] [INFO] Epoch 2/50, ValAcc: 45.31%, TrainLoss: 2.3983, ValLoss: 1.7850, LR: 0.001
[2025-07-31 06:53:09,200] [INFO] Epoch 3/50, ValAcc: 62.18%, TrainLoss: 1.4849, ValLoss: 1.1158, LR: 0.001
[2025-07-31 06:53:44,912] [INFO] Epoch 4/50, ValAcc: 70.39%, TrainLoss: 0.9686, ValLoss: 0.8754, LR: 0.001
[2025-07-31 06:54:20,618] [INFO] Epoch 5/50, ValAcc: 74.92%, TrainLoss: 0.7314, ValLoss: 0.7169, LR: 0.001
[2025-07-31 06:54:56,294] [INFO] Epoch 6/50, ValAcc: 78.00%, TrainLoss: 0.5847, ValLoss: 0.6697, LR: 0.001
[2025-07-31 06:55:31,969] [INFO] Epoch 7/50, ValAcc: 76.76%, TrainLoss: 0.4913, ValLoss: 0.7069, LR: 0.001
[2025-07-31 06:56:07,651] [INFO] Epoch 8/50, ValAcc: 80.11%, TrainLoss: 0.4242, ValLoss: 0.6707, LR: 0.001
[2025-07-31 06:56:43,361] [INFO] Epoch 9/50, ValAcc: 81.09%, TrainLoss: 0.3728, ValLoss: 0.6184, LR: 0.001
[2025-07-31 06:57:19,057] [INFO] Epoch 10/50, ValAcc: 80.17%, TrainLoss: 0.3332, ValLoss: 0.6824, LR: 0.001
[2025-07-31 06:57:54,753] [INFO] Epoch 11/50, ValAcc: 79.51%, TrainLoss: 0.2958, ValLoss: 0.7058, LR: 0.001
[2025-07-31 06:58:30,455] [INFO] Epoch 12/50, ValAcc: 80.11%, TrainLoss: 0.2548, ValLoss: 0.7149, LR: 0.001
[2025-07-31 06:59:06,153] [INFO] Epoch 13/50, ValAcc: 82.40%, TrainLoss: 0.1415, ValLoss: 0.7201, LR: 0.0005
[2025-07-31 06:59:41,845] [INFO] Epoch 14/50, ValAcc: 81.94%, TrainLoss: 0.0977, ValLoss: 0.7397, LR: 0.0005
[2025-07-31 07:00:17,553] [INFO] Epoch 15/50, ValAcc: 81.88%, TrainLoss: 0.0871, ValLoss: 0.8050, LR: 0.0005
[2025-07-31 07:00:53,246] [INFO] Epoch 16/50, ValAcc: 83.32%, TrainLoss: 0.0637, ValLoss: 0.7934, LR: 0.00025
[2025-07-31 07:01:28,939] [INFO] Epoch 17/50, ValAcc: 82.93%, TrainLoss: 0.0510, ValLoss: 0.8261, LR: 0.00025
[2025-07-31 07:02:04,627] [INFO] Epoch 18/50, ValAcc: 82.21%, TrainLoss: 0.0468, ValLoss: 0.8644, LR: 0.00025
[2025-07-31 07:02:40,304] [INFO] Epoch 19/50, ValAcc: 82.99%, TrainLoss: 0.0356, ValLoss: 0.8733, LR: 0.000125
[2025-07-31 07:03:15,999] [INFO] Epoch 20/50, ValAcc: 83.13%, TrainLoss: 0.0342, ValLoss: 0.8709, LR: 0.000125
[2025-07-31 07:03:51,685] [INFO] Epoch 21/50, ValAcc: 82.47%, TrainLoss: 0.0306, ValLoss: 0.8902, LR: 0.000125
[2025-07-31 07:04:27,376] [INFO] Epoch 22/50, ValAcc: 82.40%, TrainLoss: 0.0284, ValLoss: 0.8918, LR: 6.25e-05
[2025-07-31 07:04:27,376] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-31 07:04:32,837] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv'], pktcount=2000, kfold=5, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753942197.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753942197.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.8506,0.8480,0.8515,0.8491
[2025-07-31 07:04:32,838] [INFO] Training Fold 5/5
[2025-07-31 07:04:59,767] [INFO] Feature 0 normalized using token
[2025-07-31 07:04:59,767] [INFO] Train shape: (10660, 2000), Val shape: (1523, 2000), Test shape: (3045, 2000)
[2025-07-31 07:04:59,807] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1385, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-31 07:04:59,807] [INFO] Training...
[2025-07-31 07:05:35,519] [INFO] Epoch 1/50, ValAcc: 15.36%, TrainLoss: 3.6482, ValLoss: 3.1299, LR: 0.001
[2025-07-31 07:06:11,225] [INFO] Epoch 2/50, ValAcc: 38.08%, TrainLoss: 2.7027, ValLoss: 2.0389, LR: 0.001
[2025-07-31 07:06:46,924] [INFO] Epoch 3/50, ValAcc: 60.74%, TrainLoss: 1.7268, ValLoss: 1.1957, LR: 0.001
[2025-07-31 07:07:22,657] [INFO] Epoch 4/50, ValAcc: 71.77%, TrainLoss: 1.1058, ValLoss: 0.8073, LR: 0.001
[2025-07-31 07:07:58,370] [INFO] Epoch 5/50, ValAcc: 75.44%, TrainLoss: 0.8197, ValLoss: 0.7017, LR: 0.001
[2025-07-31 07:08:34,074] [INFO] Epoch 6/50, ValAcc: 77.35%, TrainLoss: 0.6482, ValLoss: 0.6576, LR: 0.001
[2025-07-31 07:09:09,746] [INFO] Epoch 7/50, ValAcc: 79.38%, TrainLoss: 0.5450, ValLoss: 0.5984, LR: 0.001
[2025-07-31 07:09:45,442] [INFO] Epoch 8/50, ValAcc: 79.38%, TrainLoss: 0.4538, ValLoss: 0.6251, LR: 0.001
[2025-07-31 07:10:21,136] [INFO] Epoch 9/50, ValAcc: 80.43%, TrainLoss: 0.3780, ValLoss: 0.5811, LR: 0.001
[2025-07-31 07:10:56,805] [INFO] Epoch 10/50, ValAcc: 80.83%, TrainLoss: 0.3245, ValLoss: 0.6254, LR: 0.001
[2025-07-31 07:11:32,523] [INFO] Epoch 11/50, ValAcc: 81.42%, TrainLoss: 0.3114, ValLoss: 0.6210, LR: 0.001
[2025-07-31 07:12:08,207] [INFO] Epoch 12/50, ValAcc: 80.30%, TrainLoss: 0.2751, ValLoss: 0.7197, LR: 0.001
[2025-07-31 07:12:43,884] [INFO] Epoch 13/50, ValAcc: 83.39%, TrainLoss: 0.1611, ValLoss: 0.5902, LR: 0.0005
[2025-07-31 07:13:19,556] [INFO] Epoch 14/50, ValAcc: 82.99%, TrainLoss: 0.1148, ValLoss: 0.6347, LR: 0.0005
[2025-07-31 07:13:55,246] [INFO] Epoch 15/50, ValAcc: 84.37%, TrainLoss: 0.0932, ValLoss: 0.6222, LR: 0.0005
[2025-07-31 07:14:30,956] [INFO] Epoch 16/50, ValAcc: 83.91%, TrainLoss: 0.0611, ValLoss: 0.6637, LR: 0.00025
[2025-07-31 07:15:06,649] [INFO] Epoch 17/50, ValAcc: 84.64%, TrainLoss: 0.0515, ValLoss: 0.6939, LR: 0.00025
[2025-07-31 07:15:42,351] [INFO] Epoch 18/50, ValAcc: 84.57%, TrainLoss: 0.0465, ValLoss: 0.7456, LR: 0.00025
[2025-07-31 07:16:18,050] [INFO] Epoch 19/50, ValAcc: 84.50%, TrainLoss: 0.0394, ValLoss: 0.7196, LR: 0.000125
[2025-07-31 07:16:53,738] [INFO] Epoch 20/50, ValAcc: 84.50%, TrainLoss: 0.0349, ValLoss: 0.7342, LR: 0.000125
[2025-07-31 07:17:29,446] [INFO] Epoch 21/50, ValAcc: 84.90%, TrainLoss: 0.0316, ValLoss: 0.7452, LR: 0.000125
[2025-07-31 07:18:05,118] [INFO] Epoch 22/50, ValAcc: 84.64%, TrainLoss: 0.0280, ValLoss: 0.7475, LR: 6.25e-05
[2025-07-31 07:18:05,118] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-31 07:18:10,588] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv'], pktcount=2000, kfold=5, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753942197.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753942197.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.8483,0.8458,0.8492,0.8455
[2025-07-31 07:18:10,901] [INFO] [(0.8539067629678266, 0.8519897919839391, 0.8561935616109883, 0.8530754008215469), (0.8260013131976363, 0.8283820113672961, 0.8308580320452228, 0.8321924703877136), (0.8411030860144452, 0.8428202984924166, 0.8450034247034942, 0.8449489385294661), (0.8505747126436781, 0.8480410590438219, 0.8514656914828784, 0.849065348731802), (0.8482758620689655, 0.8458217961157898, 0.849162378908258, 0.8455293165127634)]
