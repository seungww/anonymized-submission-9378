=== Step4. Script Execution Started at Wed Jul 30 07:43:38 AM UTC 2025 ===
Base directory: vrchat-worlds
Data prefix: meta
Output directory: output/vrchat-worlds/train
[INFO] tcp_window â†’ norm: token, model: bigru
Running python vrscanner.py --train --debug_path output/vrchat-worlds/train/train_meta_1753861418.debug --leaderboard_path output/vrchat-worlds/train/train_meta_1753861418.csv --kfold 5 --pktcount 1000 --input_dim 512 --hidden_size 256 --num_layers 3 --dropout 0.3 --fusion_dim 256 --fc_hidden_size 128 --epoch 50 --lr 0.001 --path vrchat-worlds/meta-tcp_window/meta-tcp_window.csv --norm token --model bigru
[2025-07-30 07:43:40,228] [INFO] Namespace(path=['vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=1000, kfold=5, model=['bigru'], norm=['token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753861418.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753861418.csv', step1=False, step2=False, step3=False, train=True, train_sliding=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'))
[2025-07-30 07:44:13,919] [INFO] Processed data from vrchat-worlds/meta-tcp_window/meta-tcp_window.csv:
[2025-07-30 07:44:13,919] [INFO] (15228, 1000)
[2025-07-30 07:44:13,919] [INFO] [['1281' '1281' '580' ... '291' '291' '291']
 ['65535' '65535' '256' ... '291' '291' '1540']
 ['2038' '2038' '2038' ... '534' '534' '310']
 ...
 ['265' '774' '774' ... '300' '300' '300']
 ['265' '265' '332' ... '289' '289' '289']
 ['343' '761' '300' ... '774' '5404' '5404']]
[2025-07-30 07:44:13,974] [INFO] Training Fold 1/5
[2025-07-30 07:44:27,774] [INFO] Feature 0 normalized using token
[2025-07-30 07:44:27,774] [INFO] Train shape: (10659, 1000), Val shape: (1523, 1000), Test shape: (3046, 1000)
[2025-07-30 07:44:27,834] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(5120, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-30 07:44:27,834] [INFO] Training...
[2025-07-30 07:44:47,416] [INFO] Epoch 1/50, ValAcc: 55.22%, TrainLoss: 2.8463, ValLoss: 1.6969, LR: 0.001
[2025-07-30 07:45:05,754] [INFO] Epoch 2/50, ValAcc: 71.24%, TrainLoss: 1.4410, ValLoss: 1.0924, LR: 0.001
[2025-07-30 07:45:24,085] [INFO] Epoch 3/50, ValAcc: 74.72%, TrainLoss: 0.9030, ValLoss: 0.9169, LR: 0.001
[2025-07-30 07:45:42,416] [INFO] Epoch 4/50, ValAcc: 77.87%, TrainLoss: 0.6574, ValLoss: 0.8389, LR: 0.001
[2025-07-30 07:46:00,759] [INFO] Epoch 5/50, ValAcc: 77.41%, TrainLoss: 0.4742, ValLoss: 0.8882, LR: 0.001
[2025-07-30 07:46:19,087] [INFO] Epoch 6/50, ValAcc: 81.75%, TrainLoss: 0.3773, ValLoss: 0.8322, LR: 0.001
[2025-07-30 07:46:37,421] [INFO] Epoch 7/50, ValAcc: 82.93%, TrainLoss: 0.2967, ValLoss: 0.8882, LR: 0.001
[2025-07-30 07:46:55,745] [INFO] Epoch 8/50, ValAcc: 83.26%, TrainLoss: 0.2431, ValLoss: 0.8980, LR: 0.001
[2025-07-30 07:47:14,076] [INFO] Epoch 9/50, ValAcc: 83.72%, TrainLoss: 0.1932, ValLoss: 0.9194, LR: 0.001
[2025-07-30 07:47:32,382] [INFO] Epoch 10/50, ValAcc: 86.74%, TrainLoss: 0.1048, ValLoss: 0.8717, LR: 0.0005
[2025-07-30 07:47:50,704] [INFO] Epoch 11/50, ValAcc: 87.00%, TrainLoss: 0.0659, ValLoss: 0.9582, LR: 0.0005
[2025-07-30 07:48:09,030] [INFO] Epoch 12/50, ValAcc: 86.74%, TrainLoss: 0.0504, ValLoss: 1.0019, LR: 0.0005
[2025-07-30 07:48:27,358] [INFO] Epoch 13/50, ValAcc: 86.93%, TrainLoss: 0.0384, ValLoss: 0.9889, LR: 0.00025
[2025-07-30 07:48:45,671] [INFO] Epoch 14/50, ValAcc: 87.46%, TrainLoss: 0.0317, ValLoss: 0.9905, LR: 0.00025
[2025-07-30 07:49:03,993] [INFO] Epoch 15/50, ValAcc: 87.20%, TrainLoss: 0.0282, ValLoss: 1.0350, LR: 0.00025
[2025-07-30 07:49:22,306] [INFO] Epoch 16/50, ValAcc: 86.80%, TrainLoss: 0.0249, ValLoss: 1.0623, LR: 0.000125
[2025-07-30 07:49:40,627] [INFO] Epoch 17/50, ValAcc: 87.39%, TrainLoss: 0.0231, ValLoss: 1.0822, LR: 0.000125
[2025-07-30 07:49:58,929] [INFO] Epoch 18/50, ValAcc: 87.07%, TrainLoss: 0.0201, ValLoss: 1.1024, LR: 0.000125
[2025-07-30 07:50:17,253] [INFO] Epoch 19/50, ValAcc: 87.07%, TrainLoss: 0.0197, ValLoss: 1.1050, LR: 6.25e-05
[2025-07-30 07:50:17,253] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-30 07:50:19,124] [INFO] Namespace(path=['vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=1000, kfold=5, model=['bigru'], norm=['token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753861418.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753861418.csv', step1=False, step2=False, step3=False, train=True, train_sliding=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='tcpwindow_token_bigru_1000_64_50_0.001_512_256_3_0.3_256_128'),0.8592,0.8575,0.8601,0.8583
[2025-07-30 07:50:19,124] [INFO] Training Fold 2/5
[2025-07-30 07:50:32,497] [INFO] Feature 0 normalized using token
[2025-07-30 07:50:32,497] [INFO] Train shape: (10659, 1000), Val shape: (1523, 1000), Test shape: (3046, 1000)
[2025-07-30 07:50:32,529] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(5091, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-30 07:50:32,529] [INFO] Training...
[2025-07-30 07:50:50,878] [INFO] Epoch 1/50, ValAcc: 50.82%, TrainLoss: 2.8973, ValLoss: 1.7728, LR: 0.001
[2025-07-30 07:51:09,208] [INFO] Epoch 2/50, ValAcc: 69.34%, TrainLoss: 1.4792, ValLoss: 1.0791, LR: 0.001
[2025-07-30 07:51:27,529] [INFO] Epoch 3/50, ValAcc: 74.39%, TrainLoss: 0.9079, ValLoss: 0.9125, LR: 0.001
[2025-07-30 07:51:45,858] [INFO] Epoch 4/50, ValAcc: 77.81%, TrainLoss: 0.6259, ValLoss: 0.8141, LR: 0.001
[2025-07-30 07:52:04,178] [INFO] Epoch 5/50, ValAcc: 80.24%, TrainLoss: 0.4357, ValLoss: 0.7689, LR: 0.001
[2025-07-30 07:52:22,497] [INFO] Epoch 6/50, ValAcc: 80.56%, TrainLoss: 0.3501, ValLoss: 0.8057, LR: 0.001
[2025-07-30 07:52:40,828] [INFO] Epoch 7/50, ValAcc: 80.89%, TrainLoss: 0.2822, ValLoss: 0.8278, LR: 0.001
[2025-07-30 07:52:59,146] [INFO] Epoch 8/50, ValAcc: 82.60%, TrainLoss: 0.2376, ValLoss: 0.7816, LR: 0.001
[2025-07-30 07:53:17,470] [INFO] Epoch 9/50, ValAcc: 84.77%, TrainLoss: 0.1315, ValLoss: 0.7466, LR: 0.0005
[2025-07-30 07:53:35,902] [INFO] Epoch 10/50, ValAcc: 85.36%, TrainLoss: 0.0913, ValLoss: 0.7553, LR: 0.0005
[2025-07-30 07:53:54,218] [INFO] Epoch 11/50, ValAcc: 84.96%, TrainLoss: 0.0681, ValLoss: 0.8110, LR: 0.0005
[2025-07-30 07:54:12,533] [INFO] Epoch 12/50, ValAcc: 85.16%, TrainLoss: 0.0518, ValLoss: 0.8436, LR: 0.0005
[2025-07-30 07:54:30,853] [INFO] Epoch 13/50, ValAcc: 85.10%, TrainLoss: 0.0360, ValLoss: 0.8813, LR: 0.00025
[2025-07-30 07:54:49,153] [INFO] Epoch 14/50, ValAcc: 85.23%, TrainLoss: 0.0299, ValLoss: 0.9019, LR: 0.00025
[2025-07-30 07:55:07,468] [INFO] Epoch 15/50, ValAcc: 85.23%, TrainLoss: 0.0260, ValLoss: 0.9567, LR: 0.00025
[2025-07-30 07:55:25,783] [INFO] Epoch 16/50, ValAcc: 84.77%, TrainLoss: 0.0230, ValLoss: 0.9555, LR: 0.000125
[2025-07-30 07:55:44,098] [INFO] Epoch 17/50, ValAcc: 85.03%, TrainLoss: 0.0193, ValLoss: 0.9676, LR: 0.000125
[2025-07-30 07:56:02,415] [INFO] Epoch 18/50, ValAcc: 85.23%, TrainLoss: 0.0194, ValLoss: 0.9832, LR: 0.000125
[2025-07-30 07:56:20,735] [INFO] Epoch 19/50, ValAcc: 85.36%, TrainLoss: 0.0163, ValLoss: 0.9823, LR: 6.25e-05
[2025-07-30 07:56:20,735] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-30 07:56:22,638] [INFO] Namespace(path=['vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=1000, kfold=5, model=['bigru'], norm=['token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753861418.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753861418.csv', step1=False, step2=False, step3=False, train=True, train_sliding=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='tcpwindow_token_bigru_1000_64_50_0.001_512_256_3_0.3_256_128'),0.8414,0.8444,0.8459,0.8456
[2025-07-30 07:56:22,639] [INFO] Training Fold 3/5
[2025-07-30 07:56:36,475] [INFO] Feature 0 normalized using token
[2025-07-30 07:56:36,476] [INFO] Train shape: (10659, 1000), Val shape: (1523, 1000), Test shape: (3046, 1000)
[2025-07-30 07:56:36,510] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(5118, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-30 07:56:36,510] [INFO] Training...
[2025-07-30 07:56:54,834] [INFO] Epoch 1/50, ValAcc: 49.70%, TrainLoss: 2.9234, ValLoss: 1.8528, LR: 0.001
[2025-07-30 07:57:13,149] [INFO] Epoch 2/50, ValAcc: 68.81%, TrainLoss: 1.4869, ValLoss: 1.1232, LR: 0.001
[2025-07-30 07:57:31,462] [INFO] Epoch 3/50, ValAcc: 75.64%, TrainLoss: 0.9100, ValLoss: 0.9137, LR: 0.001
[2025-07-30 07:57:49,773] [INFO] Epoch 4/50, ValAcc: 79.12%, TrainLoss: 0.6213, ValLoss: 0.7935, LR: 0.001
[2025-07-30 07:58:08,094] [INFO] Epoch 5/50, ValAcc: 80.89%, TrainLoss: 0.4430, ValLoss: 0.7570, LR: 0.001
[2025-07-30 07:58:26,401] [INFO] Epoch 6/50, ValAcc: 81.62%, TrainLoss: 0.3542, ValLoss: 0.8357, LR: 0.001
[2025-07-30 07:58:44,714] [INFO] Epoch 7/50, ValAcc: 81.42%, TrainLoss: 0.2672, ValLoss: 0.8547, LR: 0.001
[2025-07-30 07:59:03,033] [INFO] Epoch 8/50, ValAcc: 83.19%, TrainLoss: 0.2032, ValLoss: 0.8833, LR: 0.001
[2025-07-30 07:59:21,339] [INFO] Epoch 9/50, ValAcc: 85.95%, TrainLoss: 0.1172, ValLoss: 0.7969, LR: 0.0005
[2025-07-30 07:59:39,653] [INFO] Epoch 10/50, ValAcc: 85.49%, TrainLoss: 0.0714, ValLoss: 0.8630, LR: 0.0005
[2025-07-30 07:59:57,964] [INFO] Epoch 11/50, ValAcc: 84.96%, TrainLoss: 0.0593, ValLoss: 0.9343, LR: 0.0005
[2025-07-30 08:00:16,285] [INFO] Epoch 12/50, ValAcc: 85.55%, TrainLoss: 0.0484, ValLoss: 0.9419, LR: 0.00025
[2025-07-30 08:00:34,588] [INFO] Epoch 13/50, ValAcc: 85.69%, TrainLoss: 0.0351, ValLoss: 0.9492, LR: 0.00025
[2025-07-30 08:00:52,901] [INFO] Epoch 14/50, ValAcc: 85.62%, TrainLoss: 0.0335, ValLoss: 0.9949, LR: 0.00025
[2025-07-30 08:01:11,217] [INFO] Epoch 15/50, ValAcc: 86.08%, TrainLoss: 0.0273, ValLoss: 0.9901, LR: 0.000125
[2025-07-30 08:01:29,526] [INFO] Epoch 16/50, ValAcc: 85.62%, TrainLoss: 0.0266, ValLoss: 1.0163, LR: 0.000125
[2025-07-30 08:01:47,835] [INFO] Epoch 17/50, ValAcc: 85.82%, TrainLoss: 0.0259, ValLoss: 1.0247, LR: 0.000125
[2025-07-30 08:02:06,153] [INFO] Epoch 18/50, ValAcc: 85.69%, TrainLoss: 0.0225, ValLoss: 1.0323, LR: 6.25e-05
[2025-07-30 08:02:06,153] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-30 08:02:08,052] [INFO] Namespace(path=['vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=1000, kfold=5, model=['bigru'], norm=['token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753861418.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753861418.csv', step1=False, step2=False, step3=False, train=True, train_sliding=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='tcpwindow_token_bigru_1000_64_50_0.001_512_256_3_0.3_256_128'),0.8654,0.8661,0.8692,0.8667
[2025-07-30 08:02:08,052] [INFO] Training Fold 4/5
[2025-07-30 08:02:21,895] [INFO] Feature 0 normalized using token
[2025-07-30 08:02:21,895] [INFO] Train shape: (10660, 1000), Val shape: (1523, 1000), Test shape: (3045, 1000)
[2025-07-30 08:02:21,928] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(5144, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-30 08:02:21,928] [INFO] Training...
[2025-07-30 08:02:40,247] [INFO] Epoch 1/50, ValAcc: 53.12%, TrainLoss: 2.8217, ValLoss: 1.7112, LR: 0.001
[2025-07-30 08:02:58,556] [INFO] Epoch 2/50, ValAcc: 70.65%, TrainLoss: 1.4423, ValLoss: 1.0815, LR: 0.001
[2025-07-30 08:03:16,884] [INFO] Epoch 3/50, ValAcc: 75.44%, TrainLoss: 0.8651, ValLoss: 0.9025, LR: 0.001
[2025-07-30 08:03:35,206] [INFO] Epoch 4/50, ValAcc: 79.84%, TrainLoss: 0.5912, ValLoss: 0.8078, LR: 0.001
[2025-07-30 08:03:53,520] [INFO] Epoch 5/50, ValAcc: 80.50%, TrainLoss: 0.4316, ValLoss: 0.8206, LR: 0.001
[2025-07-30 08:04:11,835] [INFO] Epoch 6/50, ValAcc: 82.14%, TrainLoss: 0.3175, ValLoss: 0.8219, LR: 0.001
[2025-07-30 08:04:30,145] [INFO] Epoch 7/50, ValAcc: 81.48%, TrainLoss: 0.2647, ValLoss: 0.9511, LR: 0.001
[2025-07-30 08:04:48,469] [INFO] Epoch 8/50, ValAcc: 85.62%, TrainLoss: 0.1470, ValLoss: 0.8012, LR: 0.0005
[2025-07-30 08:05:06,794] [INFO] Epoch 9/50, ValAcc: 85.95%, TrainLoss: 0.0868, ValLoss: 0.8788, LR: 0.0005
[2025-07-30 08:05:25,108] [INFO] Epoch 10/50, ValAcc: 86.28%, TrainLoss: 0.0689, ValLoss: 0.8746, LR: 0.0005
[2025-07-30 08:05:43,421] [INFO] Epoch 11/50, ValAcc: 86.80%, TrainLoss: 0.0598, ValLoss: 0.9478, LR: 0.0005
[2025-07-30 08:06:01,750] [INFO] Epoch 12/50, ValAcc: 86.41%, TrainLoss: 0.0408, ValLoss: 0.9437, LR: 0.00025
[2025-07-30 08:06:20,062] [INFO] Epoch 13/50, ValAcc: 86.21%, TrainLoss: 0.0314, ValLoss: 0.9768, LR: 0.00025
[2025-07-30 08:06:38,378] [INFO] Epoch 14/50, ValAcc: 87.00%, TrainLoss: 0.0282, ValLoss: 0.9892, LR: 0.00025
[2025-07-30 08:06:56,712] [INFO] Epoch 15/50, ValAcc: 86.47%, TrainLoss: 0.0240, ValLoss: 0.9944, LR: 0.000125
[2025-07-30 08:07:15,034] [INFO] Epoch 16/50, ValAcc: 86.47%, TrainLoss: 0.0224, ValLoss: 1.0112, LR: 0.000125
[2025-07-30 08:07:33,354] [INFO] Epoch 17/50, ValAcc: 86.54%, TrainLoss: 0.0232, ValLoss: 1.0219, LR: 0.000125
[2025-07-30 08:07:51,687] [INFO] Epoch 18/50, ValAcc: 86.54%, TrainLoss: 0.0212, ValLoss: 1.0251, LR: 6.25e-05
[2025-07-30 08:07:51,687] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-30 08:07:53,598] [INFO] Namespace(path=['vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=1000, kfold=5, model=['bigru'], norm=['token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753861418.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753861418.csv', step1=False, step2=False, step3=False, train=True, train_sliding=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='tcpwindow_token_bigru_1000_64_50_0.001_512_256_3_0.3_256_128'),0.8680,0.8662,0.8683,0.8679
[2025-07-30 08:07:53,598] [INFO] Training Fold 5/5
[2025-07-30 08:08:07,498] [INFO] Feature 0 normalized using token
[2025-07-30 08:08:07,498] [INFO] Train shape: (10660, 1000), Val shape: (1523, 1000), Test shape: (3045, 1000)
[2025-07-30 08:08:07,535] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(5138, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-30 08:08:07,535] [INFO] Training...
[2025-07-30 08:08:25,855] [INFO] Epoch 1/50, ValAcc: 51.74%, TrainLoss: 2.9094, ValLoss: 1.7362, LR: 0.001
[2025-07-30 08:08:44,220] [INFO] Epoch 2/50, ValAcc: 71.96%, TrainLoss: 1.4478, ValLoss: 1.0374, LR: 0.001
[2025-07-30 08:09:02,598] [INFO] Epoch 3/50, ValAcc: 78.20%, TrainLoss: 0.8737, ValLoss: 0.7843, LR: 0.001
[2025-07-30 08:09:20,972] [INFO] Epoch 4/50, ValAcc: 79.91%, TrainLoss: 0.6152, ValLoss: 0.7728, LR: 0.001
[2025-07-30 08:09:39,337] [INFO] Epoch 5/50, ValAcc: 82.21%, TrainLoss: 0.4393, ValLoss: 0.7193, LR: 0.001
[2025-07-30 08:09:57,694] [INFO] Epoch 6/50, ValAcc: 82.80%, TrainLoss: 0.3329, ValLoss: 0.7457, LR: 0.001
[2025-07-30 08:10:16,066] [INFO] Epoch 7/50, ValAcc: 83.59%, TrainLoss: 0.2636, ValLoss: 0.7661, LR: 0.001
[2025-07-30 08:10:34,441] [INFO] Epoch 8/50, ValAcc: 83.45%, TrainLoss: 0.2433, ValLoss: 0.7836, LR: 0.001
[2025-07-30 08:10:52,804] [INFO] Epoch 9/50, ValAcc: 85.62%, TrainLoss: 0.1427, ValLoss: 0.7673, LR: 0.0005
[2025-07-30 08:11:11,164] [INFO] Epoch 10/50, ValAcc: 86.41%, TrainLoss: 0.0890, ValLoss: 0.8045, LR: 0.0005
[2025-07-30 08:11:29,552] [INFO] Epoch 11/50, ValAcc: 86.74%, TrainLoss: 0.0696, ValLoss: 0.8637, LR: 0.0005
[2025-07-30 08:11:47,915] [INFO] Epoch 12/50, ValAcc: 86.67%, TrainLoss: 0.0504, ValLoss: 0.8689, LR: 0.00025
[2025-07-30 08:12:06,288] [INFO] Epoch 13/50, ValAcc: 86.74%, TrainLoss: 0.0402, ValLoss: 0.8824, LR: 0.00025
[2025-07-30 08:12:24,675] [INFO] Epoch 14/50, ValAcc: 86.61%, TrainLoss: 0.0346, ValLoss: 0.9163, LR: 0.00025
[2025-07-30 08:12:43,037] [INFO] Epoch 15/50, ValAcc: 86.54%, TrainLoss: 0.0305, ValLoss: 0.9215, LR: 0.000125
[2025-07-30 08:13:01,403] [INFO] Epoch 16/50, ValAcc: 86.93%, TrainLoss: 0.0272, ValLoss: 0.9325, LR: 0.000125
[2025-07-30 08:13:19,774] [INFO] Epoch 17/50, ValAcc: 87.07%, TrainLoss: 0.0243, ValLoss: 0.9343, LR: 0.000125
[2025-07-30 08:13:38,162] [INFO] Epoch 18/50, ValAcc: 87.13%, TrainLoss: 0.0223, ValLoss: 0.9395, LR: 6.25e-05
[2025-07-30 08:13:38,162] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-30 08:13:40,047] [INFO] Namespace(path=['vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=1000, kfold=5, model=['bigru'], norm=['token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753861418.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753861418.csv', step1=False, step2=False, step3=False, train=True, train_sliding=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='tcpwindow_token_bigru_1000_64_50_0.001_512_256_3_0.3_256_128'),0.8650,0.8641,0.8670,0.8639
[2025-07-30 08:13:40,288] [INFO] [(0.8591595535128037, 0.857472065941654, 0.8601366182477053, 0.8582609708977192), (0.8414313854235063, 0.8443764265540565, 0.8458859576970853, 0.8455782989930044), (0.8653972422849638, 0.866099931641897, 0.8691892621177773, 0.8667013169869077), (0.8679802955665025, 0.8661670025777347, 0.8682929723914463, 0.8679406461835825), (0.865024630541872, 0.8641163066618721, 0.8669737116933074, 0.8639114777516625)]
Running python vrscanner.py --train --debug_path output/vrchat-worlds/train/train_meta_1753863221.debug --leaderboard_path output/vrchat-worlds/train/train_meta_1753863221.csv --kfold 5 --pktcount 2000 --input_dim 512 --hidden_size 256 --num_layers 3 --dropout 0.3 --fusion_dim 256 --fc_hidden_size 128 --epoch 50 --lr 0.001 --path vrchat-worlds/meta-tcp_window/meta-tcp_window.csv --norm token --model bigru
[2025-07-30 08:13:42,645] [INFO] Namespace(path=['vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=2000, kfold=5, model=['bigru'], norm=['token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753863221.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753863221.csv', step1=False, step2=False, step3=False, train=True, train_sliding=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'))
[2025-07-30 08:14:16,710] [INFO] Processed data from vrchat-worlds/meta-tcp_window/meta-tcp_window.csv:
[2025-07-30 08:14:16,710] [INFO] (15228, 2000)
[2025-07-30 08:14:16,710] [INFO] [['1281' '1281' '580' ... '300' '300' '300']
 ['65535' '65535' '256' ... '774' '2566' '2566']
 ['2038' '2038' '2038' ... '289' '289' '300']
 ...
 ['265' '774' '774' ... '268' '268' '310']
 ['265' '265' '332' ... '282' '282' '310']
 ['343' '761' '300' ... '774' '65535' '65535']]
[2025-07-30 08:14:16,818] [INFO] Training Fold 1/5
[2025-07-30 08:14:47,130] [INFO] Feature 0 normalized using token
[2025-07-30 08:14:47,131] [INFO] Train shape: (10659, 2000), Val shape: (1523, 2000), Test shape: (3046, 2000)
[2025-07-30 08:14:47,199] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(5717, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-30 08:14:47,199] [INFO] Training...
[2025-07-30 08:15:25,002] [INFO] Epoch 1/50, ValAcc: 50.23%, TrainLoss: 2.9392, ValLoss: 1.8875, LR: 0.001
[2025-07-30 08:16:01,490] [INFO] Epoch 2/50, ValAcc: 72.62%, TrainLoss: 1.4853, ValLoss: 1.0091, LR: 0.001
[2025-07-30 08:16:37,993] [INFO] Epoch 3/50, ValAcc: 81.16%, TrainLoss: 0.8438, ValLoss: 0.7128, LR: 0.001
[2025-07-30 08:17:14,457] [INFO] Epoch 4/50, ValAcc: 81.94%, TrainLoss: 0.5632, ValLoss: 0.7055, LR: 0.001
[2025-07-30 08:17:50,937] [INFO] Epoch 5/50, ValAcc: 85.49%, TrainLoss: 0.4070, ValLoss: 0.5682, LR: 0.001
[2025-07-30 08:18:27,386] [INFO] Epoch 6/50, ValAcc: 85.49%, TrainLoss: 0.3296, ValLoss: 0.6058, LR: 0.001
[2025-07-30 08:19:03,826] [INFO] Epoch 7/50, ValAcc: 86.61%, TrainLoss: 0.2551, ValLoss: 0.6637, LR: 0.001
[2025-07-30 08:19:39,954] [INFO] Epoch 8/50, ValAcc: 87.66%, TrainLoss: 0.2009, ValLoss: 0.6199, LR: 0.001
[2025-07-30 08:20:16,046] [INFO] Epoch 9/50, ValAcc: 90.15%, TrainLoss: 0.0995, ValLoss: 0.6277, LR: 0.0005
[2025-07-30 08:20:52,119] [INFO] Epoch 10/50, ValAcc: 90.22%, TrainLoss: 0.0623, ValLoss: 0.6501, LR: 0.0005
[2025-07-30 08:21:28,187] [INFO] Epoch 11/50, ValAcc: 91.07%, TrainLoss: 0.0516, ValLoss: 0.6533, LR: 0.0005
[2025-07-30 08:22:04,270] [INFO] Epoch 12/50, ValAcc: 90.41%, TrainLoss: 0.0380, ValLoss: 0.6654, LR: 0.00025
[2025-07-30 08:22:40,346] [INFO] Epoch 13/50, ValAcc: 90.54%, TrainLoss: 0.0333, ValLoss: 0.7061, LR: 0.00025
[2025-07-30 08:23:16,419] [INFO] Epoch 14/50, ValAcc: 90.74%, TrainLoss: 0.0288, ValLoss: 0.7181, LR: 0.00025
[2025-07-30 08:23:52,402] [INFO] Epoch 15/50, ValAcc: 90.48%, TrainLoss: 0.0257, ValLoss: 0.7280, LR: 0.000125
[2025-07-30 08:24:28,341] [INFO] Epoch 16/50, ValAcc: 90.54%, TrainLoss: 0.0241, ValLoss: 0.7434, LR: 0.000125
[2025-07-30 08:25:04,267] [INFO] Epoch 17/50, ValAcc: 90.54%, TrainLoss: 0.0227, ValLoss: 0.7448, LR: 0.000125
[2025-07-30 08:25:40,210] [INFO] Epoch 18/50, ValAcc: 90.68%, TrainLoss: 0.0209, ValLoss: 0.7601, LR: 6.25e-05
[2025-07-30 08:25:40,210] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-30 08:25:43,923] [INFO] Namespace(path=['vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=2000, kfold=5, model=['bigru'], norm=['token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753863221.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753863221.csv', step1=False, step2=False, step3=False, train=True, train_sliding=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='tcpwindow_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.9058,0.9038,0.9053,0.9049
[2025-07-30 08:25:43,924] [INFO] Training Fold 2/5
[2025-07-30 08:26:14,861] [INFO] Feature 0 normalized using token
[2025-07-30 08:26:14,861] [INFO] Train shape: (10659, 2000), Val shape: (1523, 2000), Test shape: (3046, 2000)
[2025-07-30 08:26:14,908] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(5660, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-30 08:26:14,909] [INFO] Training...
[2025-07-30 08:26:50,868] [INFO] Epoch 1/50, ValAcc: 52.99%, TrainLoss: 2.7855, ValLoss: 1.7292, LR: 0.001
[2025-07-30 08:27:26,820] [INFO] Epoch 2/50, ValAcc: 71.24%, TrainLoss: 1.2864, ValLoss: 0.9655, LR: 0.001
[2025-07-30 08:28:02,762] [INFO] Epoch 3/50, ValAcc: 80.89%, TrainLoss: 0.7357, ValLoss: 0.6823, LR: 0.001
[2025-07-30 08:28:38,711] [INFO] Epoch 4/50, ValAcc: 83.19%, TrainLoss: 0.4824, ValLoss: 0.6496, LR: 0.001
[2025-07-30 08:29:14,668] [INFO] Epoch 5/50, ValAcc: 84.83%, TrainLoss: 0.3435, ValLoss: 0.6320, LR: 0.001
[2025-07-30 08:29:50,636] [INFO] Epoch 6/50, ValAcc: 85.82%, TrainLoss: 0.2632, ValLoss: 0.5795, LR: 0.001
[2025-07-30 08:30:26,580] [INFO] Epoch 7/50, ValAcc: 87.92%, TrainLoss: 0.2092, ValLoss: 0.6097, LR: 0.001
[2025-07-30 08:31:02,533] [INFO] Epoch 8/50, ValAcc: 85.88%, TrainLoss: 0.1836, ValLoss: 0.6401, LR: 0.001
[2025-07-30 08:31:38,471] [INFO] Epoch 9/50, ValAcc: 86.28%, TrainLoss: 0.1700, ValLoss: 0.6771, LR: 0.001
[2025-07-30 08:32:14,431] [INFO] Epoch 10/50, ValAcc: 88.44%, TrainLoss: 0.0847, ValLoss: 0.6238, LR: 0.0005
[2025-07-30 08:32:50,380] [INFO] Epoch 11/50, ValAcc: 88.58%, TrainLoss: 0.0525, ValLoss: 0.6617, LR: 0.0005
[2025-07-30 08:33:26,328] [INFO] Epoch 12/50, ValAcc: 89.23%, TrainLoss: 0.0408, ValLoss: 0.6319, LR: 0.0005
[2025-07-30 08:34:02,283] [INFO] Epoch 13/50, ValAcc: 89.36%, TrainLoss: 0.0288, ValLoss: 0.6438, LR: 0.00025
[2025-07-30 08:34:38,234] [INFO] Epoch 14/50, ValAcc: 89.03%, TrainLoss: 0.0250, ValLoss: 0.6632, LR: 0.00025
[2025-07-30 08:35:14,175] [INFO] Epoch 15/50, ValAcc: 89.43%, TrainLoss: 0.0229, ValLoss: 0.6731, LR: 0.00025
[2025-07-30 08:35:50,132] [INFO] Epoch 16/50, ValAcc: 89.43%, TrainLoss: 0.0196, ValLoss: 0.6805, LR: 0.000125
[2025-07-30 08:36:26,093] [INFO] Epoch 17/50, ValAcc: 89.17%, TrainLoss: 0.0175, ValLoss: 0.6955, LR: 0.000125
[2025-07-30 08:37:02,045] [INFO] Epoch 18/50, ValAcc: 89.49%, TrainLoss: 0.0167, ValLoss: 0.6998, LR: 0.000125
[2025-07-30 08:37:38,003] [INFO] Epoch 19/50, ValAcc: 89.82%, TrainLoss: 0.0151, ValLoss: 0.7010, LR: 6.25e-05
[2025-07-30 08:37:38,003] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-30 08:37:41,723] [INFO] Namespace(path=['vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=2000, kfold=5, model=['bigru'], norm=['token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753863221.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753863221.csv', step1=False, step2=False, step3=False, train=True, train_sliding=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='tcpwindow_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.9028,0.9036,0.9051,0.9044
[2025-07-30 08:37:41,723] [INFO] Training Fold 3/5
[2025-07-30 08:38:12,094] [INFO] Feature 0 normalized using token
[2025-07-30 08:38:12,094] [INFO] Train shape: (10659, 2000), Val shape: (1523, 2000), Test shape: (3046, 2000)
[2025-07-30 08:38:12,138] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(5654, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-30 08:38:12,138] [INFO] Training...
[2025-07-30 08:38:48,066] [INFO] Epoch 1/50, ValAcc: 52.20%, TrainLoss: 2.8519, ValLoss: 1.7908, LR: 0.001
[2025-07-30 08:39:24,014] [INFO] Epoch 2/50, ValAcc: 71.31%, TrainLoss: 1.4138, ValLoss: 1.0106, LR: 0.001
[2025-07-30 08:39:59,952] [INFO] Epoch 3/50, ValAcc: 77.61%, TrainLoss: 0.8199, ValLoss: 0.7766, LR: 0.001
[2025-07-30 08:40:35,863] [INFO] Epoch 4/50, ValAcc: 82.07%, TrainLoss: 0.5717, ValLoss: 0.6657, LR: 0.001
[2025-07-30 08:41:11,901] [INFO] Epoch 5/50, ValAcc: 83.32%, TrainLoss: 0.3915, ValLoss: 0.6894, LR: 0.001
[2025-07-30 08:41:48,318] [INFO] Epoch 6/50, ValAcc: 85.55%, TrainLoss: 0.3194, ValLoss: 0.6210, LR: 0.001
[2025-07-30 08:42:24,762] [INFO] Epoch 7/50, ValAcc: 86.01%, TrainLoss: 0.2446, ValLoss: 0.6004, LR: 0.001
[2025-07-30 08:43:01,190] [INFO] Epoch 8/50, ValAcc: 86.01%, TrainLoss: 0.2150, ValLoss: 0.6665, LR: 0.001
[2025-07-30 08:43:37,614] [INFO] Epoch 9/50, ValAcc: 87.33%, TrainLoss: 0.1759, ValLoss: 0.6412, LR: 0.001
[2025-07-30 08:44:14,098] [INFO] Epoch 10/50, ValAcc: 87.85%, TrainLoss: 0.1403, ValLoss: 0.7135, LR: 0.001
[2025-07-30 08:44:50,534] [INFO] Epoch 11/50, ValAcc: 88.90%, TrainLoss: 0.0778, ValLoss: 0.6509, LR: 0.0005
[2025-07-30 08:45:26,965] [INFO] Epoch 12/50, ValAcc: 89.63%, TrainLoss: 0.0439, ValLoss: 0.6797, LR: 0.0005
[2025-07-30 08:46:03,412] [INFO] Epoch 13/50, ValAcc: 89.43%, TrainLoss: 0.0339, ValLoss: 0.6919, LR: 0.0005
[2025-07-30 08:46:39,843] [INFO] Epoch 14/50, ValAcc: 89.43%, TrainLoss: 0.0309, ValLoss: 0.6920, LR: 0.00025
[2025-07-30 08:47:16,288] [INFO] Epoch 15/50, ValAcc: 89.63%, TrainLoss: 0.0254, ValLoss: 0.7025, LR: 0.00025
[2025-07-30 08:47:52,733] [INFO] Epoch 16/50, ValAcc: 89.30%, TrainLoss: 0.0216, ValLoss: 0.7325, LR: 0.00025
[2025-07-30 08:48:29,158] [INFO] Epoch 17/50, ValAcc: 89.49%, TrainLoss: 0.0203, ValLoss: 0.7205, LR: 0.000125
[2025-07-30 08:49:05,661] [INFO] Epoch 18/50, ValAcc: 89.95%, TrainLoss: 0.0176, ValLoss: 0.7307, LR: 0.000125
[2025-07-30 08:49:42,093] [INFO] Epoch 19/50, ValAcc: 90.09%, TrainLoss: 0.0164, ValLoss: 0.7560, LR: 0.000125
[2025-07-30 08:50:18,528] [INFO] Epoch 20/50, ValAcc: 89.63%, TrainLoss: 0.0156, ValLoss: 0.7565, LR: 6.25e-05
[2025-07-30 08:50:18,528] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-30 08:50:22,242] [INFO] Namespace(path=['vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=2000, kfold=5, model=['bigru'], norm=['token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753863221.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753863221.csv', step1=False, step2=False, step3=False, train=True, train_sliding=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='tcpwindow_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.8936,0.8940,0.8959,0.8949
[2025-07-30 08:50:22,242] [INFO] Training Fold 4/5
[2025-07-30 08:50:53,515] [INFO] Feature 0 normalized using token
[2025-07-30 08:50:53,516] [INFO] Train shape: (10660, 2000), Val shape: (1523, 2000), Test shape: (3045, 2000)
[2025-07-30 08:50:53,562] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(5720, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-30 08:50:53,562] [INFO] Training...
[2025-07-30 08:51:30,029] [INFO] Epoch 1/50, ValAcc: 53.51%, TrainLoss: 2.8032, ValLoss: 1.6889, LR: 0.001
[2025-07-30 08:52:06,469] [INFO] Epoch 2/50, ValAcc: 73.21%, TrainLoss: 1.3649, ValLoss: 1.0012, LR: 0.001
[2025-07-30 08:52:42,910] [INFO] Epoch 3/50, ValAcc: 80.04%, TrainLoss: 0.8016, ValLoss: 0.7355, LR: 0.001
[2025-07-30 08:53:19,337] [INFO] Epoch 4/50, ValAcc: 81.35%, TrainLoss: 0.5532, ValLoss: 0.6552, LR: 0.001
[2025-07-30 08:53:55,794] [INFO] Epoch 5/50, ValAcc: 83.72%, TrainLoss: 0.3977, ValLoss: 0.6492, LR: 0.001
[2025-07-30 08:54:32,237] [INFO] Epoch 6/50, ValAcc: 84.77%, TrainLoss: 0.3069, ValLoss: 0.6420, LR: 0.001
[2025-07-30 08:55:08,681] [INFO] Epoch 7/50, ValAcc: 85.75%, TrainLoss: 0.2373, ValLoss: 0.6080, LR: 0.001
[2025-07-30 08:55:45,144] [INFO] Epoch 8/50, ValAcc: 86.21%, TrainLoss: 0.1980, ValLoss: 0.6995, LR: 0.001
[2025-07-30 08:56:21,578] [INFO] Epoch 9/50, ValAcc: 85.69%, TrainLoss: 0.1687, ValLoss: 0.6640, LR: 0.001
[2025-07-30 08:56:58,069] [INFO] Epoch 10/50, ValAcc: 87.46%, TrainLoss: 0.1406, ValLoss: 0.7522, LR: 0.001
[2025-07-30 08:57:34,525] [INFO] Epoch 11/50, ValAcc: 89.03%, TrainLoss: 0.0787, ValLoss: 0.6456, LR: 0.0005
[2025-07-30 08:58:10,967] [INFO] Epoch 12/50, ValAcc: 89.36%, TrainLoss: 0.0457, ValLoss: 0.6876, LR: 0.0005
[2025-07-30 08:58:47,415] [INFO] Epoch 13/50, ValAcc: 89.49%, TrainLoss: 0.0424, ValLoss: 0.6928, LR: 0.0005
[2025-07-30 08:59:23,859] [INFO] Epoch 14/50, ValAcc: 89.89%, TrainLoss: 0.0296, ValLoss: 0.6710, LR: 0.00025
[2025-07-30 09:00:00,327] [INFO] Epoch 15/50, ValAcc: 89.95%, TrainLoss: 0.0271, ValLoss: 0.7073, LR: 0.00025
[2025-07-30 09:00:36,823] [INFO] Epoch 16/50, ValAcc: 89.69%, TrainLoss: 0.0250, ValLoss: 0.7145, LR: 0.00025
[2025-07-30 09:01:13,272] [INFO] Epoch 17/50, ValAcc: 90.02%, TrainLoss: 0.0211, ValLoss: 0.7125, LR: 0.000125
[2025-07-30 09:01:49,705] [INFO] Epoch 18/50, ValAcc: 89.76%, TrainLoss: 0.0201, ValLoss: 0.7234, LR: 0.000125
[2025-07-30 09:02:26,162] [INFO] Epoch 19/50, ValAcc: 89.69%, TrainLoss: 0.0190, ValLoss: 0.7294, LR: 0.000125
[2025-07-30 09:03:02,591] [INFO] Epoch 20/50, ValAcc: 89.95%, TrainLoss: 0.0171, ValLoss: 0.7367, LR: 6.25e-05
[2025-07-30 09:03:02,591] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-30 09:03:06,296] [INFO] Namespace(path=['vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=2000, kfold=5, model=['bigru'], norm=['token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753863221.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753863221.csv', step1=False, step2=False, step3=False, train=True, train_sliding=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='tcpwindow_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.9054,0.9046,0.9062,0.9058
[2025-07-30 09:03:06,297] [INFO] Training Fold 5/5
[2025-07-30 09:03:36,144] [INFO] Feature 0 normalized using token
[2025-07-30 09:03:36,144] [INFO] Train shape: (10660, 2000), Val shape: (1523, 2000), Test shape: (3045, 2000)
[2025-07-30 09:03:36,188] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(5707, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-30 09:03:36,188] [INFO] Training...
[2025-07-30 09:04:12,652] [INFO] Epoch 1/50, ValAcc: 56.99%, TrainLoss: 2.7644, ValLoss: 1.6404, LR: 0.001
[2025-07-30 09:04:49,086] [INFO] Epoch 2/50, ValAcc: 75.38%, TrainLoss: 1.3017, ValLoss: 0.8868, LR: 0.001
[2025-07-30 09:05:25,544] [INFO] Epoch 3/50, ValAcc: 80.63%, TrainLoss: 0.7367, ValLoss: 0.6547, LR: 0.001
[2025-07-30 09:06:01,986] [INFO] Epoch 4/50, ValAcc: 82.60%, TrainLoss: 0.5097, ValLoss: 0.6081, LR: 0.001
[2025-07-30 09:06:38,447] [INFO] Epoch 5/50, ValAcc: 85.82%, TrainLoss: 0.3750, ValLoss: 0.5283, LR: 0.001
[2025-07-30 09:07:14,907] [INFO] Epoch 6/50, ValAcc: 87.46%, TrainLoss: 0.2863, ValLoss: 0.5612, LR: 0.001
[2025-07-30 09:07:51,347] [INFO] Epoch 7/50, ValAcc: 87.92%, TrainLoss: 0.2209, ValLoss: 0.5684, LR: 0.001
[2025-07-30 09:08:27,769] [INFO] Epoch 8/50, ValAcc: 87.07%, TrainLoss: 0.1899, ValLoss: 0.5944, LR: 0.001
[2025-07-30 09:09:04,256] [INFO] Epoch 9/50, ValAcc: 88.97%, TrainLoss: 0.1093, ValLoss: 0.5730, LR: 0.0005
[2025-07-30 09:09:40,405] [INFO] Epoch 10/50, ValAcc: 90.28%, TrainLoss: 0.0615, ValLoss: 0.5582, LR: 0.0005
[2025-07-30 09:10:16,369] [INFO] Epoch 11/50, ValAcc: 90.09%, TrainLoss: 0.0532, ValLoss: 0.5503, LR: 0.0005
[2025-07-30 09:10:52,307] [INFO] Epoch 12/50, ValAcc: 90.15%, TrainLoss: 0.0362, ValLoss: 0.5664, LR: 0.00025
[2025-07-30 09:11:28,255] [INFO] Epoch 13/50, ValAcc: 90.22%, TrainLoss: 0.0301, ValLoss: 0.5912, LR: 0.00025
[2025-07-30 09:12:04,218] [INFO] Epoch 14/50, ValAcc: 90.35%, TrainLoss: 0.0285, ValLoss: 0.6231, LR: 0.00025
[2025-07-30 09:12:40,154] [INFO] Epoch 15/50, ValAcc: 90.54%, TrainLoss: 0.0248, ValLoss: 0.6298, LR: 0.000125
[2025-07-30 09:13:16,533] [INFO] Epoch 16/50, ValAcc: 90.48%, TrainLoss: 0.0223, ValLoss: 0.6399, LR: 0.000125
[2025-07-30 09:13:53,012] [INFO] Epoch 17/50, ValAcc: 90.48%, TrainLoss: 0.0205, ValLoss: 0.6508, LR: 0.000125
[2025-07-30 09:14:29,471] [INFO] Epoch 18/50, ValAcc: 90.48%, TrainLoss: 0.0201, ValLoss: 0.6527, LR: 6.25e-05
[2025-07-30 09:14:29,471] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-30 09:14:33,181] [INFO] Namespace(path=['vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=2000, kfold=5, model=['bigru'], norm=['token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, window_size=300, step_size=100, debug_path='output/vrchat-worlds/train/train_meta_1753863221.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753863221.csv', step1=False, step2=False, step3=False, train=True, train_sliding=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='tcpwindow_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.9044,0.9035,0.9047,0.9041
[2025-07-30 09:14:33,621] [INFO] [(0.9057780695994747, 0.9037937935781813, 0.9052870327488549, 0.9049092696157709), (0.9028233749179252, 0.9036331024186048, 0.9050855904700026, 0.9044410155412994), (0.8936309914642153, 0.8940434212939607, 0.895889154199935, 0.8948619229775855), (0.9054187192118227, 0.9046306582636618, 0.9062109097257307, 0.9058238951857444), (0.9044334975369458, 0.9034776880545443, 0.9046571950912142, 0.904072401537342)]
=== Step4. Script Execution Finished at Wed Jul 30 09:14:34 AM UTC 2025 ===
