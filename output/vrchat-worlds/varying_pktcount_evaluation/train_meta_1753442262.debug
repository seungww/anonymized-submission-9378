[2025-07-25 11:17:44,644] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv', 'vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=2000, importance=False, kfold=1, model=['bigru', 'bigru'], norm=['token', 'token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/vrchat-worlds/train/train_meta_1753442262.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753442262.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'))
[2025-07-25 11:18:26,525] [INFO] Processed data from vrchat-worlds/meta-ip_len/meta-ip_len.csv:
[2025-07-25 11:18:26,526] [INFO] (15228, 2000)
[2025-07-25 11:18:26,526] [INFO] [['244' '141' '52' ... '1432' '1432' '1432']
 ['60' '60' '52' ... '52' '242' '143']
 ['1432' '1432' '1432' ... '1432' '1432' '1432']
 ...
 ['52' '1432' '1432' ... '76' '52' '52']
 ['1432' '340' '52' ... '76' '52' '52']
 ['52' '52' '1432' ... '52' '60' '60']]
[2025-07-25 11:19:11,753] [INFO] Processed data from vrchat-worlds/meta-tcp_window/meta-tcp_window.csv:
[2025-07-25 11:19:11,753] [INFO] (15228, 2000)
[2025-07-25 11:19:11,753] [INFO] [['1281' '1281' '580' ... '300' '300' '300']
 ['65535' '65535' '256' ... '774' '2566' '2566']
 ['2038' '2038' '2038' ... '289' '289' '300']
 ...
 ['265' '774' '774' ... '268' '268' '310']
 ['265' '265' '332' ... '282' '282' '310']
 ['343' '761' '300' ... '774' '65535' '65535']]
[2025-07-25 11:19:46,903] [INFO] Feature 0 normalized using token
[2025-07-25 11:19:46,903] [INFO] Train shape: (10659, 2000), Val shape: (1523, 2000), Test shape: (3046, 2000)
[2025-07-25 11:20:23,767] [INFO] Feature 1 normalized using token
[2025-07-25 11:20:23,767] [INFO] Train shape: (10659, 2000), Val shape: (1523, 2000), Test shape: (3046, 2000)
[2025-07-25 11:20:23,884] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1384, 512)
    (1): Embedding(5677, 512)
  )
  (rnn_layers): ModuleList(
    (0-1): 2 x GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0-1): 2 x Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=50, bias=True)
  )
)
[2025-07-25 11:20:23,884] [INFO] Training...
[2025-07-25 11:21:49,143] [INFO] Epoch 1/50, ValAcc: 55.55%, TrainLoss: 2.8507, ValLoss: 1.7012, LR: 0.001
[2025-07-25 11:23:13,232] [INFO] Epoch 2/50, ValAcc: 72.29%, TrainLoss: 1.3463, ValLoss: 0.9811, LR: 0.001
[2025-07-25 11:24:37,341] [INFO] Epoch 3/50, ValAcc: 80.11%, TrainLoss: 0.8241, ValLoss: 0.7375, LR: 0.001
[2025-07-25 11:26:01,363] [INFO] Epoch 4/50, ValAcc: 79.71%, TrainLoss: 0.5510, ValLoss: 0.6984, LR: 0.001
[2025-07-25 11:27:25,545] [INFO] Epoch 5/50, ValAcc: 83.65%, TrainLoss: 0.4201, ValLoss: 0.6568, LR: 0.001
[2025-07-25 11:28:49,722] [INFO] Epoch 6/50, ValAcc: 83.45%, TrainLoss: 0.3204, ValLoss: 0.6295, LR: 0.001
[2025-07-25 11:30:13,847] [INFO] Epoch 7/50, ValAcc: 83.19%, TrainLoss: 0.2676, ValLoss: 0.6869, LR: 0.001
[2025-07-25 11:31:37,986] [INFO] Epoch 8/50, ValAcc: 86.47%, TrainLoss: 0.2246, ValLoss: 0.6055, LR: 0.001
[2025-07-25 11:33:02,088] [INFO] Epoch 9/50, ValAcc: 86.28%, TrainLoss: 0.1830, ValLoss: 0.6899, LR: 0.001
[2025-07-25 11:34:26,208] [INFO] Epoch 10/50, ValAcc: 86.61%, TrainLoss: 0.1696, ValLoss: 0.6718, LR: 0.001
[2025-07-25 11:35:50,336] [INFO] Epoch 11/50, ValAcc: 87.39%, TrainLoss: 0.1233, ValLoss: 0.6780, LR: 0.001
[2025-07-25 11:37:14,481] [INFO] Epoch 12/50, ValAcc: 88.64%, TrainLoss: 0.0681, ValLoss: 0.6623, LR: 0.0005
[2025-07-25 11:38:38,652] [INFO] Epoch 13/50, ValAcc: 89.56%, TrainLoss: 0.0428, ValLoss: 0.6577, LR: 0.0005
[2025-07-25 11:40:02,840] [INFO] Epoch 14/50, ValAcc: 89.76%, TrainLoss: 0.0362, ValLoss: 0.7041, LR: 0.0005
[2025-07-25 11:41:26,991] [INFO] Epoch 15/50, ValAcc: 90.28%, TrainLoss: 0.0286, ValLoss: 0.6812, LR: 0.00025
[2025-07-25 11:42:51,196] [INFO] Epoch 16/50, ValAcc: 89.63%, TrainLoss: 0.0253, ValLoss: 0.6887, LR: 0.00025
[2025-07-25 11:44:15,310] [INFO] Epoch 17/50, ValAcc: 89.69%, TrainLoss: 0.0234, ValLoss: 0.7165, LR: 0.00025
[2025-07-25 11:45:39,477] [INFO] Epoch 18/50, ValAcc: 89.69%, TrainLoss: 0.0206, ValLoss: 0.7158, LR: 0.000125
[2025-07-25 11:47:03,480] [INFO] Epoch 19/50, ValAcc: 89.89%, TrainLoss: 0.0181, ValLoss: 0.7323, LR: 0.000125
[2025-07-25 11:48:27,603] [INFO] Epoch 20/50, ValAcc: 89.82%, TrainLoss: 0.0179, ValLoss: 0.7255, LR: 0.000125
[2025-07-25 11:49:51,760] [INFO] Epoch 21/50, ValAcc: 90.02%, TrainLoss: 0.0156, ValLoss: 0.7303, LR: 6.25e-05
[2025-07-25 11:49:51,760] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-25 11:49:59,862] [INFO] Namespace(path=['vrchat-worlds/meta-ip_len/meta-ip_len.csv', 'vrchat-worlds/meta-tcp_window/meta-tcp_window.csv'], pktcount=2000, importance=False, kfold=1, model=['bigru', 'bigru'], norm=['token', 'token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/vrchat-worlds/train/train_meta_1753442262.debug', leaderboard_path='output/vrchat-worlds/train/train_meta_1753442262.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen-tcpwindow_token-token_bigru-bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.9104,0.9087,0.9103,0.9092
[2025-07-25 11:50:00,727] [INFO] [(0.9103742613263296, 0.9086762520388397, 0.9102637231260292, 0.9091696818141712)]
