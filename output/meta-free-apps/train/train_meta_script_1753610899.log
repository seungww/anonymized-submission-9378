=== Step4. Script Execution Started at Sun Jul 27 10:08:19 AM UTC 2025 ===
Base directory: meta-free-apps
Data prefix: meta
Output directory: output/meta-free-apps/train
[INFO] ip_len â†’ norm: token, model: bigru
Running CUDA_VISIBLE_DEVICES=1 python vrscanner.py --train --debug_path output/meta-free-apps/train/train_meta_1753610899.debug --leaderboard_path output/meta-free-apps/train/train_meta_1753610899.csv --kfold 5 --pktcount 2000 --input_dim 512 --hidden_size 256 --num_layers 3 --dropout 0.3 --fusion_dim 256 --fc_hidden_size 128 --epoch 50 --lr 0.001 --path meta-free-apps/meta-ip_len/meta-ip_len.csv --norm token --model bigru
[2025-07-27 10:08:21,018] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], pktcount=2000, importance=False, kfold=5, model=['bigru'], norm=['token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/meta-free-apps/train/train_meta_1753610899.debug', leaderboard_path='output/meta-free-apps/train/train_meta_1753610899.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'))
[2025-07-27 10:11:28,884] [INFO] Processed data from meta-free-apps/meta-ip_len/meta-ip_len.csv:
[2025-07-27 10:11:28,884] [INFO] (84492, 2000)
[2025-07-27 10:11:28,885] [INFO] [['656' '94' '52' ... <NA> <NA> <NA>]
 ['423' '87' '52' ... <NA> <NA> <NA>]
 ['423' '87' '52' ... <NA> <NA> <NA>]
 ...
 ['242' '87' '52' ... '1432' '64' '64']
 ['60' '60' '52' ... '83' '52' '355']
 ['64' '52' '52' ... '1432' '1432' '1432']]
[2025-07-27 10:11:29,545] [INFO] Training Fold 1/5
[2025-07-27 10:14:57,947] [INFO] Feature 0 normalized using token
[2025-07-27 10:14:57,947] [INFO] Train shape: (59143, 2000), Val shape: (8450, 2000), Test shape: (16899, 2000)
[2025-07-27 10:14:58,052] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2025-07-27 10:14:58,052] [INFO] Training...
[2025-07-27 10:18:07,762] [INFO] Epoch 1/50, ValAcc: 69.64%, TrainLoss: 2.1881, ValLoss: 1.0374, LR: 0.001
[2025-07-27 10:21:14,364] [INFO] Epoch 2/50, ValAcc: 91.73%, TrainLoss: 0.6468, ValLoss: 0.3387, LR: 0.001
[2025-07-27 10:24:20,995] [INFO] Epoch 3/50, ValAcc: 94.24%, TrainLoss: 0.2726, ValLoss: 0.2228, LR: 0.001
[2025-07-27 10:27:27,723] [INFO] Epoch 4/50, ValAcc: 94.27%, TrainLoss: 0.2141, ValLoss: 0.2284, LR: 0.001
[2025-07-27 10:30:34,394] [INFO] Epoch 5/50, ValAcc: 94.63%, TrainLoss: 0.1984, ValLoss: 0.2034, LR: 0.001
[2025-07-27 10:33:41,111] [INFO] Epoch 6/50, ValAcc: 94.99%, TrainLoss: 0.1866, ValLoss: 0.1964, LR: 0.001
[2025-07-27 10:36:47,789] [INFO] Epoch 7/50, ValAcc: 95.05%, TrainLoss: 0.1795, ValLoss: 0.2149, LR: 0.001
[2025-07-27 10:39:54,465] [INFO] Epoch 8/50, ValAcc: 94.78%, TrainLoss: 0.1814, ValLoss: 0.2257, LR: 0.001
[2025-07-27 10:43:01,235] [INFO] Epoch 9/50, ValAcc: 95.10%, TrainLoss: 0.1696, ValLoss: 0.2121, LR: 0.001
[2025-07-27 10:46:07,878] [INFO] Epoch 10/50, ValAcc: 95.24%, TrainLoss: 0.1451, ValLoss: 0.1930, LR: 0.0005
[2025-07-27 10:49:14,459] [INFO] Epoch 11/50, ValAcc: 95.76%, TrainLoss: 0.1381, ValLoss: 0.1975, LR: 0.0005
[2025-07-27 10:52:21,123] [INFO] Epoch 12/50, ValAcc: 95.46%, TrainLoss: 0.1374, ValLoss: 0.1864, LR: 0.0005
[2025-07-27 10:55:27,783] [INFO] Epoch 13/50, ValAcc: 95.53%, TrainLoss: 0.1367, ValLoss: 0.1999, LR: 0.0005
[2025-07-27 10:58:34,416] [INFO] Epoch 14/50, ValAcc: 95.76%, TrainLoss: 0.1345, ValLoss: 0.2000, LR: 0.0005
[2025-07-27 11:01:41,060] [INFO] Epoch 15/50, ValAcc: 95.59%, TrainLoss: 0.1312, ValLoss: 0.1933, LR: 0.0005
[2025-07-27 11:04:48,741] [INFO] Epoch 16/50, ValAcc: 95.51%, TrainLoss: 0.1211, ValLoss: 0.1911, LR: 0.00025
[2025-07-27 11:07:55,483] [INFO] Epoch 17/50, ValAcc: 95.44%, TrainLoss: 0.1162, ValLoss: 0.2139, LR: 0.00025
[2025-07-27 11:11:02,096] [INFO] Epoch 18/50, ValAcc: 95.79%, TrainLoss: 0.1141, ValLoss: 0.2061, LR: 0.00025
[2025-07-27 11:14:08,806] [INFO] Epoch 19/50, ValAcc: 95.56%, TrainLoss: 0.1094, ValLoss: 0.2171, LR: 0.000125
[2025-07-27 11:17:15,404] [INFO] Epoch 20/50, ValAcc: 95.72%, TrainLoss: 0.1056, ValLoss: 0.2162, LR: 0.000125
[2025-07-27 11:20:22,018] [INFO] Epoch 21/50, ValAcc: 95.66%, TrainLoss: 0.1028, ValLoss: 0.2213, LR: 0.000125
[2025-07-27 11:23:28,655] [INFO] Epoch 22/50, ValAcc: 95.85%, TrainLoss: 0.0987, ValLoss: 0.2207, LR: 6.25e-05
[2025-07-27 11:23:28,655] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-27 11:23:47,612] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], pktcount=2000, importance=False, kfold=5, model=['bigru'], norm=['token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/meta-free-apps/train/train_meta_1753610899.debug', leaderboard_path='output/meta-free-apps/train/train_meta_1753610899.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.9550,0.9551,0.9570,0.9552
[2025-07-27 11:23:47,613] [INFO] Training Fold 2/5
[2025-07-27 11:27:13,738] [INFO] Feature 0 normalized using token
[2025-07-27 11:27:13,738] [INFO] Train shape: (59143, 2000), Val shape: (8450, 2000), Test shape: (16899, 2000)
[2025-07-27 11:27:13,859] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2025-07-27 11:27:13,859] [INFO] Training...
[2025-07-27 11:30:20,140] [INFO] Epoch 1/50, ValAcc: 86.41%, TrainLoss: 2.7904, ValLoss: 0.5133, LR: 0.001
[2025-07-27 11:33:26,485] [INFO] Epoch 2/50, ValAcc: 93.23%, TrainLoss: 0.3774, ValLoss: 0.2675, LR: 0.001
[2025-07-27 11:36:32,962] [INFO] Epoch 3/50, ValAcc: 93.36%, TrainLoss: 0.2525, ValLoss: 0.2675, LR: 0.001
[2025-07-27 11:39:39,554] [INFO] Epoch 4/50, ValAcc: 94.15%, TrainLoss: 0.2331, ValLoss: 0.2320, LR: 0.001
[2025-07-27 11:42:46,151] [INFO] Epoch 5/50, ValAcc: 94.26%, TrainLoss: 0.2126, ValLoss: 0.2342, LR: 0.001
[2025-07-27 11:45:52,747] [INFO] Epoch 6/50, ValAcc: 94.28%, TrainLoss: 0.2044, ValLoss: 0.2244, LR: 0.001
[2025-07-27 11:48:59,366] [INFO] Epoch 7/50, ValAcc: 94.25%, TrainLoss: 0.2034, ValLoss: 0.2315, LR: 0.001
[2025-07-27 11:52:05,938] [INFO] Epoch 8/50, ValAcc: 94.30%, TrainLoss: 0.1983, ValLoss: 0.2322, LR: 0.001
[2025-07-27 11:55:12,509] [INFO] Epoch 9/50, ValAcc: 94.56%, TrainLoss: 0.1909, ValLoss: 0.2397, LR: 0.001
[2025-07-27 11:58:19,058] [INFO] Epoch 10/50, ValAcc: 94.85%, TrainLoss: 0.1577, ValLoss: 0.2380, LR: 0.0005
[2025-07-27 12:01:25,604] [INFO] Epoch 11/50, ValAcc: 94.89%, TrainLoss: 0.1491, ValLoss: 0.2163, LR: 0.0005
[2025-07-27 12:04:32,169] [INFO] Epoch 12/50, ValAcc: 94.99%, TrainLoss: 0.1483, ValLoss: 0.2343, LR: 0.0005
[2025-07-27 12:07:38,747] [INFO] Epoch 13/50, ValAcc: 94.92%, TrainLoss: 0.1469, ValLoss: 0.2573, LR: 0.0005
[2025-07-27 12:10:45,309] [INFO] Epoch 14/50, ValAcc: 94.79%, TrainLoss: 0.1462, ValLoss: 0.2477, LR: 0.0005
[2025-07-27 12:13:51,921] [INFO] Epoch 15/50, ValAcc: 95.04%, TrainLoss: 0.1341, ValLoss: 0.2347, LR: 0.00025
[2025-07-27 12:16:58,545] [INFO] Epoch 16/50, ValAcc: 95.05%, TrainLoss: 0.1314, ValLoss: 0.2451, LR: 0.00025
[2025-07-27 12:20:05,128] [INFO] Epoch 17/50, ValAcc: 95.10%, TrainLoss: 0.1290, ValLoss: 0.2486, LR: 0.00025
[2025-07-27 12:23:11,663] [INFO] Epoch 18/50, ValAcc: 95.16%, TrainLoss: 0.1230, ValLoss: 0.2515, LR: 0.000125
[2025-07-27 12:26:18,227] [INFO] Epoch 19/50, ValAcc: 95.09%, TrainLoss: 0.1226, ValLoss: 0.2536, LR: 0.000125
[2025-07-27 12:29:24,774] [INFO] Epoch 20/50, ValAcc: 95.15%, TrainLoss: 0.1191, ValLoss: 0.2578, LR: 0.000125
[2025-07-27 12:32:31,254] [INFO] Epoch 21/50, ValAcc: 95.22%, TrainLoss: 0.1153, ValLoss: 0.2717, LR: 6.25e-05
[2025-07-27 12:32:31,254] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-27 12:32:50,201] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], pktcount=2000, importance=False, kfold=5, model=['bigru'], norm=['token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/meta-free-apps/train/train_meta_1753610899.debug', leaderboard_path='output/meta-free-apps/train/train_meta_1753610899.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.9543,0.9556,0.9601,0.9549
[2025-07-27 12:32:50,202] [INFO] Training Fold 3/5
[2025-07-27 12:36:13,020] [INFO] Feature 0 normalized using token
[2025-07-27 12:36:13,020] [INFO] Train shape: (59144, 2000), Val shape: (8450, 2000), Test shape: (16898, 2000)
[2025-07-27 12:36:13,081] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2025-07-27 12:36:13,081] [INFO] Training...
[2025-07-27 12:39:19,146] [INFO] Epoch 1/50, ValAcc: 68.69%, TrainLoss: 2.7024, ValLoss: 1.0950, LR: 0.001
[2025-07-27 12:42:25,399] [INFO] Epoch 2/50, ValAcc: 89.02%, TrainLoss: 0.8429, ValLoss: 0.4280, LR: 0.001
[2025-07-27 12:45:31,805] [INFO] Epoch 3/50, ValAcc: 93.81%, TrainLoss: 0.3731, ValLoss: 0.2254, LR: 0.001
[2025-07-27 12:48:39,479] [INFO] Epoch 4/50, ValAcc: 94.60%, TrainLoss: 0.2557, ValLoss: 0.1860, LR: 0.001
[2025-07-27 12:51:45,995] [INFO] Epoch 5/50, ValAcc: 95.03%, TrainLoss: 0.2165, ValLoss: 0.1908, LR: 0.001
[2025-07-27 12:54:52,532] [INFO] Epoch 6/50, ValAcc: 95.11%, TrainLoss: 0.2010, ValLoss: 0.1706, LR: 0.001
[2025-07-27 12:57:59,071] [INFO] Epoch 7/50, ValAcc: 95.24%, TrainLoss: 0.1910, ValLoss: 0.1790, LR: 0.001
[2025-07-27 13:01:05,530] [INFO] Epoch 8/50, ValAcc: 95.30%, TrainLoss: 0.1902, ValLoss: 0.1824, LR: 0.001
[2025-07-27 13:04:12,063] [INFO] Epoch 9/50, ValAcc: 95.48%, TrainLoss: 0.1823, ValLoss: 0.1772, LR: 0.001
[2025-07-27 13:07:18,498] [INFO] Epoch 10/50, ValAcc: 95.29%, TrainLoss: 0.1532, ValLoss: 0.1732, LR: 0.0005
[2025-07-27 13:10:24,886] [INFO] Epoch 11/50, ValAcc: 95.50%, TrainLoss: 0.1443, ValLoss: 0.1835, LR: 0.0005
[2025-07-27 13:13:31,321] [INFO] Epoch 12/50, ValAcc: 95.67%, TrainLoss: 0.1411, ValLoss: 0.1982, LR: 0.0005
[2025-07-27 13:16:37,717] [INFO] Epoch 13/50, ValAcc: 95.83%, TrainLoss: 0.1341, ValLoss: 0.1897, LR: 0.00025
[2025-07-27 13:19:44,172] [INFO] Epoch 14/50, ValAcc: 95.42%, TrainLoss: 0.1302, ValLoss: 0.1893, LR: 0.00025
[2025-07-27 13:22:50,632] [INFO] Epoch 15/50, ValAcc: 95.31%, TrainLoss: 0.1267, ValLoss: 0.1863, LR: 0.00025
[2025-07-27 13:25:57,033] [INFO] Epoch 16/50, ValAcc: 95.48%, TrainLoss: 0.1223, ValLoss: 0.1898, LR: 0.000125
[2025-07-27 13:29:03,495] [INFO] Epoch 17/50, ValAcc: 95.62%, TrainLoss: 0.1197, ValLoss: 0.1895, LR: 0.000125
[2025-07-27 13:32:09,888] [INFO] Epoch 18/50, ValAcc: 95.86%, TrainLoss: 0.1177, ValLoss: 0.1946, LR: 0.000125
[2025-07-27 13:35:16,328] [INFO] Epoch 19/50, ValAcc: 95.59%, TrainLoss: 0.1153, ValLoss: 0.1948, LR: 6.25e-05
[2025-07-27 13:35:16,328] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-27 13:35:35,352] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], pktcount=2000, importance=False, kfold=5, model=['bigru'], norm=['token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/meta-free-apps/train/train_meta_1753610899.debug', leaderboard_path='output/meta-free-apps/train/train_meta_1753610899.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.9549,0.9570,0.9620,0.9550
[2025-07-27 13:35:35,353] [INFO] Training Fold 4/5
[2025-07-27 13:39:03,234] [INFO] Feature 0 normalized using token
[2025-07-27 13:39:03,234] [INFO] Train shape: (59144, 2000), Val shape: (8450, 2000), Test shape: (16898, 2000)
[2025-07-27 13:39:03,309] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2025-07-27 13:39:03,309] [INFO] Training...
[2025-07-27 13:42:10,132] [INFO] Epoch 1/50, ValAcc: 82.93%, TrainLoss: 2.2169, ValLoss: 0.5936, LR: 0.001
[2025-07-27 13:45:16,784] [INFO] Epoch 2/50, ValAcc: 93.83%, TrainLoss: 0.3790, ValLoss: 0.2340, LR: 0.001
[2025-07-27 13:48:23,487] [INFO] Epoch 3/50, ValAcc: 94.40%, TrainLoss: 0.2327, ValLoss: 0.2126, LR: 0.001
[2025-07-27 13:51:30,093] [INFO] Epoch 4/50, ValAcc: 95.03%, TrainLoss: 0.2082, ValLoss: 0.1989, LR: 0.001
[2025-07-27 13:54:36,803] [INFO] Epoch 5/50, ValAcc: 94.62%, TrainLoss: 0.2000, ValLoss: 0.2344, LR: 0.001
[2025-07-27 13:57:43,456] [INFO] Epoch 6/50, ValAcc: 94.99%, TrainLoss: 0.1932, ValLoss: 0.2120, LR: 0.001
[2025-07-27 14:00:50,071] [INFO] Epoch 7/50, ValAcc: 95.11%, TrainLoss: 0.1833, ValLoss: 0.2141, LR: 0.001
[2025-07-27 14:03:56,745] [INFO] Epoch 8/50, ValAcc: 95.46%, TrainLoss: 0.1539, ValLoss: 0.1920, LR: 0.0005
[2025-07-27 14:07:03,516] [INFO] Epoch 9/50, ValAcc: 95.24%, TrainLoss: 0.1461, ValLoss: 0.1950, LR: 0.0005
[2025-07-27 14:10:10,221] [INFO] Epoch 10/50, ValAcc: 95.44%, TrainLoss: 0.1424, ValLoss: 0.1973, LR: 0.0005
[2025-07-27 14:13:16,880] [INFO] Epoch 11/50, ValAcc: 95.60%, TrainLoss: 0.1434, ValLoss: 0.1863, LR: 0.0005
[2025-07-27 14:16:23,593] [INFO] Epoch 12/50, ValAcc: 95.57%, TrainLoss: 0.1374, ValLoss: 0.1945, LR: 0.0005
[2025-07-27 14:19:30,351] [INFO] Epoch 13/50, ValAcc: 95.40%, TrainLoss: 0.1373, ValLoss: 0.2102, LR: 0.0005
[2025-07-27 14:22:37,011] [INFO] Epoch 14/50, ValAcc: 95.61%, TrainLoss: 0.1361, ValLoss: 0.1935, LR: 0.0005
[2025-07-27 14:25:43,762] [INFO] Epoch 15/50, ValAcc: 95.63%, TrainLoss: 0.1253, ValLoss: 0.1851, LR: 0.00025
[2025-07-27 14:28:50,503] [INFO] Epoch 16/50, ValAcc: 95.57%, TrainLoss: 0.1198, ValLoss: 0.1848, LR: 0.00025
[2025-07-27 14:31:57,210] [INFO] Epoch 17/50, ValAcc: 95.69%, TrainLoss: 0.1174, ValLoss: 0.1967, LR: 0.00025
[2025-07-27 14:35:03,914] [INFO] Epoch 18/50, ValAcc: 95.48%, TrainLoss: 0.1167, ValLoss: 0.1957, LR: 0.00025
[2025-07-27 14:38:10,553] [INFO] Epoch 19/50, ValAcc: 95.48%, TrainLoss: 0.1136, ValLoss: 0.2039, LR: 0.00025
[2025-07-27 14:41:17,159] [INFO] Epoch 20/50, ValAcc: 95.68%, TrainLoss: 0.1083, ValLoss: 0.1934, LR: 0.000125
[2025-07-27 14:44:23,802] [INFO] Epoch 21/50, ValAcc: 95.69%, TrainLoss: 0.1054, ValLoss: 0.2029, LR: 0.000125
[2025-07-27 14:47:30,399] [INFO] Epoch 22/50, ValAcc: 95.79%, TrainLoss: 0.1030, ValLoss: 0.2118, LR: 0.000125
[2025-07-27 14:50:37,003] [INFO] Epoch 23/50, ValAcc: 95.72%, TrainLoss: 0.0987, ValLoss: 0.2106, LR: 6.25e-05
[2025-07-27 14:50:37,003] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-27 14:50:55,990] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], pktcount=2000, importance=False, kfold=5, model=['bigru'], norm=['token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/meta-free-apps/train/train_meta_1753610899.debug', leaderboard_path='output/meta-free-apps/train/train_meta_1753610899.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.9536,0.9540,0.9553,0.9537
[2025-07-27 14:50:55,991] [INFO] Training Fold 5/5
[2025-07-27 14:54:20,503] [INFO] Feature 0 normalized using token
[2025-07-27 14:54:20,503] [INFO] Train shape: (59144, 2000), Val shape: (8450, 2000), Test shape: (16898, 2000)
[2025-07-27 14:54:20,607] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2025-07-27 14:54:20,607] [INFO] Training...
[2025-07-27 14:57:27,109] [INFO] Epoch 1/50, ValAcc: 67.03%, TrainLoss: 2.7776, ValLoss: 1.1346, LR: 0.001
[2025-07-27 15:00:34,542] [INFO] Epoch 2/50, ValAcc: 81.04%, TrainLoss: 0.9615, ValLoss: 0.6571, LR: 0.001
[2025-07-27 15:03:41,056] [INFO] Epoch 3/50, ValAcc: 91.49%, TrainLoss: 0.5010, ValLoss: 0.3133, LR: 0.001
[2025-07-27 15:06:47,563] [INFO] Epoch 4/50, ValAcc: 93.11%, TrainLoss: 0.3034, ValLoss: 0.2768, LR: 0.001
[2025-07-27 15:09:54,100] [INFO] Epoch 5/50, ValAcc: 94.27%, TrainLoss: 0.2436, ValLoss: 0.2562, LR: 0.001
[2025-07-27 15:13:00,608] [INFO] Epoch 6/50, ValAcc: 94.70%, TrainLoss: 0.2192, ValLoss: 0.2180, LR: 0.001
[2025-07-27 15:16:07,086] [INFO] Epoch 7/50, ValAcc: 94.76%, TrainLoss: 0.2103, ValLoss: 0.2218, LR: 0.001
[2025-07-27 15:19:13,544] [INFO] Epoch 8/50, ValAcc: 94.19%, TrainLoss: 0.1952, ValLoss: 0.2320, LR: 0.001
[2025-07-27 15:22:20,047] [INFO] Epoch 9/50, ValAcc: 94.77%, TrainLoss: 0.1962, ValLoss: 0.2254, LR: 0.001
[2025-07-27 15:25:26,541] [INFO] Epoch 10/50, ValAcc: 95.17%, TrainLoss: 0.1615, ValLoss: 0.2141, LR: 0.0005
[2025-07-27 15:28:33,039] [INFO] Epoch 11/50, ValAcc: 94.93%, TrainLoss: 0.1501, ValLoss: 0.2352, LR: 0.0005
[2025-07-27 15:31:39,542] [INFO] Epoch 12/50, ValAcc: 94.84%, TrainLoss: 0.1470, ValLoss: 0.2323, LR: 0.0005
[2025-07-27 15:34:46,014] [INFO] Epoch 13/50, ValAcc: 94.90%, TrainLoss: 0.1458, ValLoss: 0.2465, LR: 0.0005
[2025-07-27 15:37:52,512] [INFO] Epoch 14/50, ValAcc: 95.14%, TrainLoss: 0.1355, ValLoss: 0.2450, LR: 0.00025
[2025-07-27 15:40:59,016] [INFO] Epoch 15/50, ValAcc: 95.07%, TrainLoss: 0.1313, ValLoss: 0.2459, LR: 0.00025
[2025-07-27 15:44:05,483] [INFO] Epoch 16/50, ValAcc: 95.28%, TrainLoss: 0.1294, ValLoss: 0.2524, LR: 0.00025
[2025-07-27 15:47:10,956] [INFO] Epoch 17/50, ValAcc: 95.36%, TrainLoss: 0.1244, ValLoss: 0.2444, LR: 0.000125
[2025-07-27 15:50:15,040] [INFO] Epoch 18/50, ValAcc: 95.40%, TrainLoss: 0.1205, ValLoss: 0.2458, LR: 0.000125
[2025-07-27 15:53:19,118] [INFO] Epoch 19/50, ValAcc: 95.50%, TrainLoss: 0.1191, ValLoss: 0.2575, LR: 0.000125
[2025-07-27 15:56:23,182] [INFO] Epoch 20/50, ValAcc: 95.34%, TrainLoss: 0.1157, ValLoss: 0.2582, LR: 6.25e-05
[2025-07-27 15:56:23,182] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-07-27 15:56:41,604] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], pktcount=2000, importance=False, kfold=5, model=['bigru'], norm=['token'], attention=False, input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, debug_path='output/meta-free-apps/train/train_meta_1753610899.debug', leaderboard_path='output/meta-free-apps/train/train_meta_1753610899.csv', step1=False, step2=False, step3=False, train=True, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='iplen_token_bigru_2000_64_50_0.001_512_256_3_0.3_256_128'),0.9548,0.9558,0.9600,0.9543
[2025-07-27 15:56:43,380] [INFO] [(0.9549677495709805, 0.9551017774085853, 0.9570139470339891, 0.955187200312796), (0.9543168234806794, 0.9556402135104606, 0.9601025213684747, 0.954878077630025), (0.9549059060243816, 0.957034921789303, 0.9619923269147224, 0.9550153889846777), (0.9536039768019884, 0.9539731878398767, 0.9552597766245929, 0.9536628497432286), (0.9547875488223458, 0.9557945755301673, 0.9599948080637278, 0.9543181429329944)]
=== Step4. Script Execution Finished at Sun Jul 27 03:56:45 PM UTC 2025 ===
