[2026-01-30 15:36:25,906] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['bilstm'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769787384.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769787384.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'))
[2026-01-30 15:39:32,327] [INFO] Processed data from meta-free-apps/meta-ip_len/meta-ip_len.csv:
[2026-01-30 15:39:32,327] [INFO] (84492, 1000)
[2026-01-30 15:39:32,327] [INFO] [['656' '94' '52' ... '181' '52' '52']
 ['423' '87' '52' ... '60' '60' '52']
 ['423' '87' '52' ... '1432' '52' '1432']
 ...
 ['242' '87' '52' ... '424' '700' '52']
 ['60' '60' '52' ... '143' '52' '355']
 ['64' '52' '52' ... '91' '52' '91']]
[2026-01-30 15:39:32,660] [INFO] Training Fold 1/5
[2026-01-30 15:41:07,717] [INFO] Feature 0 normalized using token
[2026-01-30 15:41:07,717] [INFO] Train shape: (59143, 1000), Val shape: (8450, 1000), Test shape: (16899, 1000)
[2026-01-30 15:41:07,789] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): LSTM(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 15:41:07,789] [INFO] Training...
[2026-01-30 15:44:56,768] [INFO] Epoch 1/50, ValAcc: 53.64%, TrainLoss: 2.8681, ValLoss: 1.5495, LR: 0.001
[2026-01-30 15:48:44,697] [INFO] Epoch 2/50, ValAcc: 91.48%, TrainLoss: 0.8648, ValLoss: 0.3505, LR: 0.001
[2026-01-30 15:52:32,563] [INFO] Epoch 3/50, ValAcc: 93.67%, TrainLoss: 0.2800, ValLoss: 0.2643, LR: 0.001
[2026-01-30 15:56:20,457] [INFO] Epoch 4/50, ValAcc: 93.81%, TrainLoss: 0.2351, ValLoss: 0.2630, LR: 0.001
[2026-01-30 16:00:08,331] [INFO] Epoch 5/50, ValAcc: 94.14%, TrainLoss: 0.2132, ValLoss: 0.2644, LR: 0.001
[2026-01-30 16:03:55,985] [INFO] Epoch 6/50, ValAcc: 94.21%, TrainLoss: 0.2021, ValLoss: 0.2520, LR: 0.001
[2026-01-30 16:07:43,549] [INFO] Epoch 7/50, ValAcc: 94.39%, TrainLoss: 0.1949, ValLoss: 0.2454, LR: 0.001
[2026-01-30 16:11:31,456] [INFO] Epoch 8/50, ValAcc: 94.36%, TrainLoss: 0.1899, ValLoss: 0.2538, LR: 0.001
[2026-01-30 16:15:19,353] [INFO] Epoch 9/50, ValAcc: 94.67%, TrainLoss: 0.1844, ValLoss: 0.2347, LR: 0.001
[2026-01-30 16:19:07,293] [INFO] Epoch 10/50, ValAcc: 94.36%, TrainLoss: 0.1765, ValLoss: 0.2445, LR: 0.001
[2026-01-30 16:22:55,273] [INFO] Epoch 11/50, ValAcc: 94.30%, TrainLoss: 0.1703, ValLoss: 0.2385, LR: 0.001
[2026-01-30 16:26:43,229] [INFO] Epoch 12/50, ValAcc: 94.50%, TrainLoss: 0.1652, ValLoss: 0.2573, LR: 0.001
[2026-01-30 16:30:31,159] [INFO] Epoch 13/50, ValAcc: 94.83%, TrainLoss: 0.1459, ValLoss: 0.2553, LR: 0.0005
[2026-01-30 16:34:19,132] [INFO] Epoch 14/50, ValAcc: 94.88%, TrainLoss: 0.1412, ValLoss: 0.2554, LR: 0.0005
[2026-01-30 16:38:07,088] [INFO] Epoch 15/50, ValAcc: 94.67%, TrainLoss: 0.1362, ValLoss: 0.2593, LR: 0.0005
[2026-01-30 16:41:55,095] [INFO] Epoch 16/50, ValAcc: 94.80%, TrainLoss: 0.1244, ValLoss: 0.2825, LR: 0.00025
[2026-01-30 16:45:43,115] [INFO] Epoch 17/50, ValAcc: 94.95%, TrainLoss: 0.1195, ValLoss: 0.3079, LR: 0.00025
[2026-01-30 16:49:31,109] [INFO] Epoch 18/50, ValAcc: 94.85%, TrainLoss: 0.1138, ValLoss: 0.2802, LR: 0.00025
[2026-01-30 16:53:19,174] [INFO] Epoch 19/50, ValAcc: 94.72%, TrainLoss: 0.1064, ValLoss: 0.3158, LR: 0.000125
[2026-01-30 16:57:07,200] [INFO] Epoch 20/50, ValAcc: 94.97%, TrainLoss: 0.1020, ValLoss: 0.3322, LR: 0.000125
[2026-01-30 17:00:55,221] [INFO] Epoch 21/50, ValAcc: 94.77%, TrainLoss: 0.0961, ValLoss: 0.3671, LR: 0.000125
[2026-01-30 17:04:43,258] [INFO] Epoch 22/50, ValAcc: 94.75%, TrainLoss: 0.0909, ValLoss: 0.3694, LR: 6.25e-05
[2026-01-30 17:04:43,258] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 17:05:19,780] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['bilstm'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769787384.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769787384.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_bilstm_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9465,0.9465,0.9471,0.9465
[2026-01-30 17:05:19,781] [INFO] Training Fold 2/5
[2026-01-30 17:06:53,785] [INFO] Feature 0 normalized using token
[2026-01-30 17:06:53,785] [INFO] Train shape: (59143, 1000), Val shape: (8450, 1000), Test shape: (16899, 1000)
[2026-01-30 17:06:53,829] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): LSTM(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 17:06:53,829] [INFO] Training...
[2026-01-30 17:10:41,806] [INFO] Epoch 1/50, ValAcc: 65.57%, TrainLoss: 2.6820, ValLoss: 1.2338, LR: 0.001
[2026-01-30 17:14:29,812] [INFO] Epoch 2/50, ValAcc: 92.49%, TrainLoss: 0.6432, ValLoss: 0.3001, LR: 0.001
[2026-01-30 17:18:17,735] [INFO] Epoch 3/50, ValAcc: 92.26%, TrainLoss: 0.2685, ValLoss: 0.3011, LR: 0.001
[2026-01-30 17:22:05,732] [INFO] Epoch 4/50, ValAcc: 93.55%, TrainLoss: 0.2295, ValLoss: 0.2532, LR: 0.001
[2026-01-30 17:24:14,949] [INFO] Epoch 5/50, ValAcc: 93.69%, TrainLoss: 0.2122, ValLoss: 0.2490, LR: 0.001
[2026-01-30 17:26:04,087] [INFO] Epoch 6/50, ValAcc: 94.11%, TrainLoss: 0.2047, ValLoss: 0.2458, LR: 0.001
[2026-01-30 17:29:51,428] [INFO] Epoch 7/50, ValAcc: 94.12%, TrainLoss: 0.1934, ValLoss: 0.2398, LR: 0.001
[2026-01-30 17:33:38,589] [INFO] Epoch 8/50, ValAcc: 94.15%, TrainLoss: 0.1880, ValLoss: 0.2277, LR: 0.001
[2026-01-30 17:37:25,750] [INFO] Epoch 9/50, ValAcc: 94.19%, TrainLoss: 0.1801, ValLoss: 0.2411, LR: 0.001
[2026-01-30 17:41:12,972] [INFO] Epoch 10/50, ValAcc: 94.25%, TrainLoss: 0.1752, ValLoss: 0.2271, LR: 0.001
[2026-01-30 17:45:00,174] [INFO] Epoch 11/50, ValAcc: 94.31%, TrainLoss: 0.1704, ValLoss: 0.2275, LR: 0.001
[2026-01-30 17:47:50,682] [INFO] Epoch 12/50, ValAcc: 94.34%, TrainLoss: 0.1678, ValLoss: 0.2318, LR: 0.001
[2026-01-30 17:49:30,926] [INFO] Epoch 13/50, ValAcc: 94.52%, TrainLoss: 0.1626, ValLoss: 0.2248, LR: 0.001
[2026-01-30 17:51:11,437] [INFO] Epoch 14/50, ValAcc: 94.45%, TrainLoss: 0.1599, ValLoss: 0.2419, LR: 0.001
[2026-01-30 17:54:27,852] [INFO] Epoch 15/50, ValAcc: 94.43%, TrainLoss: 0.1581, ValLoss: 0.2442, LR: 0.001
[2026-01-30 17:58:15,830] [INFO] Epoch 16/50, ValAcc: 94.49%, TrainLoss: 0.1531, ValLoss: 0.2554, LR: 0.001
[2026-01-30 18:02:03,857] [INFO] Epoch 17/50, ValAcc: 94.49%, TrainLoss: 0.1361, ValLoss: 0.2474, LR: 0.0005
[2026-01-30 18:05:51,869] [INFO] Epoch 18/50, ValAcc: 94.60%, TrainLoss: 0.1296, ValLoss: 0.2505, LR: 0.0005
[2026-01-30 18:09:39,923] [INFO] Epoch 19/50, ValAcc: 94.64%, TrainLoss: 0.1259, ValLoss: 0.2497, LR: 0.0005
[2026-01-30 18:13:27,693] [INFO] Epoch 20/50, ValAcc: 94.67%, TrainLoss: 0.1149, ValLoss: 0.2882, LR: 0.00025
[2026-01-30 18:17:15,448] [INFO] Epoch 21/50, ValAcc: 94.76%, TrainLoss: 0.1091, ValLoss: 0.2959, LR: 0.00025
[2026-01-30 18:21:03,409] [INFO] Epoch 22/50, ValAcc: 94.58%, TrainLoss: 0.1032, ValLoss: 0.3142, LR: 0.00025
[2026-01-30 18:24:51,434] [INFO] Epoch 23/50, ValAcc: 94.56%, TrainLoss: 0.0945, ValLoss: 0.3414, LR: 0.000125
[2026-01-30 18:28:39,435] [INFO] Epoch 24/50, ValAcc: 94.60%, TrainLoss: 0.0908, ValLoss: 0.3337, LR: 0.000125
[2026-01-30 18:32:27,483] [INFO] Epoch 25/50, ValAcc: 94.54%, TrainLoss: 0.0866, ValLoss: 0.3875, LR: 0.000125
[2026-01-30 18:36:15,458] [INFO] Epoch 26/50, ValAcc: 94.54%, TrainLoss: 0.0796, ValLoss: 0.4026, LR: 6.25e-05
[2026-01-30 18:36:15,458] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 18:36:51,937] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['bilstm'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769787384.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769787384.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_bilstm_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9499,0.9509,0.9522,0.9503
[2026-01-30 18:36:51,938] [INFO] Training Fold 3/5
[2026-01-30 18:38:25,870] [INFO] Feature 0 normalized using token
[2026-01-30 18:38:25,870] [INFO] Train shape: (59144, 1000), Val shape: (8450, 1000), Test shape: (16898, 1000)
[2026-01-30 18:38:25,917] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): LSTM(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 18:38:25,917] [INFO] Training...
[2026-01-30 18:42:13,828] [INFO] Epoch 1/50, ValAcc: 66.36%, TrainLoss: 2.8187, ValLoss: 1.2038, LR: 0.001
[2026-01-30 18:46:01,731] [INFO] Epoch 2/50, ValAcc: 92.21%, TrainLoss: 0.6862, ValLoss: 0.3050, LR: 0.001
[2026-01-30 18:49:49,617] [INFO] Epoch 3/50, ValAcc: 93.91%, TrainLoss: 0.2742, ValLoss: 0.2272, LR: 0.001
[2026-01-30 18:53:37,542] [INFO] Epoch 4/50, ValAcc: 94.56%, TrainLoss: 0.2253, ValLoss: 0.2154, LR: 0.001
[2026-01-30 18:57:25,481] [INFO] Epoch 5/50, ValAcc: 93.96%, TrainLoss: 0.2066, ValLoss: 0.2268, LR: 0.001
[2026-01-30 19:01:13,441] [INFO] Epoch 6/50, ValAcc: 94.69%, TrainLoss: 0.1978, ValLoss: 0.2076, LR: 0.001
[2026-01-30 19:05:01,377] [INFO] Epoch 7/50, ValAcc: 94.82%, TrainLoss: 0.1883, ValLoss: 0.2104, LR: 0.001
[2026-01-30 19:08:49,356] [INFO] Epoch 8/50, ValAcc: 94.60%, TrainLoss: 0.1921, ValLoss: 0.2204, LR: 0.001
[2026-01-30 19:12:37,307] [INFO] Epoch 9/50, ValAcc: 94.75%, TrainLoss: 0.1786, ValLoss: 0.2155, LR: 0.001
[2026-01-30 19:16:25,328] [INFO] Epoch 10/50, ValAcc: 94.57%, TrainLoss: 0.1602, ValLoss: 0.2245, LR: 0.0005
[2026-01-30 19:20:13,292] [INFO] Epoch 11/50, ValAcc: 94.72%, TrainLoss: 0.1544, ValLoss: 0.2208, LR: 0.0005
[2026-01-30 19:24:01,322] [INFO] Epoch 12/50, ValAcc: 94.51%, TrainLoss: 0.1509, ValLoss: 0.2292, LR: 0.0005
[2026-01-30 19:27:49,314] [INFO] Epoch 13/50, ValAcc: 94.67%, TrainLoss: 0.1423, ValLoss: 0.2276, LR: 0.00025
[2026-01-30 19:31:37,339] [INFO] Epoch 14/50, ValAcc: 94.65%, TrainLoss: 0.1360, ValLoss: 0.2221, LR: 0.00025
[2026-01-30 19:35:25,329] [INFO] Epoch 15/50, ValAcc: 94.64%, TrainLoss: 0.1306, ValLoss: 0.2499, LR: 0.00025
[2026-01-30 19:39:13,376] [INFO] Epoch 16/50, ValAcc: 94.80%, TrainLoss: 0.1246, ValLoss: 0.2424, LR: 0.000125
[2026-01-30 19:43:01,350] [INFO] Epoch 17/50, ValAcc: 94.64%, TrainLoss: 0.1191, ValLoss: 0.2553, LR: 0.000125
[2026-01-30 19:46:49,051] [INFO] Epoch 18/50, ValAcc: 94.67%, TrainLoss: 0.1151, ValLoss: 0.2673, LR: 0.000125
[2026-01-30 19:50:36,956] [INFO] Epoch 19/50, ValAcc: 94.71%, TrainLoss: 0.1106, ValLoss: 0.2808, LR: 6.25e-05
[2026-01-30 19:50:36,957] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 19:51:13,466] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['bilstm'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769787384.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769787384.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_bilstm_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9459,0.9458,0.9476,0.9461
[2026-01-30 19:51:13,467] [INFO] Training Fold 4/5
[2026-01-30 19:52:46,399] [INFO] Feature 0 normalized using token
[2026-01-30 19:52:46,399] [INFO] Train shape: (59144, 1000), Val shape: (8450, 1000), Test shape: (16898, 1000)
[2026-01-30 19:52:46,451] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): LSTM(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 19:52:46,452] [INFO] Training...
[2026-01-30 19:56:34,412] [INFO] Epoch 1/50, ValAcc: 59.51%, TrainLoss: 2.7630, ValLoss: 1.4039, LR: 0.001
[2026-01-30 20:00:22,378] [INFO] Epoch 2/50, ValAcc: 91.75%, TrainLoss: 0.8013, ValLoss: 0.3325, LR: 0.001
[2026-01-30 20:04:10,296] [INFO] Epoch 3/50, ValAcc: 93.42%, TrainLoss: 0.2847, ValLoss: 0.2603, LR: 0.001
[2026-01-30 20:07:58,192] [INFO] Epoch 4/50, ValAcc: 93.99%, TrainLoss: 0.2326, ValLoss: 0.2502, LR: 0.001
[2026-01-30 20:11:46,120] [INFO] Epoch 5/50, ValAcc: 93.87%, TrainLoss: 0.2134, ValLoss: 0.2346, LR: 0.001
[2026-01-30 20:15:34,081] [INFO] Epoch 6/50, ValAcc: 94.14%, TrainLoss: 0.2034, ValLoss: 0.2199, LR: 0.001
[2026-01-30 20:19:22,007] [INFO] Epoch 7/50, ValAcc: 93.85%, TrainLoss: 0.1947, ValLoss: 0.2441, LR: 0.001
[2026-01-30 20:23:09,988] [INFO] Epoch 8/50, ValAcc: 94.18%, TrainLoss: 0.1886, ValLoss: 0.2228, LR: 0.001
[2026-01-30 20:26:10,846] [INFO] Epoch 9/50, ValAcc: 94.43%, TrainLoss: 0.1831, ValLoss: 0.2319, LR: 0.001
[2026-01-30 20:27:51,502] [INFO] Epoch 10/50, ValAcc: 94.37%, TrainLoss: 0.1623, ValLoss: 0.2223, LR: 0.0005
[2026-01-30 20:29:31,697] [INFO] Epoch 11/50, ValAcc: 94.56%, TrainLoss: 0.1521, ValLoss: 0.2226, LR: 0.0005
[2026-01-30 20:32:24,484] [INFO] Epoch 12/50, ValAcc: 94.62%, TrainLoss: 0.1474, ValLoss: 0.2306, LR: 0.0005
[2026-01-30 20:36:12,266] [INFO] Epoch 13/50, ValAcc: 94.62%, TrainLoss: 0.1366, ValLoss: 0.2270, LR: 0.00025
[2026-01-30 20:40:00,016] [INFO] Epoch 14/50, ValAcc: 94.47%, TrainLoss: 0.1305, ValLoss: 0.2517, LR: 0.00025
[2026-01-30 20:43:47,850] [INFO] Epoch 15/50, ValAcc: 94.57%, TrainLoss: 0.1267, ValLoss: 0.2550, LR: 0.00025
[2026-01-30 20:47:35,638] [INFO] Epoch 16/50, ValAcc: 94.51%, TrainLoss: 0.1179, ValLoss: 0.2637, LR: 0.000125
[2026-01-30 20:51:23,503] [INFO] Epoch 17/50, ValAcc: 94.47%, TrainLoss: 0.1116, ValLoss: 0.2834, LR: 0.000125
[2026-01-30 20:55:11,248] [INFO] Epoch 18/50, ValAcc: 94.63%, TrainLoss: 0.1093, ValLoss: 0.2882, LR: 0.000125
[2026-01-30 20:58:59,011] [INFO] Epoch 19/50, ValAcc: 94.56%, TrainLoss: 0.1037, ValLoss: 0.2923, LR: 6.25e-05
[2026-01-30 20:58:59,011] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 20:59:35,076] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['bilstm'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769787384.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769787384.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_bilstm_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9461,0.9461,0.9470,0.9462
[2026-01-30 20:59:35,077] [INFO] Training Fold 5/5
[2026-01-30 21:01:08,049] [INFO] Feature 0 normalized using token
[2026-01-30 21:01:08,050] [INFO] Train shape: (59144, 1000), Val shape: (8450, 1000), Test shape: (16898, 1000)
[2026-01-30 21:01:08,120] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): LSTM(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 21:01:08,120] [INFO] Training...
[2026-01-30 21:04:56,009] [INFO] Epoch 1/50, ValAcc: 58.46%, TrainLoss: 2.8773, ValLoss: 1.4283, LR: 0.001
[2026-01-30 21:08:43,746] [INFO] Epoch 2/50, ValAcc: 91.16%, TrainLoss: 0.8123, ValLoss: 0.3593, LR: 0.001
[2026-01-30 21:12:31,567] [INFO] Epoch 3/50, ValAcc: 93.40%, TrainLoss: 0.2888, ValLoss: 0.2775, LR: 0.001
[2026-01-30 21:16:19,290] [INFO] Epoch 4/50, ValAcc: 93.31%, TrainLoss: 0.2321, ValLoss: 0.2629, LR: 0.001
[2026-01-30 21:20:07,145] [INFO] Epoch 5/50, ValAcc: 93.62%, TrainLoss: 0.2115, ValLoss: 0.2470, LR: 0.001
[2026-01-30 21:23:54,894] [INFO] Epoch 6/50, ValAcc: 93.56%, TrainLoss: 0.2020, ValLoss: 0.2591, LR: 0.001
[2026-01-30 21:27:42,699] [INFO] Epoch 7/50, ValAcc: 93.54%, TrainLoss: 0.1941, ValLoss: 0.2390, LR: 0.001
[2026-01-30 21:31:30,494] [INFO] Epoch 8/50, ValAcc: 93.81%, TrainLoss: 0.1863, ValLoss: 0.2430, LR: 0.001
[2026-01-30 21:35:18,290] [INFO] Epoch 9/50, ValAcc: 94.22%, TrainLoss: 0.1805, ValLoss: 0.2312, LR: 0.001
[2026-01-30 21:39:06,095] [INFO] Epoch 10/50, ValAcc: 93.82%, TrainLoss: 0.1776, ValLoss: 0.2406, LR: 0.001
[2026-01-30 21:42:53,934] [INFO] Epoch 11/50, ValAcc: 94.43%, TrainLoss: 0.1700, ValLoss: 0.2367, LR: 0.001
[2026-01-30 21:46:41,747] [INFO] Epoch 12/50, ValAcc: 93.99%, TrainLoss: 0.1652, ValLoss: 0.2444, LR: 0.001
[2026-01-30 21:50:29,501] [INFO] Epoch 13/50, ValAcc: 94.28%, TrainLoss: 0.1456, ValLoss: 0.2348, LR: 0.0005
[2026-01-30 21:54:17,308] [INFO] Epoch 14/50, ValAcc: 94.70%, TrainLoss: 0.1378, ValLoss: 0.2507, LR: 0.0005
[2026-01-30 21:58:05,181] [INFO] Epoch 15/50, ValAcc: 94.69%, TrainLoss: 0.1341, ValLoss: 0.2428, LR: 0.0005
[2026-01-30 22:01:53,131] [INFO] Epoch 16/50, ValAcc: 94.85%, TrainLoss: 0.1223, ValLoss: 0.2562, LR: 0.00025
[2026-01-30 22:05:40,978] [INFO] Epoch 17/50, ValAcc: 94.69%, TrainLoss: 0.1171, ValLoss: 0.2600, LR: 0.00025
[2026-01-30 22:09:28,541] [INFO] Epoch 18/50, ValAcc: 94.69%, TrainLoss: 0.1102, ValLoss: 0.2723, LR: 0.00025
[2026-01-30 22:13:16,233] [INFO] Epoch 19/50, ValAcc: 94.51%, TrainLoss: 0.1019, ValLoss: 0.2843, LR: 0.000125
[2026-01-30 22:17:04,195] [INFO] Epoch 20/50, ValAcc: 94.90%, TrainLoss: 0.0965, ValLoss: 0.3123, LR: 0.000125
[2026-01-30 22:20:52,021] [INFO] Epoch 21/50, ValAcc: 94.92%, TrainLoss: 0.0913, ValLoss: 0.3232, LR: 0.000125
[2026-01-30 22:24:39,908] [INFO] Epoch 22/50, ValAcc: 94.82%, TrainLoss: 0.0859, ValLoss: 0.3288, LR: 6.25e-05
[2026-01-30 22:24:39,909] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 22:25:16,431] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['bilstm'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769787384.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769787384.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_bilstm_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9488,0.9475,0.9486,0.9482
[2026-01-30 22:25:17,338] [INFO] [(0.9465057103970649, 0.9464781214941531, 0.9471453858759887, 0.9465115543420485), (0.9498786910468076, 0.950862288760108, 0.9522292755776306, 0.9503402375505887), (0.9458515800686472, 0.9458331568315264, 0.9476154657071953, 0.946060342346556), (0.9460882944727187, 0.9461200530706791, 0.9469921472991611, 0.9461653115954809), (0.9487513315185229, 0.9474961353540764, 0.9486088742921186, 0.9481518092902074)]
