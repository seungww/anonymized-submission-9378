[2026-01-30 12:32:59,118] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['lstm'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769776377.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769776377.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'))
[2026-01-30 12:36:05,784] [INFO] Processed data from meta-free-apps/meta-ip_len/meta-ip_len.csv:
[2026-01-30 12:36:05,785] [INFO] (84492, 1000)
[2026-01-30 12:36:05,785] [INFO] [['656' '94' '52' ... '181' '52' '52']
 ['423' '87' '52' ... '60' '60' '52']
 ['423' '87' '52' ... '1432' '52' '1432']
 ...
 ['242' '87' '52' ... '424' '700' '52']
 ['60' '60' '52' ... '143' '52' '355']
 ['64' '52' '52' ... '91' '52' '91']]
[2026-01-30 12:36:06,113] [INFO] Training Fold 1/5
[2026-01-30 12:37:45,731] [INFO] Feature 0 normalized using token
[2026-01-30 12:37:45,731] [INFO] Train shape: (59143, 1000), Val shape: (8450, 1000), Test shape: (16899, 1000)
[2026-01-30 12:37:45,790] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): LSTM(512, 256, num_layers=3, batch_first=True, dropout=0.3)
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=256, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=256, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 12:37:45,790] [INFO] Training...
[2026-01-30 12:38:39,320] [INFO] Epoch 1/50, ValAcc: 55.43%, TrainLoss: 3.4549, ValLoss: 1.5270, LR: 0.001
[2026-01-30 12:39:29,435] [INFO] Epoch 2/50, ValAcc: 90.95%, TrainLoss: 0.7374, ValLoss: 0.3776, LR: 0.001
[2026-01-30 12:41:03,648] [INFO] Epoch 3/50, ValAcc: 92.49%, TrainLoss: 0.3449, ValLoss: 0.3271, LR: 0.001
[2026-01-30 12:42:45,364] [INFO] Epoch 4/50, ValAcc: 93.54%, TrainLoss: 0.2764, ValLoss: 0.3185, LR: 0.001
[2026-01-30 12:44:25,932] [INFO] Epoch 5/50, ValAcc: 93.35%, TrainLoss: 0.2506, ValLoss: 0.2865, LR: 0.001
[2026-01-30 12:46:06,951] [INFO] Epoch 6/50, ValAcc: 93.87%, TrainLoss: 0.2350, ValLoss: 0.2841, LR: 0.001
[2026-01-30 12:47:48,095] [INFO] Epoch 7/50, ValAcc: 94.17%, TrainLoss: 0.2185, ValLoss: 0.2542, LR: 0.001
[2026-01-30 12:49:29,771] [INFO] Epoch 8/50, ValAcc: 94.37%, TrainLoss: 0.2128, ValLoss: 0.3246, LR: 0.001
[2026-01-30 12:51:10,883] [INFO] Epoch 9/50, ValAcc: 93.67%, TrainLoss: 0.2067, ValLoss: 0.2776, LR: 0.001
[2026-01-30 12:52:52,695] [INFO] Epoch 10/50, ValAcc: 94.11%, TrainLoss: 0.2066, ValLoss: 0.2992, LR: 0.001
[2026-01-30 12:54:33,859] [INFO] Epoch 11/50, ValAcc: 94.19%, TrainLoss: 0.1767, ValLoss: 0.2768, LR: 0.0005
[2026-01-30 12:56:15,766] [INFO] Epoch 12/50, ValAcc: 94.24%, TrainLoss: 0.1689, ValLoss: 0.2619, LR: 0.0005
[2026-01-30 12:57:57,039] [INFO] Epoch 13/50, ValAcc: 94.36%, TrainLoss: 0.1645, ValLoss: 0.2626, LR: 0.0005
[2026-01-30 12:59:38,919] [INFO] Epoch 14/50, ValAcc: 94.54%, TrainLoss: 0.1521, ValLoss: 0.2766, LR: 0.00025
[2026-01-30 13:01:15,450] [INFO] Epoch 15/50, ValAcc: 94.26%, TrainLoss: 0.1478, ValLoss: 0.3060, LR: 0.00025
[2026-01-30 13:02:13,570] [INFO] Epoch 16/50, ValAcc: 94.63%, TrainLoss: 0.1446, ValLoss: 0.3026, LR: 0.00025
[2026-01-30 13:03:07,885] [INFO] Epoch 17/50, ValAcc: 94.66%, TrainLoss: 0.1396, ValLoss: 0.2849, LR: 0.000125
[2026-01-30 13:04:03,197] [INFO] Epoch 18/50, ValAcc: 94.65%, TrainLoss: 0.1350, ValLoss: 0.3150, LR: 0.000125
[2026-01-30 13:05:45,043] [INFO] Epoch 19/50, ValAcc: 94.67%, TrainLoss: 0.1325, ValLoss: 0.3211, LR: 0.000125
[2026-01-30 13:07:26,355] [INFO] Epoch 20/50, ValAcc: 94.62%, TrainLoss: 0.1281, ValLoss: 0.3375, LR: 6.25e-05
[2026-01-30 13:07:26,355] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 13:07:43,070] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['lstm'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769776377.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769776377.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_lstm_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9441,0.9444,0.9464,0.9442
[2026-01-30 13:07:43,071] [INFO] Training Fold 2/5
[2026-01-30 13:09:20,297] [INFO] Feature 0 normalized using token
[2026-01-30 13:09:20,298] [INFO] Train shape: (59143, 1000), Val shape: (8450, 1000), Test shape: (16899, 1000)
[2026-01-30 13:09:20,333] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): LSTM(512, 256, num_layers=3, batch_first=True, dropout=0.3)
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=256, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=256, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 13:09:20,333] [INFO] Training...
[2026-01-30 13:11:02,173] [INFO] Epoch 1/50, ValAcc: 53.85%, TrainLoss: 3.4952, ValLoss: 1.6003, LR: 0.001
[2026-01-30 13:12:43,509] [INFO] Epoch 2/50, ValAcc: 90.64%, TrainLoss: 0.7597, ValLoss: 0.3956, LR: 0.001
[2026-01-30 13:14:25,296] [INFO] Epoch 3/50, ValAcc: 91.91%, TrainLoss: 0.3714, ValLoss: 0.3386, LR: 0.001
[2026-01-30 13:16:06,606] [INFO] Epoch 4/50, ValAcc: 92.43%, TrainLoss: 0.2968, ValLoss: 0.3447, LR: 0.001
[2026-01-30 13:17:48,410] [INFO] Epoch 5/50, ValAcc: 92.76%, TrainLoss: 0.2706, ValLoss: 0.3298, LR: 0.001
[2026-01-30 13:19:29,769] [INFO] Epoch 6/50, ValAcc: 93.23%, TrainLoss: 0.2505, ValLoss: 0.2963, LR: 0.001
[2026-01-30 13:21:11,419] [INFO] Epoch 7/50, ValAcc: 93.07%, TrainLoss: 0.2348, ValLoss: 0.3189, LR: 0.001
[2026-01-30 13:22:52,610] [INFO] Epoch 8/50, ValAcc: 93.69%, TrainLoss: 0.2257, ValLoss: 0.2879, LR: 0.001
[2026-01-30 13:24:34,183] [INFO] Epoch 9/50, ValAcc: 93.63%, TrainLoss: 0.2196, ValLoss: 0.2793, LR: 0.001
[2026-01-30 13:26:15,397] [INFO] Epoch 10/50, ValAcc: 93.83%, TrainLoss: 0.2118, ValLoss: 0.2803, LR: 0.001
[2026-01-30 13:27:57,036] [INFO] Epoch 11/50, ValAcc: 93.74%, TrainLoss: 0.2099, ValLoss: 0.2831, LR: 0.001
[2026-01-30 13:29:38,251] [INFO] Epoch 12/50, ValAcc: 93.69%, TrainLoss: 0.1984, ValLoss: 0.2951, LR: 0.001
[2026-01-30 13:31:19,949] [INFO] Epoch 13/50, ValAcc: 93.83%, TrainLoss: 0.1799, ValLoss: 0.2654, LR: 0.0005
[2026-01-30 13:33:00,797] [INFO] Epoch 14/50, ValAcc: 93.86%, TrainLoss: 0.1724, ValLoss: 0.2743, LR: 0.0005
[2026-01-30 13:34:42,437] [INFO] Epoch 15/50, ValAcc: 93.85%, TrainLoss: 0.1695, ValLoss: 0.2936, LR: 0.0005
[2026-01-30 13:36:23,599] [INFO] Epoch 16/50, ValAcc: 93.98%, TrainLoss: 0.1706, ValLoss: 0.2767, LR: 0.0005
[2026-01-30 13:38:05,164] [INFO] Epoch 17/50, ValAcc: 94.17%, TrainLoss: 0.1588, ValLoss: 0.2901, LR: 0.00025
[2026-01-30 13:39:46,417] [INFO] Epoch 18/50, ValAcc: 94.13%, TrainLoss: 0.1541, ValLoss: 0.3102, LR: 0.00025
[2026-01-30 13:41:28,164] [INFO] Epoch 19/50, ValAcc: 94.13%, TrainLoss: 0.1513, ValLoss: 0.3157, LR: 0.00025
[2026-01-30 13:43:09,475] [INFO] Epoch 20/50, ValAcc: 94.11%, TrainLoss: 0.1446, ValLoss: 0.3187, LR: 0.000125
[2026-01-30 13:44:51,207] [INFO] Epoch 21/50, ValAcc: 94.05%, TrainLoss: 0.1414, ValLoss: 0.3247, LR: 0.000125
[2026-01-30 13:46:32,501] [INFO] Epoch 22/50, ValAcc: 94.21%, TrainLoss: 0.1380, ValLoss: 0.3272, LR: 0.000125
[2026-01-30 13:48:14,297] [INFO] Epoch 23/50, ValAcc: 94.17%, TrainLoss: 0.1330, ValLoss: 0.3352, LR: 6.25e-05
[2026-01-30 13:48:14,297] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 13:48:31,114] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['lstm'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769776377.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769776377.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_lstm_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9464,0.9478,0.9495,0.9470
[2026-01-30 13:48:31,115] [INFO] Training Fold 3/5
[2026-01-30 13:50:10,286] [INFO] Feature 0 normalized using token
[2026-01-30 13:50:10,286] [INFO] Train shape: (59144, 1000), Val shape: (8450, 1000), Test shape: (16898, 1000)
[2026-01-30 13:50:10,323] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): LSTM(512, 256, num_layers=3, batch_first=True, dropout=0.3)
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=256, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=256, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 13:50:10,323] [INFO] Training...
[2026-01-30 13:51:51,410] [INFO] Epoch 1/50, ValAcc: 53.05%, TrainLoss: 3.4375, ValLoss: 1.6621, LR: 0.001
[2026-01-30 13:53:33,142] [INFO] Epoch 2/50, ValAcc: 82.53%, TrainLoss: 1.1959, ValLoss: 0.6950, LR: 0.001
[2026-01-30 13:55:14,460] [INFO] Epoch 3/50, ValAcc: 92.13%, TrainLoss: 0.5254, ValLoss: 0.3139, LR: 0.001
[2026-01-30 13:56:56,243] [INFO] Epoch 4/50, ValAcc: 93.03%, TrainLoss: 0.3164, ValLoss: 0.2579, LR: 0.001
[2026-01-30 13:58:37,529] [INFO] Epoch 5/50, ValAcc: 93.74%, TrainLoss: 0.2564, ValLoss: 0.2326, LR: 0.001
[2026-01-30 14:00:19,266] [INFO] Epoch 6/50, ValAcc: 94.07%, TrainLoss: 0.2283, ValLoss: 0.2274, LR: 0.001
[2026-01-30 14:02:00,207] [INFO] Epoch 7/50, ValAcc: 94.40%, TrainLoss: 0.2169, ValLoss: 0.2068, LR: 0.001
[2026-01-30 14:02:58,403] [INFO] Epoch 8/50, ValAcc: 94.15%, TrainLoss: 0.2038, ValLoss: 0.2174, LR: 0.001
[2026-01-30 14:03:53,840] [INFO] Epoch 9/50, ValAcc: 94.56%, TrainLoss: 0.2001, ValLoss: 0.2161, LR: 0.001
[2026-01-30 14:04:43,753] [INFO] Epoch 10/50, ValAcc: 94.31%, TrainLoss: 0.1977, ValLoss: 0.2086, LR: 0.001
[2026-01-30 14:06:16,552] [INFO] Epoch 11/50, ValAcc: 94.89%, TrainLoss: 0.1739, ValLoss: 0.2062, LR: 0.0005
[2026-01-30 14:07:58,173] [INFO] Epoch 12/50, ValAcc: 94.72%, TrainLoss: 0.1635, ValLoss: 0.2076, LR: 0.0005
[2026-01-30 14:09:39,664] [INFO] Epoch 13/50, ValAcc: 94.59%, TrainLoss: 0.1609, ValLoss: 0.2075, LR: 0.0005
[2026-01-30 14:11:21,598] [INFO] Epoch 14/50, ValAcc: 94.65%, TrainLoss: 0.1582, ValLoss: 0.2057, LR: 0.0005
[2026-01-30 14:13:03,086] [INFO] Epoch 15/50, ValAcc: 94.63%, TrainLoss: 0.1543, ValLoss: 0.2108, LR: 0.0005
[2026-01-30 14:14:45,023] [INFO] Epoch 16/50, ValAcc: 94.63%, TrainLoss: 0.1495, ValLoss: 0.2110, LR: 0.0005
[2026-01-30 14:16:26,521] [INFO] Epoch 17/50, ValAcc: 94.54%, TrainLoss: 0.1452, ValLoss: 0.2229, LR: 0.0005
[2026-01-30 14:18:08,470] [INFO] Epoch 18/50, ValAcc: 94.79%, TrainLoss: 0.1374, ValLoss: 0.2186, LR: 0.00025
[2026-01-30 14:19:49,951] [INFO] Epoch 19/50, ValAcc: 95.04%, TrainLoss: 0.1308, ValLoss: 0.2339, LR: 0.00025
[2026-01-30 14:21:31,869] [INFO] Epoch 20/50, ValAcc: 94.79%, TrainLoss: 0.1301, ValLoss: 0.2294, LR: 0.00025
[2026-01-30 14:23:13,348] [INFO] Epoch 21/50, ValAcc: 95.01%, TrainLoss: 0.1227, ValLoss: 0.2453, LR: 0.000125
[2026-01-30 14:24:55,261] [INFO] Epoch 22/50, ValAcc: 94.78%, TrainLoss: 0.1195, ValLoss: 0.2446, LR: 0.000125
[2026-01-30 14:26:36,491] [INFO] Epoch 23/50, ValAcc: 94.92%, TrainLoss: 0.1164, ValLoss: 0.2468, LR: 0.000125
[2026-01-30 14:27:35,317] [INFO] Epoch 24/50, ValAcc: 94.86%, TrainLoss: 0.1095, ValLoss: 0.2567, LR: 6.25e-05
[2026-01-30 14:27:35,317] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 14:27:43,438] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['lstm'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769776377.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769776377.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_lstm_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9461,0.9466,0.9483,0.9463
[2026-01-30 14:27:43,439] [INFO] Training Fold 4/5
[2026-01-30 14:29:21,817] [INFO] Feature 0 normalized using token
[2026-01-30 14:29:21,817] [INFO] Train shape: (59144, 1000), Val shape: (8450, 1000), Test shape: (16898, 1000)
[2026-01-30 14:29:21,859] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): LSTM(512, 256, num_layers=3, batch_first=True, dropout=0.3)
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=256, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=256, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 14:29:21,859] [INFO] Training...
[2026-01-30 14:30:13,174] [INFO] Epoch 1/50, ValAcc: 82.38%, TrainLoss: 3.0596, ValLoss: 0.7487, LR: 0.001
[2026-01-30 14:31:34,849] [INFO] Epoch 2/50, ValAcc: 90.69%, TrainLoss: 0.5688, ValLoss: 0.4356, LR: 0.001
[2026-01-30 14:33:16,805] [INFO] Epoch 3/50, ValAcc: 92.26%, TrainLoss: 0.3540, ValLoss: 0.3341, LR: 0.001
[2026-01-30 14:34:58,135] [INFO] Epoch 4/50, ValAcc: 92.54%, TrainLoss: 0.3022, ValLoss: 0.3484, LR: 0.001
[2026-01-30 14:36:39,950] [INFO] Epoch 5/50, ValAcc: 92.39%, TrainLoss: 0.2876, ValLoss: 0.3346, LR: 0.001
[2026-01-30 14:38:21,365] [INFO] Epoch 6/50, ValAcc: 93.22%, TrainLoss: 0.2629, ValLoss: 0.3492, LR: 0.001
[2026-01-30 14:40:03,377] [INFO] Epoch 7/50, ValAcc: 93.44%, TrainLoss: 0.2254, ValLoss: 0.3183, LR: 0.0005
[2026-01-30 14:41:44,744] [INFO] Epoch 8/50, ValAcc: 93.59%, TrainLoss: 0.2147, ValLoss: 0.3244, LR: 0.0005
[2026-01-30 14:43:26,717] [INFO] Epoch 9/50, ValAcc: 93.60%, TrainLoss: 0.2100, ValLoss: 0.3146, LR: 0.0005
[2026-01-30 14:45:08,123] [INFO] Epoch 10/50, ValAcc: 93.76%, TrainLoss: 0.2043, ValLoss: 0.2991, LR: 0.0005
[2026-01-30 14:46:50,093] [INFO] Epoch 11/50, ValAcc: 93.74%, TrainLoss: 0.1959, ValLoss: 0.3121, LR: 0.0005
[2026-01-30 14:48:31,454] [INFO] Epoch 12/50, ValAcc: 93.75%, TrainLoss: 0.1917, ValLoss: 0.3146, LR: 0.0005
[2026-01-30 14:50:13,459] [INFO] Epoch 13/50, ValAcc: 93.89%, TrainLoss: 0.1888, ValLoss: 0.2998, LR: 0.0005
[2026-01-30 14:51:55,373] [INFO] Epoch 14/50, ValAcc: 94.01%, TrainLoss: 0.1742, ValLoss: 0.2928, LR: 0.00025
[2026-01-30 14:53:36,868] [INFO] Epoch 15/50, ValAcc: 94.00%, TrainLoss: 0.1666, ValLoss: 0.3169, LR: 0.00025
[2026-01-30 14:55:18,751] [INFO] Epoch 16/50, ValAcc: 94.05%, TrainLoss: 0.1638, ValLoss: 0.3229, LR: 0.00025
[2026-01-30 14:57:00,198] [INFO] Epoch 17/50, ValAcc: 94.12%, TrainLoss: 0.1580, ValLoss: 0.3116, LR: 0.00025
[2026-01-30 14:58:42,149] [INFO] Epoch 18/50, ValAcc: 94.25%, TrainLoss: 0.1497, ValLoss: 0.3319, LR: 0.000125
[2026-01-30 15:00:23,571] [INFO] Epoch 19/50, ValAcc: 94.24%, TrainLoss: 0.1460, ValLoss: 0.3225, LR: 0.000125
[2026-01-30 15:02:05,443] [INFO] Epoch 20/50, ValAcc: 94.31%, TrainLoss: 0.1427, ValLoss: 0.3366, LR: 0.000125
[2026-01-30 15:03:46,879] [INFO] Epoch 21/50, ValAcc: 94.20%, TrainLoss: 0.1378, ValLoss: 0.3401, LR: 6.25e-05
[2026-01-30 15:03:46,879] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 15:04:03,689] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['lstm'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769776377.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769776377.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_lstm_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9429,0.9435,0.9463,0.9429
[2026-01-30 15:04:03,690] [INFO] Training Fold 5/5
[2026-01-30 15:05:34,576] [INFO] Feature 0 normalized using token
[2026-01-30 15:05:34,576] [INFO] Train shape: (59144, 1000), Val shape: (8450, 1000), Test shape: (16898, 1000)
[2026-01-30 15:05:34,630] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): LSTM(512, 256, num_layers=3, batch_first=True, dropout=0.3)
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=256, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=256, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 15:05:34,631] [INFO] Training...
[2026-01-30 15:07:16,598] [INFO] Epoch 1/50, ValAcc: 78.56%, TrainLoss: 3.0089, ValLoss: 0.8042, LR: 0.001
[2026-01-30 15:08:58,037] [INFO] Epoch 2/50, ValAcc: 90.54%, TrainLoss: 0.5651, ValLoss: 0.3746, LR: 0.001
[2026-01-30 15:10:39,947] [INFO] Epoch 3/50, ValAcc: 92.05%, TrainLoss: 0.3366, ValLoss: 0.3241, LR: 0.001
[2026-01-30 15:12:21,365] [INFO] Epoch 4/50, ValAcc: 93.14%, TrainLoss: 0.2872, ValLoss: 0.3017, LR: 0.001
[2026-01-30 15:14:03,300] [INFO] Epoch 5/50, ValAcc: 92.75%, TrainLoss: 0.2558, ValLoss: 0.2804, LR: 0.001
[2026-01-30 15:15:44,759] [INFO] Epoch 6/50, ValAcc: 93.21%, TrainLoss: 0.2401, ValLoss: 0.2911, LR: 0.001
[2026-01-30 15:17:26,670] [INFO] Epoch 7/50, ValAcc: 93.47%, TrainLoss: 0.2255, ValLoss: 0.2930, LR: 0.001
[2026-01-30 15:19:08,112] [INFO] Epoch 8/50, ValAcc: 93.17%, TrainLoss: 0.2167, ValLoss: 0.2944, LR: 0.001
[2026-01-30 15:20:50,048] [INFO] Epoch 9/50, ValAcc: 93.66%, TrainLoss: 0.1879, ValLoss: 0.2831, LR: 0.0005
[2026-01-30 15:22:31,789] [INFO] Epoch 10/50, ValAcc: 93.57%, TrainLoss: 0.1794, ValLoss: 0.2960, LR: 0.0005
[2026-01-30 15:24:13,409] [INFO] Epoch 11/50, ValAcc: 93.93%, TrainLoss: 0.1781, ValLoss: 0.2901, LR: 0.0005
[2026-01-30 15:25:55,391] [INFO] Epoch 12/50, ValAcc: 94.15%, TrainLoss: 0.1634, ValLoss: 0.3218, LR: 0.00025
[2026-01-30 15:27:36,765] [INFO] Epoch 13/50, ValAcc: 94.31%, TrainLoss: 0.1573, ValLoss: 0.3193, LR: 0.00025
[2026-01-30 15:29:18,680] [INFO] Epoch 14/50, ValAcc: 93.75%, TrainLoss: 0.1523, ValLoss: 0.3339, LR: 0.00025
[2026-01-30 15:30:59,991] [INFO] Epoch 15/50, ValAcc: 93.98%, TrainLoss: 0.1467, ValLoss: 0.3422, LR: 0.000125
[2026-01-30 15:32:41,911] [INFO] Epoch 16/50, ValAcc: 93.86%, TrainLoss: 0.1420, ValLoss: 0.3533, LR: 0.000125
[2026-01-30 15:34:23,223] [INFO] Epoch 17/50, ValAcc: 94.17%, TrainLoss: 0.1400, ValLoss: 0.3597, LR: 0.000125
[2026-01-30 15:36:05,139] [INFO] Epoch 18/50, ValAcc: 94.28%, TrainLoss: 0.1352, ValLoss: 0.3603, LR: 6.25e-05
[2026-01-30 15:36:05,140] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 15:36:22,002] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['lstm'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769776377.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769776377.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_lstm_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9435,0.9439,0.9464,0.9428
[2026-01-30 15:36:22,898] [INFO] [(0.944079531333215, 0.9444143750917333, 0.9463552253508547, 0.9442341013182388), (0.9464465352979466, 0.9477677734864579, 0.949470780389654, 0.9469664671027537), (0.9461474730737366, 0.9465599066323416, 0.9483400743806902, 0.946288906974294), (0.9428926500177536, 0.9434977207697456, 0.9463044850447017, 0.9429418589662462), (0.9434844360279323, 0.9439060049974882, 0.9463745024309966, 0.9428343787848005)]
