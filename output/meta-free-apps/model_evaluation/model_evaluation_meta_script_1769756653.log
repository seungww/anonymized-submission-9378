=== Step4. Script Execution Started at Fri Jan 30 07:04:13 AM UTC 2026 ===
Base directory: meta-free-apps
Data prefix: meta
Output directory: output/meta-free-apps/model_evaluation
Running python vrscanner.py --train --path meta-free-apps/meta-ip_len/meta-ip_len.csv --debug_path output/meta-free-apps/model_evaluation/model_evaluation_meta_1769756653.debug --leaderboard_path output/meta-free-apps/model_evaluation/model_evaluation_meta_1769756653.csv --norm token --model birnn --kfold 5 --lr 0.001 --strict
[2026-01-30 07:04:15,605] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['birnn'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769756653.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769756653.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'))
[2026-01-30 07:07:20,819] [INFO] Processed data from meta-free-apps/meta-ip_len/meta-ip_len.csv:
[2026-01-30 07:07:20,819] [INFO] (84492, 1000)
[2026-01-30 07:07:20,820] [INFO] [['656' '94' '52' ... '181' '52' '52']
 ['423' '87' '52' ... '60' '60' '52']
 ['423' '87' '52' ... '1432' '52' '1432']
 ...
 ['242' '87' '52' ... '424' '700' '52']
 ['60' '60' '52' ... '143' '52' '355']
 ['64' '52' '52' ... '91' '52' '91']]
[2026-01-30 07:07:21,155] [INFO] Training Fold 1/5
[2026-01-30 07:08:59,159] [INFO] Feature 0 normalized using token
[2026-01-30 07:08:59,159] [INFO] Train shape: (59143, 1000), Val shape: (8450, 1000), Test shape: (16899, 1000)
[2026-01-30 07:08:59,218] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): RNN(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 07:08:59,219] [INFO] Training...
[2026-01-30 07:10:21,718] [INFO] Epoch 1/50, ValAcc: 61.98%, TrainLoss: 2.7439, ValLoss: 1.4413, LR: 0.001
[2026-01-30 07:11:42,790] [INFO] Epoch 2/50, ValAcc: 65.67%, TrainLoss: 1.4275, ValLoss: 1.2748, LR: 0.001
[2026-01-30 07:13:04,068] [INFO] Epoch 3/50, ValAcc: 68.90%, TrainLoss: 1.2789, ValLoss: 1.1529, LR: 0.001
[2026-01-30 07:14:25,321] [INFO] Epoch 4/50, ValAcc: 74.33%, TrainLoss: 1.1134, ValLoss: 0.9763, LR: 0.001
[2026-01-30 07:15:46,301] [INFO] Epoch 5/50, ValAcc: 79.96%, TrainLoss: 0.9732, ValLoss: 0.7991, LR: 0.001
[2026-01-30 07:17:07,536] [INFO] Epoch 6/50, ValAcc: 82.98%, TrainLoss: 0.7888, ValLoss: 0.7044, LR: 0.001
[2026-01-30 07:18:28,576] [INFO] Epoch 7/50, ValAcc: 85.40%, TrainLoss: 0.6718, ValLoss: 0.6167, LR: 0.001
[2026-01-30 07:19:23,872] [INFO] Epoch 8/50, ValAcc: 86.70%, TrainLoss: 0.6016, ValLoss: 0.5848, LR: 0.001
[2026-01-30 07:20:45,108] [INFO] Epoch 9/50, ValAcc: 87.91%, TrainLoss: 0.5531, ValLoss: 0.5380, LR: 0.001
[2026-01-30 07:22:06,348] [INFO] Epoch 10/50, ValAcc: 87.53%, TrainLoss: 0.5256, ValLoss: 0.5419, LR: 0.001
[2026-01-30 07:23:27,228] [INFO] Epoch 11/50, ValAcc: 88.51%, TrainLoss: 0.4941, ValLoss: 0.4968, LR: 0.001
[2026-01-30 07:24:48,430] [INFO] Epoch 12/50, ValAcc: 89.07%, TrainLoss: 0.4962, ValLoss: 0.4590, LR: 0.001
[2026-01-30 07:26:09,582] [INFO] Epoch 13/50, ValAcc: 89.30%, TrainLoss: 0.4788, ValLoss: 0.4721, LR: 0.001
[2026-01-30 07:27:30,556] [INFO] Epoch 14/50, ValAcc: 88.56%, TrainLoss: 0.4603, ValLoss: 0.4834, LR: 0.001
[2026-01-30 07:28:51,743] [INFO] Epoch 15/50, ValAcc: 88.85%, TrainLoss: 0.4344, ValLoss: 0.4971, LR: 0.001
[2026-01-30 07:30:12,768] [INFO] Epoch 16/50, ValAcc: 90.88%, TrainLoss: 0.3729, ValLoss: 0.4274, LR: 0.0005
[2026-01-30 07:31:33,995] [INFO] Epoch 17/50, ValAcc: 91.40%, TrainLoss: 0.3393, ValLoss: 0.3854, LR: 0.0005
[2026-01-30 07:32:55,180] [INFO] Epoch 18/50, ValAcc: 91.04%, TrainLoss: 0.3276, ValLoss: 0.3851, LR: 0.0005
[2026-01-30 07:34:16,142] [INFO] Epoch 19/50, ValAcc: 91.60%, TrainLoss: 0.3163, ValLoss: 0.4012, LR: 0.0005
[2026-01-30 07:35:37,349] [INFO] Epoch 20/50, ValAcc: 92.21%, TrainLoss: 0.3043, ValLoss: 0.3466, LR: 0.0005
[2026-01-30 07:36:58,255] [INFO] Epoch 21/50, ValAcc: 92.05%, TrainLoss: 0.3235, ValLoss: 0.3729, LR: 0.0005
[2026-01-30 07:38:19,422] [INFO] Epoch 22/50, ValAcc: 91.89%, TrainLoss: 0.3122, ValLoss: 0.3698, LR: 0.0005
[2026-01-30 07:39:40,611] [INFO] Epoch 23/50, ValAcc: 92.85%, TrainLoss: 0.2931, ValLoss: 0.3425, LR: 0.0005
[2026-01-30 07:41:01,551] [INFO] Epoch 24/50, ValAcc: 93.03%, TrainLoss: 0.2595, ValLoss: 0.3237, LR: 0.0005
[2026-01-30 07:42:22,755] [INFO] Epoch 25/50, ValAcc: 93.15%, TrainLoss: 0.2673, ValLoss: 0.3095, LR: 0.0005
[2026-01-30 07:43:43,924] [INFO] Epoch 26/50, ValAcc: 92.89%, TrainLoss: 0.2534, ValLoss: 0.3127, LR: 0.0005
[2026-01-30 07:45:04,863] [INFO] Epoch 27/50, ValAcc: 92.34%, TrainLoss: 0.2957, ValLoss: 0.3672, LR: 0.0005
[2026-01-30 07:46:26,013] [INFO] Epoch 28/50, ValAcc: 91.76%, TrainLoss: 0.2882, ValLoss: 0.3587, LR: 0.0005
[2026-01-30 07:47:46,931] [INFO] Epoch 29/50, ValAcc: 93.12%, TrainLoss: 0.2517, ValLoss: 0.3068, LR: 0.00025
[2026-01-30 07:49:08,130] [INFO] Epoch 30/50, ValAcc: 93.01%, TrainLoss: 0.2483, ValLoss: 0.3524, LR: 0.00025
[2026-01-30 07:50:29,307] [INFO] Epoch 31/50, ValAcc: 93.09%, TrainLoss: 0.2378, ValLoss: 0.3072, LR: 0.00025
[2026-01-30 07:51:50,268] [INFO] Epoch 32/50, ValAcc: 93.20%, TrainLoss: 0.2266, ValLoss: 0.3102, LR: 0.00025
[2026-01-30 07:53:11,452] [INFO] Epoch 33/50, ValAcc: 93.33%, TrainLoss: 0.2119, ValLoss: 0.2985, LR: 0.000125
[2026-01-30 07:54:32,292] [INFO] Epoch 34/50, ValAcc: 93.16%, TrainLoss: 0.2072, ValLoss: 0.3103, LR: 0.000125
[2026-01-30 07:55:53,499] [INFO] Epoch 35/50, ValAcc: 93.31%, TrainLoss: 0.2048, ValLoss: 0.3015, LR: 0.000125
[2026-01-30 07:57:14,703] [INFO] Epoch 36/50, ValAcc: 93.43%, TrainLoss: 0.2004, ValLoss: 0.2885, LR: 0.000125
[2026-01-30 07:58:35,675] [INFO] Epoch 37/50, ValAcc: 93.54%, TrainLoss: 0.2024, ValLoss: 0.2897, LR: 0.000125
[2026-01-30 07:59:56,903] [INFO] Epoch 38/50, ValAcc: 93.48%, TrainLoss: 0.1997, ValLoss: 0.2884, LR: 0.000125
[2026-01-30 08:01:18,107] [INFO] Epoch 39/50, ValAcc: 93.08%, TrainLoss: 0.2048, ValLoss: 0.3049, LR: 0.000125
[2026-01-30 08:02:39,042] [INFO] Epoch 40/50, ValAcc: 93.16%, TrainLoss: 0.2041, ValLoss: 0.3188, LR: 0.000125
[2026-01-30 08:04:00,245] [INFO] Epoch 41/50, ValAcc: 92.72%, TrainLoss: 0.2091, ValLoss: 0.3340, LR: 0.000125
[2026-01-30 08:05:21,203] [INFO] Epoch 42/50, ValAcc: 93.30%, TrainLoss: 0.2032, ValLoss: 0.3176, LR: 6.25e-05
[2026-01-30 08:05:21,203] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 08:05:34,750] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['birnn'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769756653.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769756653.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_birnn_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9325,0.9353,0.9422,0.9327
[2026-01-30 08:05:34,751] [INFO] Training Fold 2/5
[2026-01-30 08:07:12,352] [INFO] Feature 0 normalized using token
[2026-01-30 08:07:12,353] [INFO] Train shape: (59143, 1000), Val shape: (8450, 1000), Test shape: (16899, 1000)
[2026-01-30 08:07:12,387] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): RNN(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 08:07:12,387] [INFO] Training...
[2026-01-30 08:08:08,134] [INFO] Epoch 1/50, ValAcc: 53.93%, TrainLoss: 3.2206, ValLoss: 1.7149, LR: 0.001
[2026-01-30 08:09:29,424] [INFO] Epoch 2/50, ValAcc: 63.75%, TrainLoss: 1.5898, ValLoss: 1.3113, LR: 0.001
[2026-01-30 08:10:50,664] [INFO] Epoch 3/50, ValAcc: 66.59%, TrainLoss: 1.3245, ValLoss: 1.2182, LR: 0.001
[2026-01-30 08:12:11,496] [INFO] Epoch 4/50, ValAcc: 69.10%, TrainLoss: 1.2026, ValLoss: 1.0844, LR: 0.001
[2026-01-30 08:13:32,766] [INFO] Epoch 5/50, ValAcc: 71.23%, TrainLoss: 1.1176, ValLoss: 1.0160, LR: 0.001
[2026-01-30 08:14:53,556] [INFO] Epoch 6/50, ValAcc: 71.95%, TrainLoss: 1.0610, ValLoss: 0.9708, LR: 0.001
[2026-01-30 08:16:14,812] [INFO] Epoch 7/50, ValAcc: 73.21%, TrainLoss: 1.0149, ValLoss: 0.9420, LR: 0.001
[2026-01-30 08:17:36,016] [INFO] Epoch 8/50, ValAcc: 73.49%, TrainLoss: 0.9824, ValLoss: 0.9343, LR: 0.001
[2026-01-30 08:18:56,811] [INFO] Epoch 9/50, ValAcc: 74.92%, TrainLoss: 0.9512, ValLoss: 0.8738, LR: 0.001
[2026-01-30 08:20:18,049] [INFO] Epoch 10/50, ValAcc: 76.47%, TrainLoss: 0.9158, ValLoss: 0.8196, LR: 0.001
[2026-01-30 08:21:38,914] [INFO] Epoch 11/50, ValAcc: 76.69%, TrainLoss: 0.8625, ValLoss: 0.8165, LR: 0.001
[2026-01-30 08:22:59,996] [INFO] Epoch 12/50, ValAcc: 75.70%, TrainLoss: 0.8241, ValLoss: 0.8448, LR: 0.001
[2026-01-30 08:24:21,194] [INFO] Epoch 13/50, ValAcc: 79.21%, TrainLoss: 0.7975, ValLoss: 0.7389, LR: 0.001
[2026-01-30 08:25:41,965] [INFO] Epoch 14/50, ValAcc: 80.97%, TrainLoss: 0.7470, ValLoss: 0.6685, LR: 0.001
[2026-01-30 08:27:03,172] [INFO] Epoch 15/50, ValAcc: 82.19%, TrainLoss: 0.6978, ValLoss: 0.6464, LR: 0.001
[2026-01-30 08:28:24,371] [INFO] Epoch 16/50, ValAcc: 84.20%, TrainLoss: 0.6520, ValLoss: 0.5835, LR: 0.001
[2026-01-30 08:29:45,137] [INFO] Epoch 17/50, ValAcc: 84.59%, TrainLoss: 0.6105, ValLoss: 0.5712, LR: 0.001
[2026-01-30 08:31:06,353] [INFO] Epoch 18/50, ValAcc: 84.99%, TrainLoss: 0.6015, ValLoss: 0.5674, LR: 0.001
[2026-01-30 08:32:27,095] [INFO] Epoch 19/50, ValAcc: 85.44%, TrainLoss: 0.5805, ValLoss: 0.5560, LR: 0.001
[2026-01-30 08:33:48,265] [INFO] Epoch 20/50, ValAcc: 86.08%, TrainLoss: 0.5506, ValLoss: 0.5111, LR: 0.001
[2026-01-30 08:35:09,436] [INFO] Epoch 21/50, ValAcc: 87.72%, TrainLoss: 0.5327, ValLoss: 0.5055, LR: 0.001
[2026-01-30 08:36:30,147] [INFO] Epoch 22/50, ValAcc: 87.72%, TrainLoss: 0.5033, ValLoss: 0.4677, LR: 0.001
[2026-01-30 08:37:51,323] [INFO] Epoch 23/50, ValAcc: 87.63%, TrainLoss: 0.4983, ValLoss: 0.4829, LR: 0.001
[2026-01-30 08:39:12,396] [INFO] Epoch 24/50, ValAcc: 88.60%, TrainLoss: 0.4745, ValLoss: 0.4571, LR: 0.001
[2026-01-30 08:40:33,252] [INFO] Epoch 25/50, ValAcc: 87.47%, TrainLoss: 0.5010, ValLoss: 0.5013, LR: 0.001
[2026-01-30 08:41:54,454] [INFO] Epoch 26/50, ValAcc: 88.49%, TrainLoss: 0.4996, ValLoss: 0.5002, LR: 0.001
[2026-01-30 08:43:15,221] [INFO] Epoch 27/50, ValAcc: 88.20%, TrainLoss: 0.4740, ValLoss: 0.4903, LR: 0.001
[2026-01-30 08:44:36,405] [INFO] Epoch 28/50, ValAcc: 89.48%, TrainLoss: 0.4177, ValLoss: 0.4202, LR: 0.0005
[2026-01-30 08:45:57,581] [INFO] Epoch 29/50, ValAcc: 89.61%, TrainLoss: 0.3897, ValLoss: 0.4156, LR: 0.0005
[2026-01-30 08:47:18,308] [INFO] Epoch 30/50, ValAcc: 89.92%, TrainLoss: 0.3679, ValLoss: 0.3945, LR: 0.0005
[2026-01-30 08:48:39,514] [INFO] Epoch 31/50, ValAcc: 89.66%, TrainLoss: 0.3692, ValLoss: 0.4131, LR: 0.0005
[2026-01-30 08:50:00,253] [INFO] Epoch 32/50, ValAcc: 90.05%, TrainLoss: 0.3592, ValLoss: 0.4174, LR: 0.0005
[2026-01-30 08:51:21,425] [INFO] Epoch 33/50, ValAcc: 90.64%, TrainLoss: 0.3285, ValLoss: 0.3730, LR: 0.0005
[2026-01-30 08:52:42,579] [INFO] Epoch 34/50, ValAcc: 89.42%, TrainLoss: 0.3812, ValLoss: 0.4134, LR: 0.0005
[2026-01-30 08:54:03,302] [INFO] Epoch 35/50, ValAcc: 90.06%, TrainLoss: 0.3565, ValLoss: 0.4080, LR: 0.0005
[2026-01-30 08:55:24,509] [INFO] Epoch 36/50, ValAcc: 90.30%, TrainLoss: 0.3397, ValLoss: 0.3944, LR: 0.0005
[2026-01-30 08:56:45,702] [INFO] Epoch 37/50, ValAcc: 90.59%, TrainLoss: 0.3188, ValLoss: 0.3870, LR: 0.00025
[2026-01-30 08:57:41,307] [INFO] Epoch 38/50, ValAcc: 90.72%, TrainLoss: 0.3072, ValLoss: 0.3642, LR: 0.00025
[2026-01-30 08:59:01,421] [INFO] Epoch 39/50, ValAcc: 91.08%, TrainLoss: 0.3023, ValLoss: 0.3724, LR: 0.00025
[2026-01-30 09:00:22,619] [INFO] Epoch 40/50, ValAcc: 90.60%, TrainLoss: 0.2980, ValLoss: 0.3760, LR: 0.00025
[2026-01-30 09:01:43,345] [INFO] Epoch 41/50, ValAcc: 90.73%, TrainLoss: 0.2906, ValLoss: 0.3661, LR: 0.00025
[2026-01-30 09:03:04,562] [INFO] Epoch 42/50, ValAcc: 91.05%, TrainLoss: 0.2785, ValLoss: 0.3602, LR: 0.000125
[2026-01-30 09:04:25,731] [INFO] Epoch 43/50, ValAcc: 90.93%, TrainLoss: 0.2749, ValLoss: 0.3562, LR: 0.000125
[2026-01-30 09:05:46,432] [INFO] Epoch 44/50, ValAcc: 90.98%, TrainLoss: 0.2759, ValLoss: 0.3779, LR: 0.000125
[2026-01-30 09:07:07,585] [INFO] Epoch 45/50, ValAcc: 91.12%, TrainLoss: 0.2725, ValLoss: 0.3676, LR: 0.000125
[2026-01-30 09:08:28,296] [INFO] Epoch 46/50, ValAcc: 91.17%, TrainLoss: 0.2682, ValLoss: 0.3614, LR: 0.000125
[2026-01-30 09:09:49,469] [INFO] Epoch 47/50, ValAcc: 91.22%, TrainLoss: 0.2586, ValLoss: 0.3637, LR: 6.25e-05
[2026-01-30 09:09:49,469] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 09:10:03,016] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['birnn'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769756653.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769756653.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_birnn_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9144,0.9167,0.9243,0.9156
[2026-01-30 09:10:03,017] [INFO] Training Fold 3/5
[2026-01-30 09:11:42,560] [INFO] Feature 0 normalized using token
[2026-01-30 09:11:42,560] [INFO] Train shape: (59144, 1000), Val shape: (8450, 1000), Test shape: (16898, 1000)
[2026-01-30 09:11:42,600] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): RNN(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 09:11:42,601] [INFO] Training...
[2026-01-30 09:13:03,758] [INFO] Epoch 1/50, ValAcc: 1.05%, TrainLoss: 4.5137, ValLoss: 4.5116, LR: 0.001
[2026-01-30 09:14:24,723] [INFO] Epoch 2/50, ValAcc: 1.05%, TrainLoss: 4.5111, ValLoss: 4.5117, LR: 0.001
[2026-01-30 09:15:45,932] [INFO] Epoch 3/50, ValAcc: 1.07%, TrainLoss: 4.5110, ValLoss: 4.5118, LR: 0.001
[2026-01-30 09:17:06,946] [INFO] Epoch 4/50, ValAcc: 1.07%, TrainLoss: 4.5109, ValLoss: 4.5118, LR: 0.001
[2026-01-30 09:18:28,179] [INFO] Epoch 5/50, ValAcc: 1.07%, TrainLoss: 4.5107, ValLoss: 4.5119, LR: 0.0005
[2026-01-30 09:19:49,396] [INFO] Epoch 6/50, ValAcc: 1.07%, TrainLoss: 4.5107, ValLoss: 4.5119, LR: 0.0005
[2026-01-30 09:21:10,445] [INFO] Epoch 7/50, ValAcc: 1.07%, TrainLoss: 4.5107, ValLoss: 4.5120, LR: 0.0005
[2026-01-30 09:22:31,675] [INFO] Epoch 8/50, ValAcc: 1.07%, TrainLoss: 4.5105, ValLoss: 4.5120, LR: 0.00025
[2026-01-30 09:23:52,720] [INFO] Epoch 9/50, ValAcc: 1.07%, TrainLoss: 4.5105, ValLoss: 4.5120, LR: 0.00025
[2026-01-30 09:25:13,753] [INFO] Epoch 10/50, ValAcc: 1.07%, TrainLoss: 4.5105, ValLoss: 4.5120, LR: 0.00025
[2026-01-30 09:26:34,971] [INFO] Epoch 11/50, ValAcc: 1.07%, TrainLoss: 4.5105, ValLoss: 4.5120, LR: 0.000125
[2026-01-30 09:27:55,958] [INFO] Epoch 12/50, ValAcc: 1.07%, TrainLoss: 4.5105, ValLoss: 4.5120, LR: 0.000125
[2026-01-30 09:29:17,184] [INFO] Epoch 13/50, ValAcc: 1.07%, TrainLoss: 4.5105, ValLoss: 4.5120, LR: 0.000125
[2026-01-30 09:30:38,407] [INFO] Epoch 14/50, ValAcc: 1.07%, TrainLoss: 4.5104, ValLoss: 4.5120, LR: 6.25e-05
[2026-01-30 09:30:38,408] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 09:30:43,140] [WARNING] ValAcc too low (1.07%), getting stuck in a bad local minimum...
[2026-01-30 09:30:43,140] [INFO] Retraining with new initialization: attempt 1...
[2026-01-30 09:32:04,297] [INFO] Epoch 1/50, ValAcc: 52.06%, TrainLoss: 3.2742, ValLoss: 1.8186, LR: 0.001
[2026-01-30 09:33:25,576] [INFO] Epoch 2/50, ValAcc: 63.67%, TrainLoss: 1.5816, ValLoss: 1.3439, LR: 0.001
[2026-01-30 09:34:46,618] [INFO] Epoch 3/50, ValAcc: 66.64%, TrainLoss: 1.3546, ValLoss: 1.2311, LR: 0.001
[2026-01-30 09:36:07,878] [INFO] Epoch 4/50, ValAcc: 69.62%, TrainLoss: 1.2408, ValLoss: 1.1132, LR: 0.001
[2026-01-30 09:37:29,158] [INFO] Epoch 5/50, ValAcc: 72.88%, TrainLoss: 1.1067, ValLoss: 0.9874, LR: 0.001
[2026-01-30 09:38:50,181] [INFO] Epoch 6/50, ValAcc: 73.91%, TrainLoss: 1.0182, ValLoss: 0.9327, LR: 0.001
[2026-01-30 09:40:11,419] [INFO] Epoch 7/50, ValAcc: 74.79%, TrainLoss: 0.9653, ValLoss: 0.8972, LR: 0.001
[2026-01-30 09:41:32,376] [INFO] Epoch 8/50, ValAcc: 75.80%, TrainLoss: 0.9262, ValLoss: 0.8609, LR: 0.001
[2026-01-30 09:42:53,500] [INFO] Epoch 9/50, ValAcc: 78.46%, TrainLoss: 0.8786, ValLoss: 0.8064, LR: 0.001
[2026-01-30 09:44:14,735] [INFO] Epoch 10/50, ValAcc: 80.98%, TrainLoss: 0.8056, ValLoss: 0.6979, LR: 0.001
[2026-01-30 09:45:32,106] [INFO] Epoch 11/50, ValAcc: 82.58%, TrainLoss: 0.7240, ValLoss: 0.6421, LR: 0.001
[2026-01-30 09:46:08,504] [INFO] Epoch 12/50, ValAcc: 84.51%, TrainLoss: 0.6631, ValLoss: 0.5886, LR: 0.001
[2026-01-30 09:46:44,877] [INFO] Epoch 13/50, ValAcc: 84.08%, TrainLoss: 0.6112, ValLoss: 0.6002, LR: 0.001
[2026-01-30 09:47:21,277] [INFO] Epoch 14/50, ValAcc: 84.91%, TrainLoss: 0.5928, ValLoss: 0.5785, LR: 0.001
[2026-01-30 09:47:57,735] [INFO] Epoch 15/50, ValAcc: 86.95%, TrainLoss: 0.5697, ValLoss: 0.5105, LR: 0.001
[2026-01-30 09:48:34,216] [INFO] Epoch 16/50, ValAcc: 87.48%, TrainLoss: 0.5271, ValLoss: 0.4682, LR: 0.001
[2026-01-30 09:49:10,681] [INFO] Epoch 17/50, ValAcc: 89.48%, TrainLoss: 0.4909, ValLoss: 0.4180, LR: 0.001
[2026-01-30 09:49:47,156] [INFO] Epoch 18/50, ValAcc: 89.41%, TrainLoss: 0.4591, ValLoss: 0.4151, LR: 0.001
[2026-01-30 09:50:41,699] [INFO] Epoch 19/50, ValAcc: 89.75%, TrainLoss: 0.4484, ValLoss: 0.4018, LR: 0.001
[2026-01-30 09:52:02,669] [INFO] Epoch 20/50, ValAcc: 90.34%, TrainLoss: 0.4284, ValLoss: 0.3906, LR: 0.001
[2026-01-30 09:53:23,616] [INFO] Epoch 21/50, ValAcc: 90.24%, TrainLoss: 0.4110, ValLoss: 0.3837, LR: 0.001
[2026-01-30 09:54:44,151] [INFO] Epoch 22/50, ValAcc: 90.91%, TrainLoss: 0.4091, ValLoss: 0.3774, LR: 0.001
[2026-01-30 09:56:05,152] [INFO] Epoch 23/50, ValAcc: 90.80%, TrainLoss: 0.4020, ValLoss: 0.3733, LR: 0.001
[2026-01-30 09:57:25,883] [INFO] Epoch 24/50, ValAcc: 90.69%, TrainLoss: 0.4034, ValLoss: 0.3998, LR: 0.001
[2026-01-30 09:58:46,998] [INFO] Epoch 25/50, ValAcc: 90.58%, TrainLoss: 0.3971, ValLoss: 0.3937, LR: 0.001
[2026-01-30 10:00:08,100] [INFO] Epoch 26/50, ValAcc: 91.41%, TrainLoss: 0.4061, ValLoss: 0.3500, LR: 0.001
[2026-01-30 10:01:28,974] [INFO] Epoch 27/50, ValAcc: 90.25%, TrainLoss: 0.4048, ValLoss: 0.3963, LR: 0.001
[2026-01-30 10:02:49,963] [INFO] Epoch 28/50, ValAcc: 90.63%, TrainLoss: 0.3752, ValLoss: 0.3611, LR: 0.001
[2026-01-30 10:04:10,694] [INFO] Epoch 29/50, ValAcc: 91.42%, TrainLoss: 0.3747, ValLoss: 0.3527, LR: 0.001
[2026-01-30 10:05:31,660] [INFO] Epoch 30/50, ValAcc: 92.19%, TrainLoss: 0.3127, ValLoss: 0.3262, LR: 0.0005
[2026-01-30 10:06:52,638] [INFO] Epoch 31/50, ValAcc: 92.33%, TrainLoss: 0.2990, ValLoss: 0.2970, LR: 0.0005
[2026-01-30 10:08:13,338] [INFO] Epoch 32/50, ValAcc: 92.15%, TrainLoss: 0.2926, ValLoss: 0.3078, LR: 0.0005
[2026-01-30 10:09:34,286] [INFO] Epoch 33/50, ValAcc: 92.11%, TrainLoss: 0.2861, ValLoss: 0.3000, LR: 0.0005
[2026-01-30 10:10:55,084] [INFO] Epoch 34/50, ValAcc: 91.79%, TrainLoss: 0.2857, ValLoss: 0.3102, LR: 0.0005
[2026-01-30 10:12:15,801] [INFO] Epoch 35/50, ValAcc: 92.58%, TrainLoss: 0.2587, ValLoss: 0.2853, LR: 0.00025
[2026-01-30 10:13:36,732] [INFO] Epoch 36/50, ValAcc: 92.58%, TrainLoss: 0.2504, ValLoss: 0.2858, LR: 0.00025
[2026-01-30 10:14:57,401] [INFO] Epoch 37/50, ValAcc: 92.67%, TrainLoss: 0.2442, ValLoss: 0.2925, LR: 0.00025
[2026-01-30 10:16:18,348] [INFO] Epoch 38/50, ValAcc: 93.08%, TrainLoss: 0.2407, ValLoss: 0.2801, LR: 0.00025
[2026-01-30 10:17:39,309] [INFO] Epoch 39/50, ValAcc: 92.78%, TrainLoss: 0.2405, ValLoss: 0.2864, LR: 0.00025
[2026-01-30 10:19:00,080] [INFO] Epoch 40/50, ValAcc: 92.67%, TrainLoss: 0.2348, ValLoss: 0.2828, LR: 0.00025
[2026-01-30 10:20:21,051] [INFO] Epoch 41/50, ValAcc: 93.14%, TrainLoss: 0.2314, ValLoss: 0.2823, LR: 0.00025
[2026-01-30 10:21:41,778] [INFO] Epoch 42/50, ValAcc: 92.88%, TrainLoss: 0.2217, ValLoss: 0.2718, LR: 0.000125
[2026-01-30 10:23:02,729] [INFO] Epoch 43/50, ValAcc: 92.93%, TrainLoss: 0.2206, ValLoss: 0.2757, LR: 0.000125
[2026-01-30 10:24:23,672] [INFO] Epoch 44/50, ValAcc: 92.90%, TrainLoss: 0.2170, ValLoss: 0.2705, LR: 0.000125
[2026-01-30 10:25:44,398] [INFO] Epoch 45/50, ValAcc: 93.04%, TrainLoss: 0.2143, ValLoss: 0.2729, LR: 0.000125
[2026-01-30 10:27:05,365] [INFO] Epoch 46/50, ValAcc: 92.84%, TrainLoss: 0.2124, ValLoss: 0.2812, LR: 0.000125
[2026-01-30 10:28:25,991] [INFO] Epoch 47/50, ValAcc: 93.05%, TrainLoss: 0.2126, ValLoss: 0.2784, LR: 0.000125
[2026-01-30 10:29:46,915] [INFO] Epoch 48/50, ValAcc: 93.07%, TrainLoss: 0.2060, ValLoss: 0.2808, LR: 6.25e-05
[2026-01-30 10:29:46,915] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 10:30:00,409] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['birnn'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769756653.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769756653.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_birnn_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9280,0.9304,0.9398,0.9282
[2026-01-30 10:30:00,410] [INFO] Training Fold 4/5
[2026-01-30 10:31:32,841] [INFO] Feature 0 normalized using token
[2026-01-30 10:31:32,841] [INFO] Train shape: (59144, 1000), Val shape: (8450, 1000), Test shape: (16898, 1000)
[2026-01-30 10:31:32,910] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): RNN(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 10:31:32,910] [INFO] Training...
[2026-01-30 10:32:54,043] [INFO] Epoch 1/50, ValAcc: 52.76%, TrainLoss: 3.0952, ValLoss: 1.7473, LR: 0.001
[2026-01-30 10:34:14,659] [INFO] Epoch 2/50, ValAcc: 62.54%, TrainLoss: 1.6211, ValLoss: 1.4085, LR: 0.001
[2026-01-30 10:35:35,694] [INFO] Epoch 3/50, ValAcc: 66.36%, TrainLoss: 1.4061, ValLoss: 1.2618, LR: 0.001
[2026-01-30 10:36:56,724] [INFO] Epoch 4/50, ValAcc: 68.80%, TrainLoss: 1.2481, ValLoss: 1.1664, LR: 0.001
[2026-01-30 10:38:17,317] [INFO] Epoch 5/50, ValAcc: 70.86%, TrainLoss: 1.1752, ValLoss: 1.0992, LR: 0.001
[2026-01-30 10:39:38,383] [INFO] Epoch 6/50, ValAcc: 69.99%, TrainLoss: 1.1136, ValLoss: 1.1103, LR: 0.001
[2026-01-30 10:40:58,979] [INFO] Epoch 7/50, ValAcc: 78.67%, TrainLoss: 1.0155, ValLoss: 0.8554, LR: 0.001
[2026-01-30 10:42:20,000] [INFO] Epoch 8/50, ValAcc: 80.82%, TrainLoss: 0.8625, ValLoss: 0.7705, LR: 0.001
[2026-01-30 10:43:41,029] [INFO] Epoch 9/50, ValAcc: 82.41%, TrainLoss: 0.7722, ValLoss: 0.7508, LR: 0.001
[2026-01-30 10:45:01,643] [INFO] Epoch 10/50, ValAcc: 84.24%, TrainLoss: 0.7063, ValLoss: 0.6372, LR: 0.001
[2026-01-30 10:46:22,654] [INFO] Epoch 11/50, ValAcc: 85.30%, TrainLoss: 0.6433, ValLoss: 0.5792, LR: 0.001
[2026-01-30 10:47:43,228] [INFO] Epoch 12/50, ValAcc: 86.85%, TrainLoss: 0.6211, ValLoss: 0.5806, LR: 0.001
[2026-01-30 10:49:04,219] [INFO] Epoch 13/50, ValAcc: 87.43%, TrainLoss: 0.5788, ValLoss: 0.5406, LR: 0.001
[2026-01-30 10:50:25,217] [INFO] Epoch 14/50, ValAcc: 88.26%, TrainLoss: 0.5346, ValLoss: 0.5207, LR: 0.001
[2026-01-30 10:51:45,780] [INFO] Epoch 15/50, ValAcc: 88.19%, TrainLoss: 0.5094, ValLoss: 0.5031, LR: 0.001
[2026-01-30 10:53:06,754] [INFO] Epoch 16/50, ValAcc: 88.83%, TrainLoss: 0.4991, ValLoss: 0.4695, LR: 0.001
[2026-01-30 10:54:27,643] [INFO] Epoch 17/50, ValAcc: 89.53%, TrainLoss: 0.4783, ValLoss: 0.4553, LR: 0.001
[2026-01-30 10:55:48,296] [INFO] Epoch 18/50, ValAcc: 89.66%, TrainLoss: 0.4663, ValLoss: 0.4765, LR: 0.001
[2026-01-30 10:57:09,298] [INFO] Epoch 19/50, ValAcc: 88.24%, TrainLoss: 0.4502, ValLoss: 0.5155, LR: 0.001
[2026-01-30 10:58:29,859] [INFO] Epoch 20/50, ValAcc: 89.62%, TrainLoss: 0.4441, ValLoss: 0.4297, LR: 0.001
[2026-01-30 10:59:50,833] [INFO] Epoch 21/50, ValAcc: 89.43%, TrainLoss: 0.4387, ValLoss: 0.4664, LR: 0.001
[2026-01-30 11:01:11,805] [INFO] Epoch 22/50, ValAcc: 88.28%, TrainLoss: 0.4351, ValLoss: 0.4767, LR: 0.001
[2026-01-30 11:02:32,334] [INFO] Epoch 23/50, ValAcc: 90.04%, TrainLoss: 0.4353, ValLoss: 0.4279, LR: 0.001
[2026-01-30 11:03:53,326] [INFO] Epoch 24/50, ValAcc: 90.67%, TrainLoss: 0.3990, ValLoss: 0.3893, LR: 0.001
[2026-01-30 11:05:13,883] [INFO] Epoch 25/50, ValAcc: 90.40%, TrainLoss: 0.3884, ValLoss: 0.4165, LR: 0.001
[2026-01-30 11:06:34,836] [INFO] Epoch 26/50, ValAcc: 90.63%, TrainLoss: 0.4074, ValLoss: 0.4178, LR: 0.001
[2026-01-30 11:07:55,821] [INFO] Epoch 27/50, ValAcc: 90.92%, TrainLoss: 0.3898, ValLoss: 0.3887, LR: 0.001
[2026-01-30 11:09:16,343] [INFO] Epoch 28/50, ValAcc: 91.24%, TrainLoss: 0.3767, ValLoss: 0.3735, LR: 0.001
[2026-01-30 11:10:37,286] [INFO] Epoch 29/50, ValAcc: 91.03%, TrainLoss: 0.3844, ValLoss: 0.3837, LR: 0.001
[2026-01-30 11:11:58,011] [INFO] Epoch 30/50, ValAcc: 90.89%, TrainLoss: 0.3780, ValLoss: 0.3709, LR: 0.001
[2026-01-30 11:13:18,749] [INFO] Epoch 31/50, ValAcc: 88.91%, TrainLoss: 0.3741, ValLoss: 0.4843, LR: 0.001
[2026-01-30 11:14:39,702] [INFO] Epoch 32/50, ValAcc: 90.47%, TrainLoss: 0.4372, ValLoss: 0.3782, LR: 0.001
[2026-01-30 11:16:00,213] [INFO] Epoch 33/50, ValAcc: 90.71%, TrainLoss: 0.3857, ValLoss: 0.4101, LR: 0.001
[2026-01-30 11:17:21,164] [INFO] Epoch 34/50, ValAcc: 92.06%, TrainLoss: 0.3199, ValLoss: 0.3644, LR: 0.0005
[2026-01-30 11:18:42,105] [INFO] Epoch 35/50, ValAcc: 91.75%, TrainLoss: 0.3015, ValLoss: 0.3600, LR: 0.0005
[2026-01-30 11:19:41,383] [INFO] Epoch 36/50, ValAcc: 91.99%, TrainLoss: 0.2939, ValLoss: 0.3391, LR: 0.0005
[2026-01-30 11:20:56,593] [INFO] Epoch 37/50, ValAcc: 92.22%, TrainLoss: 0.2851, ValLoss: 0.3420, LR: 0.0005
[2026-01-30 11:22:17,521] [INFO] Epoch 38/50, ValAcc: 92.22%, TrainLoss: 0.2808, ValLoss: 0.3320, LR: 0.0005
[2026-01-30 11:23:38,020] [INFO] Epoch 39/50, ValAcc: 92.44%, TrainLoss: 0.2812, ValLoss: 0.3273, LR: 0.0005
[2026-01-30 11:24:59,005] [INFO] Epoch 40/50, ValAcc: 92.17%, TrainLoss: 0.2750, ValLoss: 0.3354, LR: 0.0005
[2026-01-30 11:26:19,968] [INFO] Epoch 41/50, ValAcc: 92.58%, TrainLoss: 0.2811, ValLoss: 0.3241, LR: 0.0005
[2026-01-30 11:27:40,506] [INFO] Epoch 42/50, ValAcc: 91.82%, TrainLoss: 0.2725, ValLoss: 0.3468, LR: 0.0005
[2026-01-30 11:29:01,475] [INFO] Epoch 43/50, ValAcc: 92.34%, TrainLoss: 0.2692, ValLoss: 0.3268, LR: 0.0005
[2026-01-30 11:30:21,985] [INFO] Epoch 44/50, ValAcc: 92.21%, TrainLoss: 0.2689, ValLoss: 0.3254, LR: 0.0005
[2026-01-30 11:31:42,919] [INFO] Epoch 45/50, ValAcc: 91.88%, TrainLoss: 0.2500, ValLoss: 0.3483, LR: 0.00025
[2026-01-30 11:33:03,829] [INFO] Epoch 46/50, ValAcc: 92.57%, TrainLoss: 0.2655, ValLoss: 0.3280, LR: 0.00025
[2026-01-30 11:34:24,357] [INFO] Epoch 47/50, ValAcc: 92.57%, TrainLoss: 0.2515, ValLoss: 0.3357, LR: 0.00025
[2026-01-30 11:35:45,301] [INFO] Epoch 48/50, ValAcc: 92.57%, TrainLoss: 0.2363, ValLoss: 0.3214, LR: 0.000125
[2026-01-30 11:37:06,037] [INFO] Epoch 49/50, ValAcc: 92.52%, TrainLoss: 0.2297, ValLoss: 0.3229, LR: 0.000125
[2026-01-30 11:38:26,775] [INFO] Epoch 50/50, ValAcc: 92.88%, TrainLoss: 0.2272, ValLoss: 0.3119, LR: 0.000125
[2026-01-30 11:38:40,294] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['birnn'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769756653.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769756653.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_birnn_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9327,0.9335,0.9408,0.9324
[2026-01-30 11:38:40,295] [INFO] Training Fold 5/5
[2026-01-30 11:40:15,637] [INFO] Feature 0 normalized using token
[2026-01-30 11:40:15,637] [INFO] Train shape: (59144, 1000), Val shape: (8450, 1000), Test shape: (16898, 1000)
[2026-01-30 11:40:15,673] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): RNN(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 11:40:15,673] [INFO] Training...
[2026-01-30 11:41:36,752] [INFO] Epoch 1/50, ValAcc: 59.21%, TrainLoss: 2.7524, ValLoss: 1.5257, LR: 0.001
[2026-01-30 11:42:48,992] [INFO] Epoch 2/50, ValAcc: 66.70%, TrainLoss: 1.4096, ValLoss: 1.2595, LR: 0.001
[2026-01-30 11:43:25,299] [INFO] Epoch 3/50, ValAcc: 72.96%, TrainLoss: 1.1349, ValLoss: 1.0124, LR: 0.001
[2026-01-30 11:44:01,598] [INFO] Epoch 4/50, ValAcc: 77.51%, TrainLoss: 0.9533, ValLoss: 0.8695, LR: 0.001
[2026-01-30 11:44:37,901] [INFO] Epoch 5/50, ValAcc: 79.89%, TrainLoss: 0.8437, ValLoss: 0.7795, LR: 0.001
[2026-01-30 11:45:14,175] [INFO] Epoch 6/50, ValAcc: 81.41%, TrainLoss: 0.7622, ValLoss: 0.7183, LR: 0.001
[2026-01-30 11:45:50,441] [INFO] Epoch 7/50, ValAcc: 81.36%, TrainLoss: 0.6982, ValLoss: 0.7163, LR: 0.001
[2026-01-30 11:46:26,703] [INFO] Epoch 8/50, ValAcc: 83.44%, TrainLoss: 0.6594, ValLoss: 0.6369, LR: 0.001
[2026-01-30 11:47:02,967] [INFO] Epoch 9/50, ValAcc: 84.65%, TrainLoss: 0.6174, ValLoss: 0.6117, LR: 0.001
[2026-01-30 11:47:39,231] [INFO] Epoch 10/50, ValAcc: 86.93%, TrainLoss: 0.5477, ValLoss: 0.5514, LR: 0.001
[2026-01-30 11:48:15,484] [INFO] Epoch 11/50, ValAcc: 88.05%, TrainLoss: 0.5058, ValLoss: 0.4941, LR: 0.001
[2026-01-30 11:48:51,729] [INFO] Epoch 12/50, ValAcc: 86.88%, TrainLoss: 0.5102, ValLoss: 0.5846, LR: 0.001
[2026-01-30 11:49:27,985] [INFO] Epoch 13/50, ValAcc: 88.11%, TrainLoss: 0.4961, ValLoss: 0.5012, LR: 0.001
[2026-01-30 11:50:04,278] [INFO] Epoch 14/50, ValAcc: 88.84%, TrainLoss: 0.4652, ValLoss: 0.4555, LR: 0.001
[2026-01-30 11:50:40,557] [INFO] Epoch 15/50, ValAcc: 89.50%, TrainLoss: 0.4508, ValLoss: 0.4807, LR: 0.001
[2026-01-30 11:51:16,840] [INFO] Epoch 16/50, ValAcc: 89.46%, TrainLoss: 0.4347, ValLoss: 0.4433, LR: 0.001
[2026-01-30 11:51:53,104] [INFO] Epoch 17/50, ValAcc: 89.48%, TrainLoss: 0.4396, ValLoss: 0.4454, LR: 0.001
[2026-01-30 11:53:05,831] [INFO] Epoch 18/50, ValAcc: 89.23%, TrainLoss: 0.4232, ValLoss: 0.4712, LR: 0.001
[2026-01-30 11:54:26,974] [INFO] Epoch 19/50, ValAcc: 90.33%, TrainLoss: 0.4132, ValLoss: 0.4187, LR: 0.001
[2026-01-30 11:55:47,598] [INFO] Epoch 20/50, ValAcc: 90.60%, TrainLoss: 0.3964, ValLoss: 0.4476, LR: 0.001
[2026-01-30 11:57:08,680] [INFO] Epoch 21/50, ValAcc: 91.02%, TrainLoss: 0.3856, ValLoss: 0.4215, LR: 0.001
[2026-01-30 11:58:29,800] [INFO] Epoch 22/50, ValAcc: 89.70%, TrainLoss: 0.3829, ValLoss: 0.4244, LR: 0.001
[2026-01-30 11:59:50,453] [INFO] Epoch 23/50, ValAcc: 91.68%, TrainLoss: 0.3165, ValLoss: 0.3848, LR: 0.0005
[2026-01-30 12:01:11,538] [INFO] Epoch 24/50, ValAcc: 91.16%, TrainLoss: 0.3230, ValLoss: 0.3939, LR: 0.0005
[2026-01-30 12:02:32,668] [INFO] Epoch 25/50, ValAcc: 91.50%, TrainLoss: 0.3142, ValLoss: 0.3628, LR: 0.0005
[2026-01-30 12:03:53,268] [INFO] Epoch 26/50, ValAcc: 92.17%, TrainLoss: 0.2771, ValLoss: 0.3519, LR: 0.0005
[2026-01-30 12:05:14,385] [INFO] Epoch 27/50, ValAcc: 92.50%, TrainLoss: 0.2591, ValLoss: 0.3283, LR: 0.0005
[2026-01-30 12:06:34,985] [INFO] Epoch 28/50, ValAcc: 92.11%, TrainLoss: 0.2887, ValLoss: 0.3544, LR: 0.0005
[2026-01-30 12:07:56,097] [INFO] Epoch 29/50, ValAcc: 92.51%, TrainLoss: 0.2697, ValLoss: 0.3230, LR: 0.0005
[2026-01-30 12:09:17,216] [INFO] Epoch 30/50, ValAcc: 92.96%, TrainLoss: 0.2447, ValLoss: 0.3245, LR: 0.0005
[2026-01-30 12:10:37,795] [INFO] Epoch 31/50, ValAcc: 92.33%, TrainLoss: 0.2522, ValLoss: 0.3180, LR: 0.0005
[2026-01-30 12:11:58,898] [INFO] Epoch 32/50, ValAcc: 92.76%, TrainLoss: 0.2415, ValLoss: 0.3217, LR: 0.0005
[2026-01-30 12:13:20,035] [INFO] Epoch 33/50, ValAcc: 92.58%, TrainLoss: 0.2401, ValLoss: 0.3152, LR: 0.0005
[2026-01-30 12:14:14,563] [INFO] Epoch 34/50, ValAcc: 92.78%, TrainLoss: 0.2375, ValLoss: 0.3232, LR: 0.0005
[2026-01-30 12:14:50,785] [INFO] Epoch 35/50, ValAcc: 92.22%, TrainLoss: 0.2518, ValLoss: 0.3274, LR: 0.0005
[2026-01-30 12:15:27,000] [INFO] Epoch 36/50, ValAcc: 92.98%, TrainLoss: 0.2874, ValLoss: 0.3202, LR: 0.0005
[2026-01-30 12:16:03,243] [INFO] Epoch 37/50, ValAcc: 92.90%, TrainLoss: 0.2296, ValLoss: 0.3050, LR: 0.00025
[2026-01-30 12:16:39,630] [INFO] Epoch 38/50, ValAcc: 92.98%, TrainLoss: 0.2187, ValLoss: 0.3112, LR: 0.00025
[2026-01-30 12:17:15,996] [INFO] Epoch 39/50, ValAcc: 93.02%, TrainLoss: 0.2141, ValLoss: 0.3009, LR: 0.00025
[2026-01-30 12:17:52,381] [INFO] Epoch 40/50, ValAcc: 93.03%, TrainLoss: 0.2155, ValLoss: 0.3081, LR: 0.00025
[2026-01-30 12:18:28,756] [INFO] Epoch 41/50, ValAcc: 93.17%, TrainLoss: 0.2115, ValLoss: 0.3095, LR: 0.00025
[2026-01-30 12:19:31,737] [INFO] Epoch 42/50, ValAcc: 93.25%, TrainLoss: 0.2145, ValLoss: 0.2918, LR: 0.00025
[2026-01-30 12:20:52,803] [INFO] Epoch 43/50, ValAcc: 93.33%, TrainLoss: 0.2035, ValLoss: 0.3112, LR: 0.00025
[2026-01-30 12:22:13,546] [INFO] Epoch 44/50, ValAcc: 93.25%, TrainLoss: 0.1986, ValLoss: 0.3070, LR: 0.00025
[2026-01-30 12:23:34,360] [INFO] Epoch 45/50, ValAcc: 93.05%, TrainLoss: 0.2019, ValLoss: 0.2946, LR: 0.00025
[2026-01-30 12:24:55,387] [INFO] Epoch 46/50, ValAcc: 93.28%, TrainLoss: 0.1947, ValLoss: 0.3029, LR: 0.000125
[2026-01-30 12:26:15,905] [INFO] Epoch 47/50, ValAcc: 93.22%, TrainLoss: 0.1915, ValLoss: 0.3077, LR: 0.000125
[2026-01-30 12:27:36,945] [INFO] Epoch 48/50, ValAcc: 93.30%, TrainLoss: 0.1889, ValLoss: 0.3024, LR: 0.000125
[2026-01-30 12:28:57,996] [INFO] Epoch 49/50, ValAcc: 93.44%, TrainLoss: 0.1839, ValLoss: 0.2949, LR: 6.25e-05
[2026-01-30 12:28:57,996] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 12:29:11,494] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['birnn'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769756653.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769756653.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_birnn_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9390,0.9417,0.9489,0.9386
[2026-01-30 12:29:12,528] [INFO] [(0.93248121190603, 0.935334543922074, 0.9422032008514543, 0.9327414431238609), (0.9144328066749512, 0.9166885041910636, 0.9242741938504081, 0.9155569134540127), (0.9280388211622678, 0.9303933577705162, 0.9397923669250825, 0.9281704679257142), (0.9327139306426796, 0.933461634828686, 0.9407781586591717, 0.9324246123045288), (0.9390460409515919, 0.9417383413812516, 0.9488554563024869, 0.9385976413743504)]
=== Step4. Script Execution Finished at Fri Jan 30 12:29:13 PM UTC 2026 ===
