=== Step4. Script Execution Started at Fri Jan 30 04:18:05 AM UTC 2026 ===
Base directory: meta-free-apps
Data prefix: meta
Output directory: output/meta-free-apps/model_evaluation
Running python vrscanner.py --train --path meta-free-apps/meta-ip_len/meta-ip_len.csv --debug_path output/meta-free-apps/model_evaluation/model_evaluation_meta_1769746685.debug --leaderboard_path output/meta-free-apps/model_evaluation/model_evaluation_meta_1769746685.csv --norm token --model cnn --kfold 5 --lr 0.001 --strict
[2026-01-30 04:18:07,483] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['cnn'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769746685.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769746685.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'))
[2026-01-30 04:21:14,230] [INFO] Processed data from meta-free-apps/meta-ip_len/meta-ip_len.csv:
[2026-01-30 04:21:14,230] [INFO] (84492, 1000)
[2026-01-30 04:21:14,230] [INFO] [['656' '94' '52' ... '181' '52' '52']
 ['423' '87' '52' ... '60' '60' '52']
 ['423' '87' '52' ... '1432' '52' '1432']
 ...
 ['242' '87' '52' ... '424' '700' '52']
 ['60' '60' '52' ... '143' '52' '355']
 ['64' '52' '52' ... '91' '52' '91']]
[2026-01-30 04:21:14,560] [INFO] Training Fold 1/5
[2026-01-30 04:22:50,188] [INFO] Feature 0 normalized using token
[2026-01-30 04:22:50,189] [INFO] Train shape: (59143, 1000), Val shape: (8450, 1000), Test shape: (16899, 1000)
[2026-01-30 04:22:50,245] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): Sequential(
      (0): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))
      (1): ReLU()
      (2): Dropout(p=0.3, inplace=False)
      (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
      (4): ReLU()
      (5): Dropout(p=0.3, inplace=False)
    )
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=256, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=256, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 04:22:50,245] [INFO] Training...
[2026-01-30 04:22:58,217] [INFO] Epoch 1/50, ValAcc: 51.38%, TrainLoss: 3.2518, ValLoss: 1.6278, LR: 0.001
[2026-01-30 04:23:05,160] [INFO] Epoch 2/50, ValAcc: 73.53%, TrainLoss: 1.4084, ValLoss: 0.9846, LR: 0.001
[2026-01-30 04:23:12,336] [INFO] Epoch 3/50, ValAcc: 83.75%, TrainLoss: 0.9182, ValLoss: 0.6577, LR: 0.001
[2026-01-30 04:23:19,468] [INFO] Epoch 4/50, ValAcc: 87.40%, TrainLoss: 0.6837, ValLoss: 0.5301, LR: 0.001
[2026-01-30 04:23:26,613] [INFO] Epoch 5/50, ValAcc: 89.21%, TrainLoss: 0.5744, ValLoss: 0.4713, LR: 0.001
[2026-01-30 04:23:33,737] [INFO] Epoch 6/50, ValAcc: 89.95%, TrainLoss: 0.5070, ValLoss: 0.4306, LR: 0.001
[2026-01-30 04:23:40,821] [INFO] Epoch 7/50, ValAcc: 90.62%, TrainLoss: 0.4637, ValLoss: 0.3947, LR: 0.001
[2026-01-30 04:23:47,911] [INFO] Epoch 8/50, ValAcc: 90.85%, TrainLoss: 0.4163, ValLoss: 0.3962, LR: 0.001
[2026-01-30 04:23:55,016] [INFO] Epoch 9/50, ValAcc: 91.30%, TrainLoss: 0.3913, ValLoss: 0.3545, LR: 0.001
[2026-01-30 04:24:01,822] [INFO] Epoch 10/50, ValAcc: 91.80%, TrainLoss: 0.3669, ValLoss: 0.3400, LR: 0.001
[2026-01-30 04:24:08,806] [INFO] Epoch 11/50, ValAcc: 91.94%, TrainLoss: 0.3485, ValLoss: 0.3677, LR: 0.001
[2026-01-30 04:24:15,833] [INFO] Epoch 12/50, ValAcc: 92.17%, TrainLoss: 0.3284, ValLoss: 0.3469, LR: 0.001
[2026-01-30 04:24:22,811] [INFO] Epoch 13/50, ValAcc: 92.36%, TrainLoss: 0.3163, ValLoss: 0.3261, LR: 0.001
[2026-01-30 04:24:29,889] [INFO] Epoch 14/50, ValAcc: 91.82%, TrainLoss: 0.3021, ValLoss: 0.3467, LR: 0.001
[2026-01-30 04:24:36,908] [INFO] Epoch 15/50, ValAcc: 92.36%, TrainLoss: 0.2960, ValLoss: 0.3242, LR: 0.001
[2026-01-30 04:24:43,852] [INFO] Epoch 16/50, ValAcc: 92.34%, TrainLoss: 0.2831, ValLoss: 0.3371, LR: 0.001
[2026-01-30 04:24:50,795] [INFO] Epoch 17/50, ValAcc: 92.41%, TrainLoss: 0.2793, ValLoss: 0.3189, LR: 0.001
[2026-01-30 04:24:57,769] [INFO] Epoch 18/50, ValAcc: 92.73%, TrainLoss: 0.2659, ValLoss: 0.3277, LR: 0.001
[2026-01-30 04:25:04,688] [INFO] Epoch 19/50, ValAcc: 92.33%, TrainLoss: 0.2627, ValLoss: 0.3297, LR: 0.001
[2026-01-30 04:25:11,616] [INFO] Epoch 20/50, ValAcc: 92.64%, TrainLoss: 0.2568, ValLoss: 0.3089, LR: 0.001
[2026-01-30 04:25:18,615] [INFO] Epoch 21/50, ValAcc: 92.82%, TrainLoss: 0.2529, ValLoss: 0.3215, LR: 0.001
[2026-01-30 04:25:25,671] [INFO] Epoch 22/50, ValAcc: 92.79%, TrainLoss: 0.2492, ValLoss: 0.3259, LR: 0.001
[2026-01-30 04:25:32,638] [INFO] Epoch 23/50, ValAcc: 92.92%, TrainLoss: 0.2406, ValLoss: 0.3241, LR: 0.001
[2026-01-30 04:25:39,621] [INFO] Epoch 24/50, ValAcc: 93.42%, TrainLoss: 0.2108, ValLoss: 0.3200, LR: 0.0005
[2026-01-30 04:25:46,621] [INFO] Epoch 25/50, ValAcc: 93.25%, TrainLoss: 0.2033, ValLoss: 0.3299, LR: 0.0005
[2026-01-30 04:25:53,602] [INFO] Epoch 26/50, ValAcc: 92.99%, TrainLoss: 0.1971, ValLoss: 0.3317, LR: 0.0005
[2026-01-30 04:26:00,573] [INFO] Epoch 27/50, ValAcc: 93.41%, TrainLoss: 0.1804, ValLoss: 0.3354, LR: 0.00025
[2026-01-30 04:26:07,592] [INFO] Epoch 28/50, ValAcc: 93.15%, TrainLoss: 0.1788, ValLoss: 0.3330, LR: 0.00025
[2026-01-30 04:26:14,618] [INFO] Epoch 29/50, ValAcc: 93.24%, TrainLoss: 0.1738, ValLoss: 0.3382, LR: 0.00025
[2026-01-30 04:26:21,594] [INFO] Epoch 30/50, ValAcc: 93.25%, TrainLoss: 0.1683, ValLoss: 0.3471, LR: 0.000125
[2026-01-30 04:26:28,574] [INFO] Epoch 31/50, ValAcc: 93.38%, TrainLoss: 0.1654, ValLoss: 0.3486, LR: 0.000125
[2026-01-30 04:26:35,553] [INFO] Epoch 32/50, ValAcc: 93.38%, TrainLoss: 0.1617, ValLoss: 0.3449, LR: 0.000125
[2026-01-30 04:26:42,522] [INFO] Epoch 33/50, ValAcc: 93.33%, TrainLoss: 0.1584, ValLoss: 0.3560, LR: 6.25e-05
[2026-01-30 04:26:42,523] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 04:26:43,560] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['cnn'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769746685.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769746685.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_cnn_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9316,0.9321,0.9340,0.9318
[2026-01-30 04:26:43,561] [INFO] Training Fold 2/5
[2026-01-30 04:28:17,406] [INFO] Feature 0 normalized using token
[2026-01-30 04:28:17,406] [INFO] Train shape: (59143, 1000), Val shape: (8450, 1000), Test shape: (16899, 1000)
[2026-01-30 04:28:17,447] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): Sequential(
      (0): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))
      (1): ReLU()
      (2): Dropout(p=0.3, inplace=False)
      (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
      (4): ReLU()
      (5): Dropout(p=0.3, inplace=False)
    )
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=256, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=256, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 04:28:17,447] [INFO] Training...
[2026-01-30 04:28:24,404] [INFO] Epoch 1/50, ValAcc: 58.01%, TrainLoss: 3.2453, ValLoss: 1.5554, LR: 0.001
[2026-01-30 04:28:31,391] [INFO] Epoch 2/50, ValAcc: 71.44%, TrainLoss: 1.4264, ValLoss: 1.0814, LR: 0.001
[2026-01-30 04:28:38,386] [INFO] Epoch 3/50, ValAcc: 81.07%, TrainLoss: 1.0181, ValLoss: 0.7330, LR: 0.001
[2026-01-30 04:28:45,383] [INFO] Epoch 4/50, ValAcc: 84.79%, TrainLoss: 0.7368, ValLoss: 0.5848, LR: 0.001
[2026-01-30 04:28:52,386] [INFO] Epoch 5/50, ValAcc: 87.74%, TrainLoss: 0.6213, ValLoss: 0.4953, LR: 0.001
[2026-01-30 04:28:59,463] [INFO] Epoch 6/50, ValAcc: 89.60%, TrainLoss: 0.5228, ValLoss: 0.4461, LR: 0.001
[2026-01-30 04:29:06,459] [INFO] Epoch 7/50, ValAcc: 90.40%, TrainLoss: 0.4726, ValLoss: 0.4047, LR: 0.001
[2026-01-30 04:29:13,446] [INFO] Epoch 8/50, ValAcc: 90.78%, TrainLoss: 0.4294, ValLoss: 0.3768, LR: 0.001
[2026-01-30 04:29:20,434] [INFO] Epoch 9/50, ValAcc: 91.02%, TrainLoss: 0.3972, ValLoss: 0.3753, LR: 0.001
[2026-01-30 04:29:27,421] [INFO] Epoch 10/50, ValAcc: 91.44%, TrainLoss: 0.3722, ValLoss: 0.3562, LR: 0.001
[2026-01-30 04:29:34,415] [INFO] Epoch 11/50, ValAcc: 91.82%, TrainLoss: 0.3566, ValLoss: 0.3457, LR: 0.001
[2026-01-30 04:29:41,400] [INFO] Epoch 12/50, ValAcc: 92.05%, TrainLoss: 0.3403, ValLoss: 0.3285, LR: 0.001
[2026-01-30 04:29:48,378] [INFO] Epoch 13/50, ValAcc: 91.87%, TrainLoss: 0.3240, ValLoss: 0.3380, LR: 0.001
[2026-01-30 04:29:55,376] [INFO] Epoch 14/50, ValAcc: 92.09%, TrainLoss: 0.3081, ValLoss: 0.3289, LR: 0.001
[2026-01-30 04:30:02,390] [INFO] Epoch 15/50, ValAcc: 92.11%, TrainLoss: 0.3001, ValLoss: 0.3202, LR: 0.001
[2026-01-30 04:30:09,452] [INFO] Epoch 16/50, ValAcc: 92.50%, TrainLoss: 0.2903, ValLoss: 0.3154, LR: 0.001
[2026-01-30 04:30:16,457] [INFO] Epoch 17/50, ValAcc: 92.38%, TrainLoss: 0.2763, ValLoss: 0.3152, LR: 0.001
[2026-01-30 04:30:23,448] [INFO] Epoch 18/50, ValAcc: 92.58%, TrainLoss: 0.2728, ValLoss: 0.3097, LR: 0.001
[2026-01-30 04:30:30,514] [INFO] Epoch 19/50, ValAcc: 92.72%, TrainLoss: 0.2629, ValLoss: 0.3214, LR: 0.001
[2026-01-30 04:30:37,506] [INFO] Epoch 20/50, ValAcc: 92.46%, TrainLoss: 0.2616, ValLoss: 0.3236, LR: 0.001
[2026-01-30 04:30:44,495] [INFO] Epoch 21/50, ValAcc: 92.60%, TrainLoss: 0.2553, ValLoss: 0.3160, LR: 0.001
[2026-01-30 04:30:51,582] [INFO] Epoch 22/50, ValAcc: 92.73%, TrainLoss: 0.2209, ValLoss: 0.3147, LR: 0.0005
[2026-01-30 04:30:58,565] [INFO] Epoch 23/50, ValAcc: 92.82%, TrainLoss: 0.2127, ValLoss: 0.3067, LR: 0.0005
[2026-01-30 04:31:05,586] [INFO] Epoch 24/50, ValAcc: 92.77%, TrainLoss: 0.2068, ValLoss: 0.3099, LR: 0.0005
[2026-01-30 04:31:12,632] [INFO] Epoch 25/50, ValAcc: 92.91%, TrainLoss: 0.2015, ValLoss: 0.3132, LR: 0.0005
[2026-01-30 04:31:19,605] [INFO] Epoch 26/50, ValAcc: 92.98%, TrainLoss: 0.1984, ValLoss: 0.3122, LR: 0.0005
[2026-01-30 04:31:26,626] [INFO] Epoch 27/50, ValAcc: 92.96%, TrainLoss: 0.1864, ValLoss: 0.3064, LR: 0.00025
[2026-01-30 04:31:33,686] [INFO] Epoch 28/50, ValAcc: 92.95%, TrainLoss: 0.1780, ValLoss: 0.3238, LR: 0.00025
[2026-01-30 04:31:40,676] [INFO] Epoch 29/50, ValAcc: 92.97%, TrainLoss: 0.1738, ValLoss: 0.3210, LR: 0.00025
[2026-01-30 04:31:47,616] [INFO] Epoch 30/50, ValAcc: 92.97%, TrainLoss: 0.1724, ValLoss: 0.3229, LR: 0.00025
[2026-01-30 04:31:54,620] [INFO] Epoch 31/50, ValAcc: 92.98%, TrainLoss: 0.1654, ValLoss: 0.3195, LR: 0.000125
[2026-01-30 04:32:01,649] [INFO] Epoch 32/50, ValAcc: 93.02%, TrainLoss: 0.1631, ValLoss: 0.3207, LR: 0.000125
[2026-01-30 04:32:08,684] [INFO] Epoch 33/50, ValAcc: 92.97%, TrainLoss: 0.1593, ValLoss: 0.3206, LR: 0.000125
[2026-01-30 04:32:15,689] [INFO] Epoch 34/50, ValAcc: 93.03%, TrainLoss: 0.1564, ValLoss: 0.3295, LR: 6.25e-05
[2026-01-30 04:32:15,689] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 04:32:16,708] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['cnn'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769746685.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769746685.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_cnn_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9353,0.9344,0.9367,0.9361
[2026-01-30 04:32:16,709] [INFO] Training Fold 3/5
[2026-01-30 04:33:52,277] [INFO] Feature 0 normalized using token
[2026-01-30 04:33:52,278] [INFO] Train shape: (59144, 1000), Val shape: (8450, 1000), Test shape: (16898, 1000)
[2026-01-30 04:33:52,324] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): Sequential(
      (0): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))
      (1): ReLU()
      (2): Dropout(p=0.3, inplace=False)
      (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
      (4): ReLU()
      (5): Dropout(p=0.3, inplace=False)
    )
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=256, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=256, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 04:33:52,324] [INFO] Training...
[2026-01-30 04:33:59,201] [INFO] Epoch 1/50, ValAcc: 57.44%, TrainLoss: 3.1801, ValLoss: 1.5373, LR: 0.001
[2026-01-30 04:34:06,199] [INFO] Epoch 2/50, ValAcc: 71.09%, TrainLoss: 1.4471, ValLoss: 1.0866, LR: 0.001
[2026-01-30 04:34:13,231] [INFO] Epoch 3/50, ValAcc: 80.21%, TrainLoss: 1.0420, ValLoss: 0.7705, LR: 0.001
[2026-01-30 04:34:20,293] [INFO] Epoch 4/50, ValAcc: 86.08%, TrainLoss: 0.7742, ValLoss: 0.5675, LR: 0.001
[2026-01-30 04:34:27,304] [INFO] Epoch 5/50, ValAcc: 88.47%, TrainLoss: 0.6248, ValLoss: 0.4752, LR: 0.001
[2026-01-30 04:34:34,313] [INFO] Epoch 6/50, ValAcc: 89.78%, TrainLoss: 0.5411, ValLoss: 0.4253, LR: 0.001
[2026-01-30 04:34:41,313] [INFO] Epoch 7/50, ValAcc: 90.21%, TrainLoss: 0.4780, ValLoss: 0.3901, LR: 0.001
[2026-01-30 04:34:48,327] [INFO] Epoch 8/50, ValAcc: 91.31%, TrainLoss: 0.4353, ValLoss: 0.3655, LR: 0.001
[2026-01-30 04:34:55,339] [INFO] Epoch 9/50, ValAcc: 91.73%, TrainLoss: 0.4006, ValLoss: 0.3538, LR: 0.001
[2026-01-30 04:35:02,332] [INFO] Epoch 10/50, ValAcc: 91.30%, TrainLoss: 0.3821, ValLoss: 0.3417, LR: 0.001
[2026-01-30 04:35:09,320] [INFO] Epoch 11/50, ValAcc: 91.83%, TrainLoss: 0.3606, ValLoss: 0.3354, LR: 0.001
[2026-01-30 04:35:16,344] [INFO] Epoch 12/50, ValAcc: 91.92%, TrainLoss: 0.3434, ValLoss: 0.3273, LR: 0.001
[2026-01-30 04:35:23,405] [INFO] Epoch 13/50, ValAcc: 92.24%, TrainLoss: 0.3251, ValLoss: 0.3032, LR: 0.001
[2026-01-30 04:35:30,419] [INFO] Epoch 14/50, ValAcc: 91.96%, TrainLoss: 0.3085, ValLoss: 0.3274, LR: 0.001
[2026-01-30 04:35:37,431] [INFO] Epoch 15/50, ValAcc: 92.41%, TrainLoss: 0.3017, ValLoss: 0.2932, LR: 0.001
[2026-01-30 04:35:44,432] [INFO] Epoch 16/50, ValAcc: 92.46%, TrainLoss: 0.2894, ValLoss: 0.2894, LR: 0.001
[2026-01-30 04:35:51,440] [INFO] Epoch 17/50, ValAcc: 93.04%, TrainLoss: 0.2836, ValLoss: 0.2858, LR: 0.001
[2026-01-30 04:35:58,445] [INFO] Epoch 18/50, ValAcc: 92.64%, TrainLoss: 0.2732, ValLoss: 0.2871, LR: 0.001
[2026-01-30 04:36:05,468] [INFO] Epoch 19/50, ValAcc: 92.75%, TrainLoss: 0.2635, ValLoss: 0.2821, LR: 0.001
[2026-01-30 04:36:12,536] [INFO] Epoch 20/50, ValAcc: 92.69%, TrainLoss: 0.2604, ValLoss: 0.2794, LR: 0.001
[2026-01-30 04:36:19,542] [INFO] Epoch 21/50, ValAcc: 93.08%, TrainLoss: 0.2521, ValLoss: 0.2771, LR: 0.001
[2026-01-30 04:36:26,558] [INFO] Epoch 22/50, ValAcc: 93.34%, TrainLoss: 0.2500, ValLoss: 0.2903, LR: 0.001
[2026-01-30 04:36:33,582] [INFO] Epoch 23/50, ValAcc: 92.97%, TrainLoss: 0.2378, ValLoss: 0.2905, LR: 0.001
[2026-01-30 04:36:40,751] [INFO] Epoch 24/50, ValAcc: 93.38%, TrainLoss: 0.2354, ValLoss: 0.2840, LR: 0.001
[2026-01-30 04:36:47,879] [INFO] Epoch 25/50, ValAcc: 93.60%, TrainLoss: 0.2063, ValLoss: 0.2874, LR: 0.0005
[2026-01-30 04:36:55,019] [INFO] Epoch 26/50, ValAcc: 93.47%, TrainLoss: 0.1965, ValLoss: 0.2798, LR: 0.0005
[2026-01-30 04:37:02,137] [INFO] Epoch 27/50, ValAcc: 93.15%, TrainLoss: 0.1951, ValLoss: 0.2837, LR: 0.0005
[2026-01-30 04:37:09,192] [INFO] Epoch 28/50, ValAcc: 93.29%, TrainLoss: 0.1821, ValLoss: 0.2809, LR: 0.00025
[2026-01-30 04:37:16,293] [INFO] Epoch 29/50, ValAcc: 93.51%, TrainLoss: 0.1728, ValLoss: 0.2830, LR: 0.00025
[2026-01-30 04:37:23,350] [INFO] Epoch 30/50, ValAcc: 93.47%, TrainLoss: 0.1672, ValLoss: 0.2889, LR: 0.00025
[2026-01-30 04:37:30,434] [INFO] Epoch 31/50, ValAcc: 93.34%, TrainLoss: 0.1616, ValLoss: 0.2888, LR: 0.000125
[2026-01-30 04:37:37,449] [INFO] Epoch 32/50, ValAcc: 93.22%, TrainLoss: 0.1608, ValLoss: 0.2867, LR: 0.000125
[2026-01-30 04:37:44,535] [INFO] Epoch 33/50, ValAcc: 93.38%, TrainLoss: 0.1584, ValLoss: 0.2856, LR: 0.000125
[2026-01-30 04:37:51,577] [INFO] Epoch 34/50, ValAcc: 93.53%, TrainLoss: 0.1540, ValLoss: 0.2943, LR: 6.25e-05
[2026-01-30 04:37:51,577] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 04:37:52,596] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['cnn'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769746685.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769746685.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_cnn_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9290,0.9295,0.9317,0.9292
[2026-01-30 04:37:52,597] [INFO] Training Fold 4/5
[2026-01-30 04:39:27,851] [INFO] Feature 0 normalized using token
[2026-01-30 04:39:27,852] [INFO] Train shape: (59144, 1000), Val shape: (8450, 1000), Test shape: (16898, 1000)
[2026-01-30 04:39:27,882] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): Sequential(
      (0): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))
      (1): ReLU()
      (2): Dropout(p=0.3, inplace=False)
      (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
      (4): ReLU()
      (5): Dropout(p=0.3, inplace=False)
    )
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=256, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=256, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 04:39:27,882] [INFO] Training...
[2026-01-30 04:39:34,844] [INFO] Epoch 1/50, ValAcc: 60.60%, TrainLoss: 3.2762, ValLoss: 1.4361, LR: 0.001
[2026-01-30 04:39:41,855] [INFO] Epoch 2/50, ValAcc: 71.27%, TrainLoss: 1.3521, ValLoss: 1.0599, LR: 0.001
[2026-01-30 04:39:48,865] [INFO] Epoch 3/50, ValAcc: 82.89%, TrainLoss: 1.0174, ValLoss: 0.6929, LR: 0.001
[2026-01-30 04:39:55,882] [INFO] Epoch 4/50, ValAcc: 87.05%, TrainLoss: 0.7074, ValLoss: 0.5483, LR: 0.001
[2026-01-30 04:40:02,904] [INFO] Epoch 5/50, ValAcc: 89.23%, TrainLoss: 0.5748, ValLoss: 0.4506, LR: 0.001
[2026-01-30 04:40:09,955] [INFO] Epoch 6/50, ValAcc: 89.55%, TrainLoss: 0.5069, ValLoss: 0.4282, LR: 0.001
[2026-01-30 04:40:16,968] [INFO] Epoch 7/50, ValAcc: 90.21%, TrainLoss: 0.4634, ValLoss: 0.3951, LR: 0.001
[2026-01-30 04:40:23,985] [INFO] Epoch 8/50, ValAcc: 90.86%, TrainLoss: 0.4195, ValLoss: 0.3684, LR: 0.001
[2026-01-30 04:40:31,002] [INFO] Epoch 9/50, ValAcc: 91.28%, TrainLoss: 0.3950, ValLoss: 0.3508, LR: 0.001
[2026-01-30 04:40:38,036] [INFO] Epoch 10/50, ValAcc: 91.27%, TrainLoss: 0.3693, ValLoss: 0.3497, LR: 0.001
[2026-01-30 04:40:45,065] [INFO] Epoch 11/50, ValAcc: 91.63%, TrainLoss: 0.3537, ValLoss: 0.3405, LR: 0.001
[2026-01-30 04:40:52,103] [INFO] Epoch 12/50, ValAcc: 91.53%, TrainLoss: 0.3341, ValLoss: 0.3365, LR: 0.001
[2026-01-30 04:40:59,138] [INFO] Epoch 13/50, ValAcc: 92.21%, TrainLoss: 0.3233, ValLoss: 0.3221, LR: 0.001
[2026-01-30 04:41:06,185] [INFO] Epoch 14/50, ValAcc: 92.09%, TrainLoss: 0.3127, ValLoss: 0.3196, LR: 0.001
[2026-01-30 04:41:13,239] [INFO] Epoch 15/50, ValAcc: 92.06%, TrainLoss: 0.2992, ValLoss: 0.3278, LR: 0.001
[2026-01-30 04:41:20,272] [INFO] Epoch 16/50, ValAcc: 91.91%, TrainLoss: 0.2899, ValLoss: 0.3214, LR: 0.001
[2026-01-30 04:41:27,323] [INFO] Epoch 17/50, ValAcc: 91.83%, TrainLoss: 0.2784, ValLoss: 0.3231, LR: 0.001
[2026-01-30 04:41:34,376] [INFO] Epoch 18/50, ValAcc: 92.34%, TrainLoss: 0.2432, ValLoss: 0.3096, LR: 0.0005
[2026-01-30 04:41:41,308] [INFO] Epoch 19/50, ValAcc: 92.33%, TrainLoss: 0.2343, ValLoss: 0.3003, LR: 0.0005
[2026-01-30 04:41:48,341] [INFO] Epoch 20/50, ValAcc: 92.34%, TrainLoss: 0.2294, ValLoss: 0.3009, LR: 0.0005
[2026-01-30 04:41:55,389] [INFO] Epoch 21/50, ValAcc: 92.53%, TrainLoss: 0.2248, ValLoss: 0.3019, LR: 0.0005
[2026-01-30 04:42:02,413] [INFO] Epoch 22/50, ValAcc: 92.41%, TrainLoss: 0.2182, ValLoss: 0.3033, LR: 0.0005
[2026-01-30 04:42:09,448] [INFO] Epoch 23/50, ValAcc: 92.62%, TrainLoss: 0.2062, ValLoss: 0.3038, LR: 0.00025
[2026-01-30 04:42:16,463] [INFO] Epoch 24/50, ValAcc: 92.56%, TrainLoss: 0.1954, ValLoss: 0.2974, LR: 0.00025
[2026-01-30 04:42:23,484] [INFO] Epoch 25/50, ValAcc: 92.52%, TrainLoss: 0.1925, ValLoss: 0.3080, LR: 0.00025
[2026-01-30 04:42:30,497] [INFO] Epoch 26/50, ValAcc: 92.49%, TrainLoss: 0.1912, ValLoss: 0.2998, LR: 0.00025
[2026-01-30 04:42:37,512] [INFO] Epoch 27/50, ValAcc: 92.69%, TrainLoss: 0.1847, ValLoss: 0.3037, LR: 0.00025
[2026-01-30 04:42:44,538] [INFO] Epoch 28/50, ValAcc: 92.66%, TrainLoss: 0.1780, ValLoss: 0.3028, LR: 0.000125
[2026-01-30 04:42:51,575] [INFO] Epoch 29/50, ValAcc: 92.65%, TrainLoss: 0.1737, ValLoss: 0.3097, LR: 0.000125
[2026-01-30 04:42:58,604] [INFO] Epoch 30/50, ValAcc: 92.46%, TrainLoss: 0.1727, ValLoss: 0.3037, LR: 0.000125
[2026-01-30 04:43:05,622] [INFO] Epoch 31/50, ValAcc: 92.46%, TrainLoss: 0.1691, ValLoss: 0.3106, LR: 6.25e-05
[2026-01-30 04:43:05,622] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 04:43:06,627] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['cnn'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769746685.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769746685.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_cnn_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9322,0.9324,0.9337,0.9324
[2026-01-30 04:43:06,629] [INFO] Training Fold 5/5
[2026-01-30 04:44:42,827] [INFO] Feature 0 normalized using token
[2026-01-30 04:44:42,827] [INFO] Train shape: (59144, 1000), Val shape: (8450, 1000), Test shape: (16898, 1000)
[2026-01-30 04:44:42,865] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1386, 512)
  )
  (sequence_encoders): ModuleList(
    (0): Sequential(
      (0): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))
      (1): ReLU()
      (2): Dropout(p=0.3, inplace=False)
      (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
      (4): ReLU()
      (5): Dropout(p=0.3, inplace=False)
    )
  )
  (transformer_input_proj): ModuleList(
    (0): Identity()
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=256, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=256, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2026-01-30 04:44:42,865] [INFO] Training...
[2026-01-30 04:44:49,901] [INFO] Epoch 1/50, ValAcc: 56.07%, TrainLoss: 2.9650, ValLoss: 1.5765, LR: 0.001
[2026-01-30 04:44:56,966] [INFO] Epoch 2/50, ValAcc: 71.18%, TrainLoss: 1.4052, ValLoss: 1.0725, LR: 0.001
[2026-01-30 04:45:04,033] [INFO] Epoch 3/50, ValAcc: 83.34%, TrainLoss: 0.9400, ValLoss: 0.7072, LR: 0.001
[2026-01-30 04:45:11,190] [INFO] Epoch 4/50, ValAcc: 85.73%, TrainLoss: 0.7014, ValLoss: 0.5971, LR: 0.001
[2026-01-30 04:45:18,255] [INFO] Epoch 5/50, ValAcc: 88.13%, TrainLoss: 0.5881, ValLoss: 0.5163, LR: 0.001
[2026-01-30 04:45:25,214] [INFO] Epoch 6/50, ValAcc: 88.62%, TrainLoss: 0.5170, ValLoss: 0.4742, LR: 0.001
[2026-01-30 04:45:32,179] [INFO] Epoch 7/50, ValAcc: 89.60%, TrainLoss: 0.4743, ValLoss: 0.4390, LR: 0.001
[2026-01-30 04:45:39,214] [INFO] Epoch 8/50, ValAcc: 89.85%, TrainLoss: 0.4346, ValLoss: 0.4225, LR: 0.001
[2026-01-30 04:45:46,278] [INFO] Epoch 9/50, ValAcc: 90.38%, TrainLoss: 0.4050, ValLoss: 0.4037, LR: 0.001
[2026-01-30 04:45:53,339] [INFO] Epoch 10/50, ValAcc: 91.02%, TrainLoss: 0.3772, ValLoss: 0.3846, LR: 0.001
[2026-01-30 04:46:00,384] [INFO] Epoch 11/50, ValAcc: 91.53%, TrainLoss: 0.3609, ValLoss: 0.3627, LR: 0.001
[2026-01-30 04:46:07,433] [INFO] Epoch 12/50, ValAcc: 91.80%, TrainLoss: 0.3436, ValLoss: 0.3518, LR: 0.001
[2026-01-30 04:46:14,515] [INFO] Epoch 13/50, ValAcc: 91.89%, TrainLoss: 0.3307, ValLoss: 0.3427, LR: 0.001
[2026-01-30 04:46:21,503] [INFO] Epoch 14/50, ValAcc: 91.88%, TrainLoss: 0.3166, ValLoss: 0.3391, LR: 0.001
[2026-01-30 04:46:28,531] [INFO] Epoch 15/50, ValAcc: 91.96%, TrainLoss: 0.3049, ValLoss: 0.3452, LR: 0.001
[2026-01-30 04:46:35,596] [INFO] Epoch 16/50, ValAcc: 91.60%, TrainLoss: 0.3010, ValLoss: 0.3375, LR: 0.001
[2026-01-30 04:46:42,538] [INFO] Epoch 17/50, ValAcc: 91.87%, TrainLoss: 0.2859, ValLoss: 0.3340, LR: 0.001
[2026-01-30 04:46:49,487] [INFO] Epoch 18/50, ValAcc: 92.09%, TrainLoss: 0.2789, ValLoss: 0.3342, LR: 0.001
[2026-01-30 04:46:56,414] [INFO] Epoch 19/50, ValAcc: 91.85%, TrainLoss: 0.2752, ValLoss: 0.3269, LR: 0.001
[2026-01-30 04:47:03,481] [INFO] Epoch 20/50, ValAcc: 92.32%, TrainLoss: 0.2616, ValLoss: 0.3353, LR: 0.001
[2026-01-30 04:47:10,556] [INFO] Epoch 21/50, ValAcc: 92.40%, TrainLoss: 0.2586, ValLoss: 0.3250, LR: 0.001
[2026-01-30 04:47:17,618] [INFO] Epoch 22/50, ValAcc: 92.53%, TrainLoss: 0.2504, ValLoss: 0.3315, LR: 0.001
[2026-01-30 04:47:24,677] [INFO] Epoch 23/50, ValAcc: 92.54%, TrainLoss: 0.2442, ValLoss: 0.3332, LR: 0.001
[2026-01-30 04:47:31,735] [INFO] Epoch 24/50, ValAcc: 92.18%, TrainLoss: 0.2447, ValLoss: 0.3395, LR: 0.001
[2026-01-30 04:47:38,798] [INFO] Epoch 25/50, ValAcc: 92.56%, TrainLoss: 0.2091, ValLoss: 0.3205, LR: 0.0005
[2026-01-30 04:47:45,955] [INFO] Epoch 26/50, ValAcc: 92.69%, TrainLoss: 0.1979, ValLoss: 0.3280, LR: 0.0005
[2026-01-30 04:47:53,025] [INFO] Epoch 27/50, ValAcc: 92.32%, TrainLoss: 0.1984, ValLoss: 0.3196, LR: 0.0005
[2026-01-30 04:48:00,089] [INFO] Epoch 28/50, ValAcc: 92.76%, TrainLoss: 0.1909, ValLoss: 0.3234, LR: 0.0005
[2026-01-30 04:48:07,150] [INFO] Epoch 29/50, ValAcc: 92.59%, TrainLoss: 0.1884, ValLoss: 0.3404, LR: 0.0005
[2026-01-30 04:48:14,078] [INFO] Epoch 30/50, ValAcc: 92.79%, TrainLoss: 0.1860, ValLoss: 0.3217, LR: 0.0005
[2026-01-30 04:48:21,015] [INFO] Epoch 31/50, ValAcc: 92.91%, TrainLoss: 0.1673, ValLoss: 0.3278, LR: 0.00025
[2026-01-30 04:48:28,021] [INFO] Epoch 32/50, ValAcc: 93.03%, TrainLoss: 0.1627, ValLoss: 0.3472, LR: 0.00025
[2026-01-30 04:48:35,051] [INFO] Epoch 33/50, ValAcc: 93.04%, TrainLoss: 0.1626, ValLoss: 0.3359, LR: 0.00025
[2026-01-30 04:48:42,057] [INFO] Epoch 34/50, ValAcc: 92.90%, TrainLoss: 0.1564, ValLoss: 0.3404, LR: 0.000125
[2026-01-30 04:48:49,053] [INFO] Epoch 35/50, ValAcc: 93.23%, TrainLoss: 0.1520, ValLoss: 0.3510, LR: 0.000125
[2026-01-30 04:48:56,054] [INFO] Epoch 36/50, ValAcc: 92.84%, TrainLoss: 0.1487, ValLoss: 0.3451, LR: 0.000125
[2026-01-30 04:49:03,049] [INFO] Epoch 37/50, ValAcc: 92.85%, TrainLoss: 0.1462, ValLoss: 0.3528, LR: 6.25e-05
[2026-01-30 04:49:03,049] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2026-01-30 04:49:04,066] [INFO] Namespace(path=['meta-free-apps/meta-ip_len/meta-ip_len.csv'], unknown_path=None, pktcount=1000, kfold=5, model=['cnn'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, cnn_kernel_size=3, cnn_layers=2, transformer_heads=4, transformer_ff=512, transformer_layers=2, transformer_dropout=0.1, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769746685.debug', leaderboard_path='output/meta-free-apps/model_evaluation/model_evaluation_meta_1769746685.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, app_launch_detection_evaluation=False, device=device(type='cuda'), name='iplen_token_cnn_1000_64_50_0.001_512_256_3_0.3_256_128'),0.9303,0.9289,0.9314,0.9304
[2026-01-30 04:49:05,167] [INFO] [(0.9315935854192556, 0.9320969126522486, 0.9339651818414593, 0.931780663820813), (0.9353216166637079, 0.9344419983249719, 0.9367445963653446, 0.936068520386219), (0.9289856787785536, 0.9295006780868407, 0.9317296223493255, 0.9291865211853141), (0.9322405018345367, 0.9323510531474837, 0.9337273474324115, 0.9324288542109965), (0.9303467866019647, 0.9289460697459943, 0.9313835622621166, 0.9304482499185637)]
=== Step4. Script Execution Finished at Fri Jan 30 04:49:06 AM UTC 2026 ===
