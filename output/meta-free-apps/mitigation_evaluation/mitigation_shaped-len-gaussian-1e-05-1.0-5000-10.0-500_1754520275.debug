[2025-08-06 22:44:37,444] [INFO] Namespace(path=['mitigation_t2/shaped-len-gaussian-1e-05-1.0-5000-10.0-500.csv'], pktcount=1000, kfold=1, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/mitigation_evaluation/mitigation_shaped-len-gaussian-1e-05-1.0-5000-10.0-500_1754520275.debug', leaderboard_path='output/meta-free-apps/mitigation_evaluation/mitigation_shaped-len-gaussian-1e-05-1.0-5000-10.0-500_1754520275.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'))
[2025-08-06 22:46:28,049] [INFO] Processed data from mitigation_t2/shaped-len-gaussian-1e-05-1.0-5000-10.0-500.csv:
[2025-08-06 22:46:28,049] [INFO] (84492, 1000)
[2025-08-06 22:46:28,049] [INFO] [['52' '52' '1333' ... <NA> <NA> <NA>]
 ['52' '52' '1432' ... <NA> <NA> <NA>]
 ['52' '52' '52' ... <NA> <NA> <NA>]
 ...
 ['1432' '1432' '1432' ... '1432' '1432' '1432']
 ['1432' '1432' '1432' ... '1148' '52' '52']
 ['623' '1432' '1432' ... '1432' '1432' '1432']]
[2025-08-06 22:47:55,290] [INFO] Feature 0 normalized using token
[2025-08-06 22:47:55,290] [INFO] Train shape: (59143, 1000), Val shape: (8450, 1000), Test shape: (16899, 1000)
[2025-08-06 22:47:55,369] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1382, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2025-08-06 22:47:55,369] [INFO] Training...
[2025-08-06 22:50:00,693] [INFO] Epoch 1/50, ValAcc: 1.04%, TrainLoss: 4.5135, ValLoss: 4.5119, LR: 0.001
[2025-08-06 22:52:03,419] [INFO] Epoch 2/50, ValAcc: 0.95%, TrainLoss: 4.5111, ValLoss: 4.5120, LR: 0.001
[2025-08-06 22:52:03,419] [INFO] ValAcc too low 0.95%. Stopping early.
[2025-08-06 22:52:09,448] [WARNING] ValAcc too low (0.95%), getting stuck in a bad local minimum...
[2025-08-06 22:52:09,449] [INFO] Retraining with new initialization: attempt 1...
[2025-08-06 22:54:12,251] [INFO] Epoch 1/50, ValAcc: 1.04%, TrainLoss: 4.5137, ValLoss: 4.5114, LR: 0.001
[2025-08-06 22:56:15,011] [INFO] Epoch 2/50, ValAcc: 1.04%, TrainLoss: 4.5111, ValLoss: 4.5117, LR: 0.001
[2025-08-06 22:58:17,916] [INFO] Epoch 3/50, ValAcc: 1.04%, TrainLoss: 4.5109, ValLoss: 4.5120, LR: 0.001
[2025-08-06 23:00:21,076] [INFO] Epoch 4/50, ValAcc: 0.98%, TrainLoss: 4.5112, ValLoss: 4.5122, LR: 0.001
[2025-08-06 23:00:21,076] [INFO] ValAcc too low 0.98%. Stopping early.
[2025-08-06 23:00:27,113] [WARNING] ValAcc too low (0.98%), getting stuck in a bad local minimum...
[2025-08-06 23:00:27,113] [INFO] Retraining with new initialization: attempt 2...
[2025-08-06 23:02:30,886] [INFO] Epoch 1/50, ValAcc: 1.07%, TrainLoss: 4.5137, ValLoss: 4.5112, LR: 0.001
[2025-08-06 23:04:33,652] [INFO] Epoch 2/50, ValAcc: 0.91%, TrainLoss: 4.5111, ValLoss: 4.5117, LR: 0.001
[2025-08-06 23:04:33,652] [INFO] ValAcc too low 0.91%. Stopping early.
[2025-08-06 23:04:39,684] [WARNING] ValAcc too low (0.91%), getting stuck in a bad local minimum...
[2025-08-06 23:04:39,684] [INFO] Retraining with new initialization: attempt 3...
[2025-08-06 23:06:42,203] [INFO] Epoch 1/50, ValAcc: 0.98%, TrainLoss: 4.5132, ValLoss: 4.5112, LR: 0.001
[2025-08-06 23:08:44,635] [INFO] Epoch 2/50, ValAcc: 0.98%, TrainLoss: 4.5111, ValLoss: 4.5117, LR: 0.001
[2025-08-06 23:08:44,635] [INFO] ValAcc too low 0.98%. Stopping early.
[2025-08-06 23:08:50,676] [WARNING] ValAcc too low (0.98%), getting stuck in a bad local minimum...
[2025-08-06 23:08:50,676] [INFO] Retraining with new initialization: attempt 4...
[2025-08-06 23:10:53,137] [INFO] Epoch 1/50, ValAcc: 1.11%, TrainLoss: 4.5106, ValLoss: 4.5094, LR: 0.001
[2025-08-06 23:12:55,566] [INFO] Epoch 2/50, ValAcc: 1.17%, TrainLoss: 4.5004, ValLoss: 4.4971, LR: 0.001
[2025-08-06 23:14:58,016] [INFO] Epoch 3/50, ValAcc: 1.29%, TrainLoss: 4.4938, ValLoss: 4.6030, LR: 0.001
[2025-08-06 23:17:00,479] [INFO] Epoch 4/50, ValAcc: 1.25%, TrainLoss: 4.4907, ValLoss: 4.4839, LR: 0.001
[2025-08-06 23:19:02,868] [INFO] Epoch 5/50, ValAcc: 1.23%, TrainLoss: 4.4895, ValLoss: 4.4795, LR: 0.001
[2025-08-06 23:21:05,299] [INFO] Epoch 6/50, ValAcc: 1.31%, TrainLoss: 4.4818, ValLoss: 4.4884, LR: 0.001
[2025-08-06 23:23:07,732] [INFO] Epoch 7/50, ValAcc: 1.50%, TrainLoss: 4.4798, ValLoss: 4.4679, LR: 0.001
[2025-08-06 23:25:10,200] [INFO] Epoch 8/50, ValAcc: 1.40%, TrainLoss: 4.4700, ValLoss: 4.4793, LR: 0.001
[2025-08-06 23:27:12,993] [INFO] Epoch 9/50, ValAcc: 3.41%, TrainLoss: 4.4025, ValLoss: 4.3093, LR: 0.001
[2025-08-06 23:29:15,804] [INFO] Epoch 10/50, ValAcc: 4.06%, TrainLoss: 4.3034, ValLoss: 4.2027, LR: 0.001
[2025-08-06 23:31:18,806] [INFO] Epoch 11/50, ValAcc: 6.77%, TrainLoss: 4.1653, ValLoss: 3.9667, LR: 0.001
[2025-08-06 23:33:21,796] [INFO] Epoch 12/50, ValAcc: 8.83%, TrainLoss: 3.9775, ValLoss: 3.7809, LR: 0.001
[2025-08-06 23:35:24,771] [INFO] Epoch 13/50, ValAcc: 14.47%, TrainLoss: 3.7843, ValLoss: 3.4779, LR: 0.001
[2025-08-06 23:37:27,586] [INFO] Epoch 14/50, ValAcc: 16.76%, TrainLoss: 3.5396, ValLoss: 3.6073, LR: 0.001
[2025-08-06 23:39:30,276] [INFO] Epoch 15/50, ValAcc: 19.27%, TrainLoss: 3.3270, ValLoss: 3.2269, LR: 0.001
[2025-08-06 23:41:33,027] [INFO] Epoch 16/50, ValAcc: 23.62%, TrainLoss: 3.1809, ValLoss: 3.1116, LR: 0.001
[2025-08-06 23:43:35,775] [INFO] Epoch 17/50, ValAcc: 22.01%, TrainLoss: 3.0714, ValLoss: 3.0491, LR: 0.001
[2025-08-06 23:45:38,833] [INFO] Epoch 18/50, ValAcc: 19.02%, TrainLoss: 2.9789, ValLoss: 3.1825, LR: 0.001
[2025-08-06 23:47:41,895] [INFO] Epoch 19/50, ValAcc: 26.09%, TrainLoss: 2.8822, ValLoss: 2.9144, LR: 0.001
[2025-08-06 23:49:44,803] [INFO] Epoch 20/50, ValAcc: 28.84%, TrainLoss: 2.7918, ValLoss: 2.9087, LR: 0.001
[2025-08-06 23:51:47,626] [INFO] Epoch 21/50, ValAcc: 28.06%, TrainLoss: 2.7112, ValLoss: 2.9404, LR: 0.001
[2025-08-06 23:53:50,409] [INFO] Epoch 22/50, ValAcc: 27.21%, TrainLoss: 2.6331, ValLoss: 2.9667, LR: 0.001
[2025-08-06 23:55:53,240] [INFO] Epoch 23/50, ValAcc: 29.21%, TrainLoss: 2.5695, ValLoss: 2.8842, LR: 0.001
[2025-08-06 23:57:56,063] [INFO] Epoch 24/50, ValAcc: 31.24%, TrainLoss: 2.5421, ValLoss: 2.7145, LR: 0.001
[2025-08-06 23:59:59,911] [INFO] Epoch 25/50, ValAcc: 23.61%, TrainLoss: 2.5001, ValLoss: 3.4651, LR: 0.001
[2025-08-07 00:02:04,127] [INFO] Epoch 26/50, ValAcc: 29.89%, TrainLoss: 2.4570, ValLoss: 3.0452, LR: 0.001
[2025-08-07 00:04:07,122] [INFO] Epoch 27/50, ValAcc: 31.41%, TrainLoss: 2.4244, ValLoss: 2.9603, LR: 0.001
[2025-08-07 00:06:10,004] [INFO] Epoch 28/50, ValAcc: 31.38%, TrainLoss: 2.2681, ValLoss: 2.8711, LR: 0.0005
[2025-08-07 00:08:12,865] [INFO] Epoch 29/50, ValAcc: 32.18%, TrainLoss: 2.1845, ValLoss: 2.7892, LR: 0.0005
[2025-08-07 00:10:15,697] [INFO] Epoch 30/50, ValAcc: 33.21%, TrainLoss: 2.1403, ValLoss: 2.9309, LR: 0.0005
[2025-08-07 00:12:18,516] [INFO] Epoch 31/50, ValAcc: 33.22%, TrainLoss: 2.0118, ValLoss: 2.8708, LR: 0.00025
[2025-08-07 00:14:21,351] [INFO] Epoch 32/50, ValAcc: 32.33%, TrainLoss: 1.9590, ValLoss: 3.2227, LR: 0.00025
[2025-08-07 00:16:24,169] [INFO] Epoch 33/50, ValAcc: 31.30%, TrainLoss: 1.9176, ValLoss: 3.4113, LR: 0.00025
[2025-08-07 00:18:27,007] [INFO] Epoch 34/50, ValAcc: 31.34%, TrainLoss: 1.8468, ValLoss: 3.3491, LR: 0.000125
[2025-08-07 00:20:29,837] [INFO] Epoch 35/50, ValAcc: 32.31%, TrainLoss: 1.8126, ValLoss: 3.4051, LR: 0.000125
[2025-08-07 00:22:32,685] [INFO] Epoch 36/50, ValAcc: 31.47%, TrainLoss: 1.7842, ValLoss: 3.3409, LR: 0.000125
[2025-08-07 00:24:35,566] [INFO] Epoch 37/50, ValAcc: 31.94%, TrainLoss: 1.7450, ValLoss: 3.4072, LR: 6.25e-05
[2025-08-07 00:24:35,566] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-08-07 00:24:53,648] [INFO] Namespace(path=['mitigation_t2/shaped-len-gaussian-1e-05-1.0-5000-10.0-500.csv'], pktcount=1000, kfold=1, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/mitigation_evaluation/mitigation_shaped-len-gaussian-1e-05-1.0-5000-10.0-500_1754520275.debug', leaderboard_path='output/meta-free-apps/mitigation_evaluation/mitigation_shaped-len-gaussian-1e-05-1.0-5000-10.0-500_1754520275.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='500_token_bigru_1000_64_50_0.001_512_256_3_0.3_256_128'),0.3266,0.3165,0.3272,0.3266
[2025-08-07 00:24:54,813] [INFO] [(0.3266465471329664, 0.31647089114732796, 0.32719153147437885, 0.32658304733859495)]
