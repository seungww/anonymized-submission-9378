[2025-08-07 01:59:02,855] [INFO] Namespace(path=['mitigation_t1/shaped-len-gaussian-1e-05-0.1-1250-100.0-12.csv'], pktcount=1000, kfold=1, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/mitigation_evaluation/mitigation_shaped-len-gaussian-1e-05-0.1-1250-100.0-12_1754531941.debug', leaderboard_path='output/meta-free-apps/mitigation_evaluation/mitigation_shaped-len-gaussian-1e-05-0.1-1250-100.0-12_1754531941.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'))
[2025-08-07 02:00:27,218] [INFO] Processed data from mitigation_t1/shaped-len-gaussian-1e-05-0.1-1250-100.0-12.csv:
[2025-08-07 02:00:27,218] [INFO] (84492, 1000)
[2025-08-07 02:00:27,218] [INFO] [['125' '512' '246' ... <NA> <NA> <NA>]
 ['52' '348' '397' ... <NA> <NA> <NA>]
 ['85' '378' '266' ... <NA> <NA> <NA>]
 ...
 ['78' '221' '636' ... '217' '276' '124']
 ['390' '516' '1432' ... '1432' '1432' '1432']
 ['660' '1432' '1432' ... '375' '129' '159']]
[2025-08-07 02:02:01,551] [INFO] Feature 0 normalized using token
[2025-08-07 02:02:01,552] [INFO] Train shape: (59143, 1000), Val shape: (8450, 1000), Test shape: (16899, 1000)
[2025-08-07 02:02:01,631] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1382, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2025-08-07 02:02:01,631] [INFO] Training...
[2025-08-07 02:03:45,592] [INFO] Epoch 1/50, ValAcc: 1.03%, TrainLoss: 4.5110, ValLoss: 4.5097, LR: 0.001
[2025-08-07 02:05:27,607] [INFO] Epoch 2/50, ValAcc: 0.98%, TrainLoss: 4.5111, ValLoss: 4.5119, LR: 0.001
[2025-08-07 02:05:27,608] [INFO] ValAcc too low 0.98%. Stopping early.
[2025-08-07 02:05:32,815] [WARNING] ValAcc too low (0.98%), getting stuck in a bad local minimum...
[2025-08-07 02:05:32,815] [INFO] Retraining with new initialization: attempt 1...
[2025-08-07 02:07:14,758] [INFO] Epoch 1/50, ValAcc: 26.33%, TrainLoss: 3.5476, ValLoss: 2.7465, LR: 0.001
[2025-08-07 02:08:57,190] [INFO] Epoch 2/50, ValAcc: 44.17%, TrainLoss: 2.2806, ValLoss: 1.9621, LR: 0.001
[2025-08-07 02:10:39,648] [INFO] Epoch 3/50, ValAcc: 45.09%, TrainLoss: 1.7858, ValLoss: 1.9549, LR: 0.001
[2025-08-07 02:12:21,701] [INFO] Epoch 4/50, ValAcc: 53.98%, TrainLoss: 1.5488, ValLoss: 1.5693, LR: 0.001
[2025-08-07 02:14:03,630] [INFO] Epoch 5/50, ValAcc: 54.38%, TrainLoss: 1.3904, ValLoss: 1.5409, LR: 0.001
[2025-08-07 02:15:45,568] [INFO] Epoch 6/50, ValAcc: 57.57%, TrainLoss: 1.2970, ValLoss: 1.4292, LR: 0.001
[2025-08-07 02:17:27,636] [INFO] Epoch 7/50, ValAcc: 60.71%, TrainLoss: 1.2098, ValLoss: 1.3444, LR: 0.001
[2025-08-07 02:19:09,634] [INFO] Epoch 8/50, ValAcc: 57.10%, TrainLoss: 1.1415, ValLoss: 1.4399, LR: 0.001
[2025-08-07 02:20:51,476] [INFO] Epoch 9/50, ValAcc: 55.14%, TrainLoss: 1.1142, ValLoss: 1.6102, LR: 0.001
[2025-08-07 02:22:33,068] [INFO] Epoch 10/50, ValAcc: 58.51%, TrainLoss: 1.0643, ValLoss: 1.4381, LR: 0.001
[2025-08-07 02:24:14,562] [INFO] Epoch 11/50, ValAcc: 67.07%, TrainLoss: 0.8886, ValLoss: 1.1330, LR: 0.0005
[2025-08-07 02:25:56,158] [INFO] Epoch 12/50, ValAcc: 65.09%, TrainLoss: 0.8167, ValLoss: 1.1639, LR: 0.0005
[2025-08-07 02:27:37,721] [INFO] Epoch 13/50, ValAcc: 66.99%, TrainLoss: 0.7806, ValLoss: 1.1649, LR: 0.0005
[2025-08-07 02:29:19,585] [INFO] Epoch 14/50, ValAcc: 56.38%, TrainLoss: 0.7576, ValLoss: 1.7240, LR: 0.0005
[2025-08-07 02:31:01,533] [INFO] Epoch 15/50, ValAcc: 67.43%, TrainLoss: 0.6659, ValLoss: 1.1495, LR: 0.00025
[2025-08-07 02:32:43,439] [INFO] Epoch 16/50, ValAcc: 67.43%, TrainLoss: 0.6229, ValLoss: 1.1718, LR: 0.00025
[2025-08-07 02:34:25,413] [INFO] Epoch 17/50, ValAcc: 68.72%, TrainLoss: 0.6063, ValLoss: 1.1506, LR: 0.00025
[2025-08-07 02:36:07,295] [INFO] Epoch 18/50, ValAcc: 68.89%, TrainLoss: 0.5553, ValLoss: 1.2321, LR: 0.000125
[2025-08-07 02:37:48,437] [INFO] Epoch 19/50, ValAcc: 67.82%, TrainLoss: 0.5310, ValLoss: 1.2538, LR: 0.000125
[2025-08-07 02:39:27,823] [INFO] Epoch 20/50, ValAcc: 68.54%, TrainLoss: 0.5186, ValLoss: 1.2629, LR: 0.000125
[2025-08-07 02:41:08,792] [INFO] Epoch 21/50, ValAcc: 67.79%, TrainLoss: 0.4931, ValLoss: 1.3325, LR: 6.25e-05
[2025-08-07 02:41:08,792] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-08-07 02:41:24,176] [INFO] Namespace(path=['mitigation_t1/shaped-len-gaussian-1e-05-0.1-1250-100.0-12.csv'], pktcount=1000, kfold=1, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/mitigation_evaluation/mitigation_shaped-len-gaussian-1e-05-0.1-1250-100.0-12_1754531941.debug', leaderboard_path='output/meta-free-apps/mitigation_evaluation/mitigation_shaped-len-gaussian-1e-05-0.1-1250-100.0-12_1754531941.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='12_token_bigru_1000_64_50_0.001_512_256_3_0.3_256_128'),0.6733,0.6709,0.6777,0.6728
[2025-08-07 02:41:25,183] [INFO] [(0.6732942777679153, 0.6708747714466003, 0.6777102115828155, 0.6728086684358303)]
