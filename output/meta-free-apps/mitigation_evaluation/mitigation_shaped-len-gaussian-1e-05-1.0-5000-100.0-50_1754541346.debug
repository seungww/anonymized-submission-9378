[2025-08-07 04:35:47,786] [INFO] Namespace(path=['mitigation_t1/shaped-len-gaussian-1e-05-1.0-5000-100.0-50.csv'], pktcount=1000, kfold=1, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/mitigation_evaluation/mitigation_shaped-len-gaussian-1e-05-1.0-5000-100.0-50_1754541346.debug', leaderboard_path='output/meta-free-apps/mitigation_evaluation/mitigation_shaped-len-gaussian-1e-05-1.0-5000-100.0-50_1754541346.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'))
[2025-08-07 04:37:10,610] [INFO] Processed data from mitigation_t1/shaped-len-gaussian-1e-05-1.0-5000-100.0-50.csv:
[2025-08-07 04:37:10,610] [INFO] (84492, 1000)
[2025-08-07 04:37:10,610] [INFO] [['52' '738' '600' ... <NA> <NA> <NA>]
 ['149' '52' '1432' ... <NA> <NA> <NA>]
 ['826' '1234' '1001' ... <NA> <NA> <NA>]
 ...
 ['1432' '1432' '1432' ... '712' '1053' '466']
 ['1432' '1432' '1432' ... '1432' '1432' '1432']
 ['1020' '1432' '1432' ... '1432' '1432' '1432']]
[2025-08-07 04:38:30,877] [INFO] Feature 0 normalized using token
[2025-08-07 04:38:30,877] [INFO] Train shape: (59143, 1000), Val shape: (8450, 1000), Test shape: (16899, 1000)
[2025-08-07 04:38:30,958] [INFO] Classifier: VRScannerModel(
  (input_modules): ModuleList(
    (0): Embedding(1382, 512)
  )
  (rnn_layers): ModuleList(
    (0): GRU(512, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (attn_nets): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
  )
  (projection_layers): ModuleList(
    (0): Linear(in_features=512, out_features=256, bias=True)
  )
  (feature_attn_net): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): Tanh()
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.3, inplace=False)
    (3): Linear(in_features=128, out_features=91, bias=True)
  )
)
[2025-08-07 04:38:30,958] [INFO] Training...
[2025-08-07 04:40:15,567] [INFO] Epoch 1/50, ValAcc: 14.58%, TrainLoss: 4.2444, ValLoss: 3.3253, LR: 0.001
[2025-08-07 04:41:56,124] [INFO] Epoch 2/50, ValAcc: 30.14%, TrainLoss: 3.0102, ValLoss: 2.5833, LR: 0.001
[2025-08-07 04:43:38,327] [INFO] Epoch 3/50, ValAcc: 36.89%, TrainLoss: 2.5682, ValLoss: 2.3044, LR: 0.001
[2025-08-07 04:45:20,209] [INFO] Epoch 4/50, ValAcc: 41.04%, TrainLoss: 2.2575, ValLoss: 2.1386, LR: 0.001
[2025-08-07 04:47:01,901] [INFO] Epoch 5/50, ValAcc: 42.09%, TrainLoss: 2.0006, ValLoss: 2.0457, LR: 0.001
[2025-08-07 04:48:43,557] [INFO] Epoch 6/50, ValAcc: 47.07%, TrainLoss: 1.8288, ValLoss: 1.8574, LR: 0.001
[2025-08-07 04:50:25,396] [INFO] Epoch 7/50, ValAcc: 41.49%, TrainLoss: 1.7104, ValLoss: 2.1773, LR: 0.001
[2025-08-07 04:52:07,258] [INFO] Epoch 8/50, ValAcc: 50.38%, TrainLoss: 1.6058, ValLoss: 1.7602, LR: 0.001
[2025-08-07 04:53:49,144] [INFO] Epoch 9/50, ValAcc: 46.25%, TrainLoss: 1.5307, ValLoss: 1.9657, LR: 0.001
[2025-08-07 04:55:31,022] [INFO] Epoch 10/50, ValAcc: 42.30%, TrainLoss: 1.4545, ValLoss: 2.1399, LR: 0.001
[2025-08-07 04:57:12,893] [INFO] Epoch 11/50, ValAcc: 49.47%, TrainLoss: 1.4131, ValLoss: 1.7844, LR: 0.001
[2025-08-07 04:58:54,730] [INFO] Epoch 12/50, ValAcc: 40.58%, TrainLoss: 1.1997, ValLoss: 2.6207, LR: 0.0005
[2025-08-07 05:00:36,572] [INFO] Epoch 13/50, ValAcc: 49.23%, TrainLoss: 1.1135, ValLoss: 2.0532, LR: 0.0005
[2025-08-07 05:02:18,413] [INFO] Epoch 14/50, ValAcc: 46.12%, TrainLoss: 1.0532, ValLoss: 2.1516, LR: 0.0005
[2025-08-07 05:04:00,166] [INFO] Epoch 15/50, ValAcc: 49.74%, TrainLoss: 0.9379, ValLoss: 2.0337, LR: 0.00025
[2025-08-07 05:05:41,809] [INFO] Epoch 16/50, ValAcc: 54.73%, TrainLoss: 0.8893, ValLoss: 1.8397, LR: 0.00025
[2025-08-07 05:07:23,458] [INFO] Epoch 17/50, ValAcc: 50.09%, TrainLoss: 0.8463, ValLoss: 2.1476, LR: 0.00025
[2025-08-07 05:09:05,091] [INFO] Epoch 18/50, ValAcc: 49.09%, TrainLoss: 0.7822, ValLoss: 2.2593, LR: 0.000125
[2025-08-07 05:10:46,739] [INFO] Epoch 19/50, ValAcc: 47.99%, TrainLoss: 0.7579, ValLoss: 2.4793, LR: 0.000125
[2025-08-07 05:12:28,392] [INFO] Epoch 20/50, ValAcc: 49.51%, TrainLoss: 0.7366, ValLoss: 2.4349, LR: 0.000125
[2025-08-07 05:14:10,020] [INFO] Epoch 21/50, ValAcc: 49.62%, TrainLoss: 0.7036, ValLoss: 2.4285, LR: 6.25e-05
[2025-08-07 05:14:10,020] [INFO] Learning rate 0.000063 is below threshold. Stopping early.
[2025-08-07 05:14:25,667] [INFO] Namespace(path=['mitigation_t1/shaped-len-gaussian-1e-05-1.0-5000-100.0-50.csv'], pktcount=1000, kfold=1, model=['bigru'], norm=['token'], input_dim=512, hidden_size=256, num_layers=3, dropout=0.3, fusion_dim=256, fc_hidden_size=128, batch_size=64, epoch=50, lr=0.001, feature_attention=False, timestep_attention=False, strict=True, window_size=300, step_size=100, debug_path='output/meta-free-apps/mitigation_evaluation/mitigation_shaped-len-gaussian-1e-05-1.0-5000-100.0-50_1754541346.debug', leaderboard_path='output/meta-free-apps/mitigation_evaluation/mitigation_shaped-len-gaussian-1e-05-1.0-5000-100.0-50_1754541346.csv', step1=False, step2=False, step3=False, train=True, sliding_window_evaluation=False, longitudinal_evaluation=False, openworld_evaluation=False, device=device(type='cuda'), name='50_token_bigru_1000_64_50_0.001_512_256_3_0.3_256_128'),0.4855,0.4820,0.4954,0.4859
[2025-08-07 05:14:26,456] [INFO] [(0.48553168826557785, 0.48199008182007685, 0.49537161157268533, 0.4858942456285053)]
